[["index.html", "Desagregación de datos en encuestas de hogares: metodologías bayesianas para modelos de estimación en áreas pequeñas Agenda", " Desagregación de datos en encuestas de hogares: metodologías bayesianas para modelos de estimación en áreas pequeñas Andrés Gutiérrez1, Stalyn Guerrero2 2023-05-06 Agenda Experto Regional en Estadísticas Sociales - Comisión Económica para América Latina y el Caribe (CEPAL) - andres.gutierrez@cepal.org↩︎ Consultor - Comisión Económica para América Latina y el Caribe (CEPAL), guerrerostalyn@gmail.com↩︎ "],["material-del-curso.html", "Material del curso", " Material del curso En el siguiente enlace encontrará material bibliográfico complementario (Libros, presentaciones, casos de estudio y manuales de instalación) Descargar En el siguiente enlace encontrará las rutinas de R desarrolladas para el taller. Descargar "],["día-1---sesión-1--no-dejar-a-nadie-atrás---ods-y-la-agenda-2030.html", "Capítulo 1 Día 1 - Sesión 1- No dejar a nadie atrás - ODS y la Agenda 2030", " Capítulo 1 Día 1 - Sesión 1- No dejar a nadie atrás - ODS y la Agenda 2030 Objetivos de Desarrollo Sostenible y limitaciones de las encuesta "],["día-1---sesión-2--limitaciones-de-las-encuestas-de-hogares.html", "Capítulo 2 Día 1 - Sesión 2- Limitaciones de las encuestas de hogares", " Capítulo 2 Día 1 - Sesión 2- Limitaciones de las encuestas de hogares Objetivos de Desarrollo Sostenible y limitaciones de las encuesta "],["día-1---sesión-3--censo-e-información-satelital.html", "Capítulo 3 Día 1 - Sesión 3- Censo e información satelital ", " Capítulo 3 Día 1 - Sesión 3- Censo e información satelital "],["uso-de-imágenes-satelitales-y-sae.html", "3.1 Uso de imágenes satelitales y SAE", " 3.1 Uso de imágenes satelitales y SAE Uno de los artículo pioneros de estimación de áreas pequeñas fue el artículo de Singh, R, et. al. (2002) el cual abordó la estimación del rendimiento de cultivos para los tehsil (unidad subadministrativa) del distriyo Rohtak district en Haryana (India). Las imágenes raster representan el mundo mediante un conjunto de celdas contiguas igualmente espaciadas conocidas como pixeles, estas imágenes tienen información como un sistema de información geográfico, Un sistema de referencia de coordenadas. Las imágenes almacenan un identificador, un valor en cada pixel (o un vector con diferentes valores) y cada celda tiene asociada una escala de colores. Las imágenes pueden obtenerse crudas y procesadas, estas primeras contienen solamente las capas de colores, las segundas contienen también valores que han sido procesados en cada celda (índices de vegetación, intensidad lumínica, tipo de vegetación). La información cruda puede utilizarse para entrenar características que se desean entrenar (carreteras, tipo de cultivo, bosque / no bosque), afortunadamente en Google Earth Engine encontramos muchos indicadores procesadas asociadas a un pixel. Estos indicadores pueden agregarse a nivel de un área geográfica. 3.1.1 Fuentes de datos de imágenes satelitales Algunas de las principales fuentes de imágenes satelitales son: http://earthexplorer.usgs.gov/ https://lpdaacsvc.cr.usgs.gov/appeears/ https://search.earthdata.nasa.gov/search https://scihub.copernicus.eu/ https://aws.amazon.com/public-data-sets/landsat/ Sin embargo la mayor parte de estas fuentes están centralizadas en Google Earth Engine que permite buscar fuentes de datos provenientes de imágenes satelitales. GEE se puede manejar por medio de APIS en diferentes lenguajes de programación: Javascript (por defecto), Python y R (paquete rgee). "],["google-earth-eninge.html", "3.2 Google Earth Eninge", " 3.2 Google Earth Eninge Crear una cuenta en link, una vez que se ingrese a la cuenta puede buscarse los conjuntos de datos de interés: Una vez se busque el conjunto de datos se puede abrir un editor de código brindado por google en Javascript. Copiar y pegar la sintaxis que brinda el buscador de conjunto de datos para visualizar la imagen raster y disponer de sentencias que Permitan la obtención del conjunto de datos de interés posteriormente en R "],["instalación-de-rgee.html", "3.3 Instalación de rgee", " 3.3 Instalación de rgee Descargar e instalar anaconda o conda. (https://www.anaconda.com/products/individual) Abrir Anaconda prompt y configurar ambiente de trabajo (ambiente python rgee_py) con las siguientes sentencias: conda create -n rgee_py python=3.9 activate rgee_py pip install google-api-python-client pip install earthengine-api pip install numpy Listar los ambientes de Python disponibles en anaconda prompt conda env list Una vez identificado la ruta del ambiente ambiente rgee_py definirla en R (no se debe olvidar cambiar \\ por /). Instalar reticulate y rgee, cargar paquetes para procesamiento espacial y configurar el ambiente de trabajo como sigue: library(reticulate) # Conexión con Python library(rgee) # Conexión con Google Earth Engine library(sf) # Paquete para manejar datos geográficos library(dplyr) # Paquete para procesamiento de datos library(magrittr) rgee_environment_dir = &quot;C://Users//sguerrero//Anaconda3//envs//rgee_py//python.exe&quot; # Configurar python (Algunas veces no es detectado y se debe reiniciar R) reticulate::use_python(rgee_environment_dir, required=T) rgee::ee_install_set_pyenv(py_path = rgee_environment_dir, py_env = &quot;rgee_py&quot;) Sys.setenv(RETICULATE_PYTHON = rgee_environment_dir) Sys.setenv(EARTHENGINE_PYTHON = rgee_environment_dir) Una vez configurado el ambiente puede iniciarlizarse una sesión de Google Earth Engine como sigue: rgee::ee_Initialize(drive = T) Notas: Se debe inicializar cada sesión con el comando rgee::ee_Initialize(drive = T). Los comandos de javascript que invoquen métodos con “.” se sustituyen por signo peso ($), por ejemplo: ee.ImageCollection().filterDate() # Javascript ee$ImageCollection()$filterDate() # R 3.3.1 Descargar información satelital Paso 1: disponer de los shapefile shape &lt;- read_sf(&quot;Recursos/Día1/Sesion2/Shape/DOM.shp&quot;) plot(shape[&quot;geometry&quot;]) Paso 2: Seleccionar el archivo de imágenes que desea procesar, para nuestro ejemplo luces nocturnas. luces &lt;- ee$ImageCollection(&quot;NOAA/DMSP-OLS/NIGHTTIME_LIGHTS&quot;) %&gt;% ee$ImageCollection$filterDate(&quot;2013-01-01&quot;, &quot;2014-01-01&quot;) %&gt;% ee$ImageCollection$map(function(x) x$select(&quot;stable_lights&quot;)) %&gt;% ee$ImageCollection$toBands() Paso 3: Descargar la información shape_luces &lt;- map(unique(shape$dam), ~tryCatch(ee_extract( x = luces, y = shape[&quot;dam&quot;] %&gt;% filter(dam == .x), ee$Reducer$mean(), sf = FALSE ) %&gt;% mutate(dam = .x), error = function(e)data.frame(dam = .x))) shape_luces %&lt;&gt;% bind_rows() tba(shape_luces, cap = &quot;Promedio de luces nocturnasa&quot;) Repetir la rutina para: Tipo de suelo: crops-coverfraction (Porcentaje de cubrimiento cultivos) y urban-coverfraction (Porcentaje de cobertura urbana) disponibles en https://developers.google.com/earth-engine/datasets/catalog/COGTMNICUS_Landcover_100m_Proba-V-C3_Global#description Tiempo de viaje al hospital o clínica más cercana (accessibility) y tiempo de viaje al hospital o clínica más cercana utilizando transporte no motorizado (accessibility_walking_only) información disponible en https://develoGTMs.google.com/earth-engine/datasets/catalog/Oxford_MAP_accessibility_to_healthcare_2019 Modificación humana, donde se consideran los asentamiento humano, la agricultura, el transporte, la minería y producción de energía e infraestructura eléctrica. En el siguiente link encuentra la información satelital https://develoGTMs.google.com/earth-engine/datasets/catalog/CSP_HM_GlobalHumanModification#description Paso 4 consolidar la información. dam luces_nocturnas cubrimiento_cultivo cubrimiento_urbano modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 02 97.27735 107.10243 100.28394 111.01645 112.25437 109.66652 03 94.36142 97.71126 96.32667 96.29454 100.55525 105.35470 04 96.53042 95.73335 96.55354 98.67362 102.77860 103.78255 05 91.61138 98.91270 93.17994 95.16236 97.72809 95.59357 01 97.65958 86.79795 106.90397 82.34083 89.53466 87.11064 06 100.52567 107.21708 99.96448 104.95498 94.75524 95.69942 08 94.54495 103.38473 93.84241 102.73169 98.74441 101.96155 09 96.82438 91.41961 97.18788 92.96846 91.28395 90.46557 30 95.68487 91.78986 93.93370 96.83847 98.54392 98.93543 10 92.18900 98.33939 94.53840 97.45111 108.54346 107.34596 Los resultados se muestran en los siguientes mapas 3.3.2 Luces nocturnas 3.3.3 Cubrimiento cultivos 3.3.4 Cubrimiento urbanos 3.3.5 Modificación humana 3.3.6 Tiempo promedio al hospital 3.3.7 Tiempo promedio al hospital en vehiculo no motorizado "],["censos-de-población-y-vivienda.html", "3.4 Censos de población y vivienda", " 3.4 Censos de población y vivienda Es necesario definir las variables del país con los que se desea trabajar. De acuerdo a esto, como primer paso se debe tener acceso al censo del país, para ello puede acceder desde el siguiente enlace https://redatam.org/en/microdata en el cual dispondrá de un archivo .zip con los microdatos del país. Ahora bien, para leer el conjunto de datos, es necesario emplear la función redatam.open de la librería redatam, la cual depende directamente del diccionario censal del software REDATAM, este es un archivo con extensión dicx y que debe encontrarse en la carpeta sobre los datos que se están leyendo. Así, es como se crea un objeto dentro de R que hace la respectiva unión del diccionario con los microdatos de la base de datos censal. La siguiente sintaxis muestra la lectura del diccionario en R y los cálculos iniciales # https://redatamr.ideasybits.com/ library(redatam) RepDoma &lt;- redatam.open(&quot;cpv2010dom-cde.dicX&quot;) CONTEOS &lt;- redatam.query(RepDoma, &quot;freq PROVIC.IDPROVI by VIVIENDA.ZONA by PERSONA.P27 by PERSONA.P29 by PERSONA.ANEST&quot;, tot.omit = FALSE) Después de realizar algunas validaciones se estandarizan las variables como muestra el siguiente código. CONTEOS &lt;- readRDS(file = &quot;Recursos/Día1/Sesion2/Data/CONTEOS.RDS&quot;) # Eliminando totales de la tabla CONTEOS2 &lt;- CONTEOS %&gt;% filter_at(vars(matches(&quot;_label&quot;)),all_vars(. != &quot;__tot__&quot;)) censo_mrp &lt;- CONTEOS2 %&gt;% transmute(dam = str_pad( string = IDPROVI1_value, width = 2, pad = &quot;0&quot; ), area = case_when(ZONA2_value == 1 ~ &quot;1&quot;, # 1 = Urbana TRUE ~ &quot;0&quot;), sexo = as.character(P273_value), edad = case_when( P294_value %in% 0:14 ~ &quot;1&quot;, # 0 a 14 P294_value %in% 15:29 ~ &quot;2&quot;, # 15 a 29 P294_value %in% 30:44 ~ &quot;3&quot;, # 30 a 44 P294_value %in% 45:64 ~ &quot;4&quot;, # 45 a 64 TRUE ~ &quot;5&quot;), # 65 o mas anoest = case_when( P294_value &lt; 5| is.na(ANEST5_value) ~ &quot;98&quot;, # No aplica ANEST5_value == 99 ~ &quot;99&quot;, #NS/NR ANEST5_value %in% 0 ~ &quot;1&quot;, # Sin educacion ANEST5_value %in% c(1:6) ~ &quot;2&quot;, # 1-6 ANEST5_value %in% c(7:12) ~ &quot;3&quot;, # 7-12 ANEST5_value &gt; 12 ~ &quot;4&quot; , # 12 o mas TRUE ~ &quot;Error&quot; ), value) %&gt;% group_by(dam, area, sexo, edad,anoest) %&gt;% summarise(n = sum(value), .groups = &quot;drop&quot;) A partir de la base estandarizada es posible construir algunas covariables para la dam. censo_mrp &lt;- readRDS(&quot;Recursos/Día1/Sesion2/Data/censo_mrp_dam.rds&quot;) tasa_censo &lt;- model.matrix(dam ~ -1 +., data = censo_mrp %&gt;% select(-n)) %&gt;% data.frame() %&gt;% mutate(dam = censo_mrp$dam, n = censo_mrp$n) %&gt;% group_by(dam) %&gt;% summarise_all(~weighted.mean(x = .,w = n)) %&gt;% select(-area0, -anoest98,-anoest98,-n) tba(tasa_censo) dam area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 01 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 02 0.7718 0.4733 0.2773 0.1831 0.1531 0.0634 0.3350 0.2771 0.0540 0.0065 03 0.7128 0.4804 0.2643 0.1572 0.1489 0.0718 0.3470 0.2542 0.0493 0.0055 04 0.8345 0.4826 0.2756 0.1738 0.1454 0.0638 0.3169 0.2948 0.0827 0.0082 05 0.5977 0.4849 0.2509 0.1752 0.1748 0.0899 0.3471 0.3252 0.0625 0.0052 06 0.6626 0.4909 0.2671 0.1988 0.1736 0.0786 0.3140 0.3383 0.1038 0.0087 07 0.4828 0.4768 0.2380 0.1431 0.1527 0.0788 0.3287 0.1949 0.0315 0.0037 08 0.5144 0.4610 0.2648 0.1728 0.1625 0.0845 0.3822 0.2730 0.0440 0.0035 09 0.4535 0.4889 0.2733 0.2084 0.1694 0.0764 0.3125 0.3699 0.0840 0.0078 10 0.7996 0.4865 0.2658 0.1648 0.1418 0.0665 0.3214 0.2603 0.0485 0.0052 11 0.7784 0.4766 0.3001 0.2393 0.1250 0.0430 0.2986 0.3722 0.0650 0.0076 12 0.9425 0.5059 0.2821 0.2061 0.1466 0.0515 0.2810 0.3955 0.0794 0.0080 13 0.4696 0.4885 0.2762 0.2049 0.1606 0.0719 0.3142 0.3582 0.0781 0.0070 14 0.5252 0.4855 0.2700 0.1929 0.1729 0.0731 0.3258 0.3517 0.0765 0.0079 15 0.5312 0.4718 0.2685 0.1984 0.1764 0.0798 0.3103 0.3318 0.0519 0.0048 16 0.6441 0.4651 0.2738 0.1932 0.1334 0.0459 0.2589 0.2403 0.0316 0.0028 17 0.6810 0.5047 0.2665 0.1984 0.1549 0.0646 0.3707 0.3252 0.0460 0.0052 18 0.5839 0.4895 0.2699 0.2126 0.1689 0.0703 0.2875 0.3940 0.0727 0.0067 19 0.2891 0.4902 0.2568 0.2001 0.1839 0.0954 0.3037 0.3483 0.1097 0.0078 20 0.4354 0.4837 0.2811 0.2007 0.1554 0.0628 0.3080 0.3691 0.0595 0.0059 21 0.5186 0.4996 0.2807 0.1956 0.1451 0.0507 0.2931 0.3782 0.0783 0.0082 22 0.6009 0.4725 0.2559 0.1698 0.1695 0.0891 0.3482 0.2674 0.0642 0.0075 23 0.8408 0.5063 0.2861 0.1974 0.1522 0.0572 0.2840 0.4022 0.0817 0.0077 24 0.5628 0.4827 0.2754 0.1871 0.1662 0.0743 0.3198 0.3320 0.1000 0.0089 25 0.7561 0.5017 0.2795 0.2221 0.1583 0.0649 0.2843 0.3727 0.1106 0.0102 26 0.4795 0.4776 0.2632 0.1821 0.1770 0.1038 0.3340 0.3156 0.0767 0.0074 27 0.7917 0.4785 0.2810 0.2098 0.1501 0.0681 0.3121 0.3151 0.0817 0.0074 28 0.6797 0.4949 0.2690 0.2028 0.1597 0.0655 0.2883 0.3819 0.0855 0.0101 29 0.4939 0.4836 0.2656 0.1718 0.1537 0.0756 0.3438 0.3188 0.0526 0.0056 30 0.7412 0.4902 0.2722 0.1855 0.1624 0.0775 0.3308 0.3338 0.0696 0.0070 31 0.6292 0.4587 0.2556 0.2037 0.1761 0.0848 0.3785 0.2681 0.0602 0.0050 32 0.8780 0.5098 0.2870 0.2126 0.1502 0.0447 0.2409 0.4005 0.1291 0.0131 Es posible construir a partir de una variable del censo, haciendo que el proceso se hace más corto, para este caso es empleada la variable VIVIENDA.V05, agregada por dam En el primer bloque que código usando la función redatam.query() se realiza el conteo de viviendas que tienen el piso de tierra. Seguido de esto, eliminamos los registros que no son de interés, por ejemplo, el total en la dam o total nacional, los cuales se identifican dentro de la base con la etiqueta __tot__. El siguiente paso es contar el número de viviendas por dam que tienen piso de tierra en el censo (Pobx) y el total de viviendas que respondieron a la pregunta (PobT), para finalmente realizar el cociente de estas dos preguntas. CONTEOS &lt;- redatam.query(RepDoma, &quot;freq PROVIC.IDPROVI by VIVIENDA.V05&quot;, tot.omit = FALSE) PISO &lt;- CONTEOS %&gt;% filter_at(vars(matches(&quot;_label&quot;)), all_vars(!. %in% c(&quot;__tot__&quot;,&quot;__mv__&quot;) )) tasa_piso &lt;- PISO %&gt;% mutate(Pobx = ifelse(V052_value %in% c(7), value, 0), PobT = value) %&gt;% group_by( depto = str_pad( string = IDPROVI1_value, width = 2, pad = &quot;0&quot; ) ) %&gt;% summarise(PobT = sum(PobT), Pobx = sum(Pobx)) %&gt;% transmute(depto, piso_tierra = Pobx/PobT) La tabla resultante se muestra a continuación. dam piso_tierra 02 0.1038 03 0.1435 04 0.0828 05 0.0593 01 0.0033 06 0.0191 08 0.0582 09 0.0365 30 0.0564 10 0.1133 11 0.0089 07 0.3020 12 0.0120 13 0.0214 14 0.0252 28 0.0197 15 0.0926 29 0.0523 16 0.2136 17 0.0257 18 0.0422 24 0.0287 19 0.0155 20 0.0211 21 0.0323 31 0.0734 22 0.1748 23 0.0221 26 0.0357 25 0.0170 32 0.0152 27 0.0620 El proceso se repite con otras preguntas del censo hasta consolidar la tabla siguiente. predictors_censo_dam &lt;- readRDS(&quot;Recursos/Día1/Sesion2/Data/predictors_censo_dam.rds&quot;) tba(predictors_censo_dam) dam area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion 02 0.7718 0.4733 0.2773 0.1831 0.1531 0.0634 0.3350 0.2771 0.0540 0.0065 0.1587 0.7424 0.3233 0.1962 0.9594 0.1038 0.1229 0.0489 0.1050 0.7512 0.3066 0.0016 03 0.7128 0.4804 0.2643 0.1572 0.1489 0.0718 0.3470 0.2542 0.0493 0.0055 0.2531 0.6512 0.4074 0.4032 0.9705 0.1435 0.2050 0.0935 0.1047 0.7433 0.2683 0.0008 04 0.8345 0.4826 0.2756 0.1738 0.1454 0.0638 0.3169 0.2948 0.0827 0.0082 0.1426 0.7577 0.3386 0.2966 0.9441 0.0828 0.1261 0.0559 0.1652 0.8083 0.3060 0.0013 05 0.5977 0.4849 0.2509 0.1752 0.1748 0.0899 0.3471 0.3252 0.0625 0.0052 0.0624 0.8704 0.2923 0.3864 0.9466 0.0593 0.0901 0.0339 0.1133 0.8275 0.1455 0.0006 01 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 06 0.6626 0.4909 0.2671 0.1988 0.1736 0.0786 0.3140 0.3383 0.1038 0.0087 0.0656 0.5465 0.2116 0.3791 0.9119 0.0191 0.0955 0.0149 0.1718 0.8580 0.1501 0.0021 08 0.5144 0.4610 0.2648 0.1728 0.1625 0.0845 0.3822 0.2730 0.0440 0.0035 0.2241 0.5158 0.4239 0.4996 0.9655 0.0582 0.2128 0.0240 0.0816 0.7910 0.3178 0.0008 09 0.4535 0.4889 0.2733 0.2084 0.1694 0.0764 0.3125 0.3699 0.0840 0.0078 0.0496 0.6379 0.1732 0.3440 0.9114 0.0365 0.0806 0.0145 0.1391 0.8654 0.1709 0.0013 30 0.7412 0.4902 0.2722 0.1855 0.1624 0.0775 0.3308 0.3338 0.0696 0.0070 0.1346 0.4029 0.2879 0.3509 0.9449 0.0564 0.1727 0.0209 0.1269 0.8358 0.2080 0.0007 10 0.7996 0.4865 0.2658 0.1648 0.1418 0.0665 0.3214 0.2603 0.0485 0.0052 0.1983 0.7116 0.4010 0.3478 0.9788 0.1133 0.1710 0.1151 0.1016 0.7355 0.3088 0.0004 11 0.7784 0.4766 0.3001 0.2393 0.1250 0.0430 0.2986 0.3722 0.0650 0.0076 0.0499 0.1475 0.1943 0.2442 0.9006 0.0089 0.0871 0.0182 0.1158 0.8615 0.3985 0.0028 07 0.4828 0.4768 0.2380 0.1431 0.1527 0.0788 0.3287 0.1949 0.0315 0.0037 0.2423 0.5225 0.6287 0.5988 0.9826 0.3020 0.2668 0.0577 0.0710 0.6320 0.2933 0.0005 12 0.9425 0.5059 0.2821 0.2061 0.1466 0.0515 0.2810 0.3955 0.0794 0.0080 0.0482 0.7438 0.1351 0.1958 0.8864 0.0120 0.0710 0.0404 0.1455 0.8905 0.3271 0.0021 13 0.4696 0.4885 0.2762 0.2049 0.1606 0.0719 0.3142 0.3582 0.0781 0.0070 0.0482 0.4743 0.1600 0.2868 0.9109 0.0214 0.0301 0.0215 0.1327 0.8496 0.1545 0.0024 14 0.5252 0.4855 0.2700 0.1929 0.1729 0.0731 0.3258 0.3517 0.0765 0.0079 0.0914 0.6197 0.2136 0.4319 0.9307 0.0252 0.1265 0.0256 0.1335 0.8534 0.1747 0.0011 28 0.6797 0.4949 0.2690 0.2028 0.1597 0.0655 0.2883 0.3819 0.0855 0.0101 0.0385 0.7019 0.1433 0.1773 0.8864 0.0197 0.0217 0.0151 0.1560 0.8700 0.1483 0.0015 15 0.5312 0.4718 0.2685 0.1984 0.1764 0.0798 0.3103 0.3318 0.0519 0.0048 0.0963 0.8061 0.3138 0.4871 0.9562 0.0926 0.0724 0.0409 0.0894 0.7713 0.1734 0.0007 29 0.4939 0.4836 0.2656 0.1718 0.1537 0.0756 0.3438 0.3188 0.0526 0.0056 0.1584 0.3967 0.3666 0.5787 0.9690 0.0523 0.2579 0.0166 0.1000 0.8193 0.1801 0.0015 16 0.6441 0.4651 0.2738 0.1932 0.1334 0.0459 0.2589 0.2403 0.0316 0.0028 0.2475 0.6564 0.4743 0.4722 0.9689 0.2136 0.1851 0.1202 0.0647 0.6170 0.3718 0.0002 17 0.6810 0.5047 0.2665 0.1984 0.1549 0.0646 0.3707 0.3252 0.0460 0.0052 0.0597 0.6812 0.2013 0.2577 0.9238 0.0257 0.1211 0.0286 0.0852 0.8494 0.2445 0.0012 18 0.5839 0.4895 0.2699 0.2126 0.1689 0.0703 0.2875 0.3940 0.0727 0.0067 0.0508 0.6276 0.2385 0.2723 0.8766 0.0422 0.1088 0.0321 0.1231 0.8535 0.1761 0.0029 24 0.5628 0.4827 0.2754 0.1871 0.1662 0.0743 0.3198 0.3320 0.1000 0.0089 0.0888 0.5112 0.2304 0.4438 0.9395 0.0287 0.1069 0.0106 0.1725 0.8535 0.1312 0.0014 19 0.2891 0.4902 0.2568 0.2001 0.1839 0.0954 0.3037 0.3483 0.1097 0.0078 0.0336 0.3167 0.2653 0.5648 0.9315 0.0155 0.0943 0.0099 0.1731 0.8522 0.1199 0.0006 20 0.4354 0.4837 0.2811 0.2007 0.1554 0.0628 0.3080 0.3691 0.0595 0.0059 0.1084 0.5409 0.2254 0.4523 0.9463 0.0211 0.1233 0.0342 0.1070 0.8418 0.2265 0.0009 21 0.5186 0.4996 0.2807 0.1956 0.1451 0.0507 0.2931 0.3782 0.0783 0.0082 0.0598 0.6674 0.1860 0.3141 0.9105 0.0323 0.0689 0.0185 0.1483 0.8755 0.2328 0.0047 31 0.6292 0.4587 0.2556 0.2037 0.1761 0.0848 0.3785 0.2681 0.0602 0.0050 0.0938 0.8112 0.3792 0.3025 0.9654 0.0734 0.1714 0.0277 0.1021 0.7747 0.2180 0.0005 22 0.6009 0.4725 0.2559 0.1698 0.1695 0.0891 0.3482 0.2674 0.0642 0.0075 0.1496 0.7350 0.3965 0.3638 0.9565 0.1748 0.2050 0.0633 0.1236 0.7571 0.2152 0.0019 23 0.8408 0.5063 0.2861 0.1974 0.1522 0.0572 0.2840 0.4022 0.0817 0.0077 0.1011 0.6079 0.1780 0.2227 0.8981 0.0221 0.0610 0.0161 0.1481 0.8904 0.2771 0.0023 26 0.4795 0.4776 0.2632 0.1821 0.1770 0.1038 0.3340 0.3156 0.0767 0.0074 0.0542 0.7367 0.2924 0.4135 0.9223 0.0357 0.0765 0.0414 0.1274 0.8042 0.1157 0.0005 25 0.7561 0.5017 0.2795 0.2221 0.1583 0.0649 0.2843 0.3727 0.1106 0.0102 0.0246 0.8397 0.1335 0.1783 0.8308 0.0170 0.0179 0.0176 0.1831 0.8801 0.1668 0.0062 32 0.8780 0.5098 0.2870 0.2126 0.1502 0.0447 0.2409 0.4005 0.1291 0.0131 0.0348 0.6973 0.0795 0.2003 0.8280 0.0152 0.0365 0.0146 0.2311 0.9110 0.2110 0.0188 27 0.7917 0.4785 0.2810 0.2098 0.1501 0.0681 0.3121 0.3151 0.0817 0.0074 0.0623 0.8198 0.2460 0.1664 0.9299 0.0620 0.0491 0.0277 0.1404 0.7995 0.1739 0.0010 3.4.1 Mapas de las variables con información censal. temp2 &lt;- inner_join(shape[&quot;dam&quot;], predictors_censo_dam) for(ii in names(predictors_censo_dam[,-1])){ plot( temp2[ii], key.pos = 4, breaks = quantile(temp2[[ii]])) } "],["día-2---sesión-1--fundamentos-de-la-inferencia-bayesiana-en-r-y-stan.html", "Capítulo 4 Día 2 - Sesión 1- Fundamentos de la inferencia Bayesiana en R y STAN", " Capítulo 4 Día 2 - Sesión 1- Fundamentos de la inferencia Bayesiana en R y STAN El proyecto Manhattan y la estimación desagregada con encuestas de hogares "],["día-2---sesión-1--modelos-sintéticos-simples.html", "Capítulo 5 Día 2 - Sesión 1- Modelos sintéticos simples ", " Capítulo 5 Día 2 - Sesión 1- Modelos sintéticos simples "],["regla-de-bayes.html", "5.1 Regla de Bayes", " 5.1 Regla de Bayes En términos de inferencia para \\(\\boldsymbol{\\theta}\\), es necesario encontrar la distribución de los parámetros condicionada a la observación de los datos. Para este fin, es necesario definir la distribución conjunta de la variable de interés con el vector de parámetros. \\[ p(\\boldsymbol{\\theta},\\mathbf{Y})=p(\\boldsymbol{\\theta})p(\\mathbf{Y} \\mid \\boldsymbol{\\theta}) \\] La distribución \\(p(\\boldsymbol{\\theta})\\) se le conoce con el nombre de distribución previa. El término \\(p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})\\) es la distribución de muestreo, verosimilitud o distribución de los datos. La distribución del vector de parámetros condicionada a los datos observados está dada por \\[ p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})=\\frac{p(\\boldsymbol{\\theta},\\mathbf{Y})}{p(\\mathbf{Y})}=\\frac{p(\\boldsymbol{\\theta})p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})}{p(\\mathbf{Y})} \\] A la distribución \\(p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})\\) se le conoce con el nombre de distribución posterior. Nótese que el denominador no depende del vector de parámetros y considerando a los datos observados como fijos, corresponde a una constante y puede ser obviada. Por lo tanto, otra representación de la regla de Bayes está dada por \\[ p(\\boldsymbol{\\theta} \\mid \\mathbf{Y})\\propto p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})p(\\boldsymbol{\\theta}) \\] "],["inferencia-bayesiana..html", "5.2 Inferencia Bayesiana.", " 5.2 Inferencia Bayesiana. En términos de estimación, inferencia y predicción, el enfoque Bayesiano supone dos momentos o etapas: Antes de la recolección de las datos, en donde el investigador propone, basado en su conocimiento, experiencia o fuentes externas, una distribución de probabilidad previa para el parámetro de interés. Después de la recolección de los datos. Siguiendo el teorema de Bayes, el investigador actualiza su conocimiento acerca del comportamiento probabilístico del parámetro de interés mediante la distribución posterior de este. "],["modelos-uniparamétricos.html", "5.3 Modelos uniparamétricos", " 5.3 Modelos uniparamétricos Los modelos que están definidos en términos de un solo parámetro que pertenece al conjunto de los números reales se definen como modelos uniparamétricos. 5.3.1 Modelo de unidad: Bernoulli Suponga que \\(Y\\) es una variable aleatoria con distribución Bernoulli dada por: \\[ p(Y \\mid \\theta)=\\theta^y(1-\\theta)^{1-y}I_{\\{0,1\\}}(y) \\] Como el parámetro \\(\\theta\\) está restringido al espacio \\(\\Theta=[0,1]\\), entonces es posible formular varias opciones para la distribución previa del parámetro. En particular, la distribución uniforme restringida al intervalo \\([0,1]\\) o la distribución Beta parecen ser buenas opciones. Puesto que la distribución uniforme es un caso particular de la distribución Beta. Por lo tanto la distribución previa del parámetro \\(\\theta\\) estará dada por \\[ \\begin{equation} p(\\theta \\mid \\alpha,\\beta)= \\frac{1}{Beta(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}I_{[0,1]}(\\theta). \\end{equation} \\] y la distribución posterior del parámetro \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta \\mid Y \\sim Beta(y+\\alpha,\\beta-y+1) \\end{equation*} \\] Cuando se tiene una muestra aleatoria \\(Y_1,\\ldots,Y_n\\) de variables con distribución Bernoulli de parámetro \\(\\theta\\), entonces la distribución posterior del parámetro de interés es \\[ \\begin{equation*} \\theta \\mid Y_1,\\ldots,Y_n \\sim Beta\\left(\\sum_{i=1}^ny_i+\\alpha,\\beta-\\sum_{i=1}^ny_i+n\\right) \\end{equation*} \\] Obejtivo Estimar la proporción de personas que están por debajo de la linea pobreza. Es decir, \\[ P = \\frac{\\sum_{U}y_i}{N} \\] donde \\(y_i\\) toma el valor de 1 cuando el ingreso de la persona es menor a la linea de pobreza 0 en caso contrario El estimador de \\(P\\) esta dado por: \\[ \\hat{P} = \\frac{\\sum_{s}w_{i}y_{i}}{\\sum_{s}{w_{i} }} \\] con \\(w_i\\) el factor de expansión para la \\(i-ésima\\) observación. Además, y obtener \\(\\widehat{Var}\\left(\\hat{P}\\right)\\). 5.3.1.1 Práctica en R library(tidyverse) encuesta &lt;- readRDS(&quot;Recursos/Día2/Sesion1/Data/encuestaDOM21N1.rds&quot;) Sea \\(Y\\) la variable aleatoria \\[ Y_{i}=\\begin{cases} 1 &amp; ingreso&lt;lp\\\\ 0 &amp; ingreso\\geq lp \\end{cases} \\] El tamaño de la muestra es de 6796 en la dam 1 datay &lt;- encuesta %&gt;% filter(dam_ee == 1) %&gt;% transmute(y = ifelse(ingcorte &lt; lp, 1,0)) addmargins(table(datay$y)) 0 1 Sum 5063 1733 6796 Un grupo de estadístico experto decide utilizar una distribución previa Beta, definiendo los parámetros de la distribución previa como \\(Beta(\\alpha=1, \\beta=1)\\). La distribución posterior del parámetro de interés, que representa la probabilidad de estar por debajo de la linea de pobreza, es \\(Beta(1733 + 1, 1 - 1733 + 6796)=Beta(1734, 5064)\\) Figura 5.1: Distribución previa (línea roja) y distribución posterior (línea negra) La estimación del parámetro estaría dado por: \\[ E(X) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{1734}{1734+ 5064} = 0.255075 \\] luego, el intervalo de credibilidad para la distribución posterior es. n = length(datay$y) n1 = sum(datay$y) qbeta(c(0.025, 0.975), shape1 = 1 + n1, shape2 = 1 - n1 + n) ## [1] 0.2447824 0.2655041 5.3.1.2 Práctica en STAN En STAN es posible obtener el mismo tipo de inferencia creando cuatro cadenas cuya distribución de probabilidad coincide con la distribución posterior del ejemplo. data { // Entrada el modelo int&lt;lower=0&gt; n; // Numero de observaciones int y[n]; // Vector de longitud n real a; real b; } parameters { // Definir parámetro real&lt;lower=0, upper=1&gt; theta; } model { // Definir modelo y ~ bernoulli(theta); theta ~ beta(a, b); // Distribución previa } generated quantities { real ypred[n]; // vector de longitud n for (ii in 1:n){ ypred[ii] = bernoulli_rng(theta); } } Para compilar STAN debemos definir los parámetros de entrada sample_data &lt;- list(n = nrow(datay), y = datay$y, a = 1, b = 1) Para ejecutar STAN en R tenemos la librería rstan library(rstan) Bernoulli &lt;- &quot;Recursos/Día2/Sesion1/Data/modelosStan/1Bernoulli.stan&quot; options(mc.cores = parallel::detectCores()) rstan::rstan_options(auto_write = TRUE) # speed up running time model_Bernoulli &lt;- stan( file = Bernoulli, # Stan program data = sample_data, # named list of data verbose = FALSE, warmup = 500, # number of warmup iterations per chain iter = 1000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) saveRDS(model_Bernoulli, file = &quot;Recursos/Día2/Sesion1/0Recursos/Bernoulli/model_Bernoulli.rds&quot;) model_Bernoulli &lt;- readRDS(&quot;Recursos/Día2/Sesion1/0Recursos/Bernoulli/model_Bernoulli.rds&quot;) La estimación del parámetro \\(\\theta\\) es: tabla_Ber1 &lt;- summary(model_Bernoulli, pars = &quot;theta&quot;)$summary tabla_Ber1 %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 0.255 2e-04 0.0053 0.2445 0.2515 0.255 0.2584 0.2657 703.8891 1.0011 Para observar las cadenas compilamos las lineas de código library(posterior) library(ggplot2) temp &lt;- as_draws_df(as.array(model_Bernoulli,pars = &quot;theta&quot;)) p1 &lt;- ggplot(data = temp, aes(x = theta))+ geom_density(color = &quot;blue&quot;, size = 2) + stat_function(fun = posterior1, args = list(y = datay$y), size = 2) + theme_bw(base_size = 20) + labs(x = latex2exp::TeX(&quot;\\\\theta&quot;), y = latex2exp::TeX(&quot;f(\\\\theta)&quot;)) #ggsave(filename = &quot;Recursos/Día2/Sesion1/0Recursos/Bernoulli/Bernoulli2.png&quot;,plot = p1) p1 Figura 5.2: Resultado con STAN (línea azul) y posterior teórica (línea negra) Para validar las cadenas library(bayesplot) library(patchwork) posterior_theta &lt;- as.array(model_Bernoulli, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / traceplot(model_Bernoulli, pars = &quot;theta&quot;, inc_warmup = T) Predicción de \\(Y\\) en cada una de las iteraciones de las cadenas. y_pred_B &lt;- as.array(model_Bernoulli, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, 1:n] ppc_dens_overlay(y = datay$y, y_pred2) 5.3.2 Modelo de área: Binomial Cuando se dispone de una muestra aleatoria de variables con distribución Bernoulli \\(Y_1,\\ldots,Y_n\\), la inferencia Bayesiana se puede llevar a cabo usando la distribución Binomial, puesto que es bien sabido que la suma de variables aleatorias Bernoulli \\[ \\begin{equation*} S=\\sum_{i=1}^nY_i \\end{equation*} \\] sigue una distribución Binomial. Es decir: \\[ \\begin{equation} p(S \\mid \\theta)=\\binom{n}{s}\\theta^s(1-\\theta)^{n-s}I_{\\{0,1,\\ldots,n\\}}(s), \\end{equation} \\] Nótese que la distribución Binomial es un caso general para la distribución Bernoulli, cuando \\(n=1\\). Por lo tanto es natural suponer que distribución previa del parámetro \\(\\theta\\) estará dada por \\[ \\begin{equation} p(\\theta \\mid \\alpha,\\beta)= \\frac{1}{Beta(\\alpha,\\beta)}\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}I_{[0,1]}(\\theta). \\end{equation} \\] La distribución posterior del parámetro \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta \\mid S \\sim Beta(s+\\alpha,\\beta-s+n) \\end{equation*} \\] Ahora, cuando se tiene una sucesión de variables aleatorias \\(S_1,\\ldots,S_d, \\ldots,S_D\\) independientes y con distribución \\(Binomial(n_d,\\theta_d)\\) para \\(d=1,\\ldots,K\\), entonces la distribución posterior del parámetro de interés \\(\\theta_d\\) es \\[ \\begin{equation*} \\theta_d \\mid s_d \\sim Beta\\left(s_d+\\alpha,\\ \\beta+ n_d- s_d\\right) \\end{equation*} \\] Obejtivo Estimar la proporción de personas que están por debajo de la linea pobreza en el \\(d-ésimo\\) dominio. Es decir, \\[ P_d = \\frac{\\sum_{U_d}y_{di}}{N_d} \\] donde \\(y_i\\) toma el valor de 1 cuando el ingreso de la persona es menor a la linea de pobreza 0 en caso contrario. El estimador de \\(P\\) esta dado por: \\[ \\hat{P_d} = \\frac{\\sum_{s_d}w_{di}y_{di}}{\\sum_{s_d}{w_{di} }} \\] con \\(w_{di}\\) el factor de expansión para la \\(i-ésima\\) observación en el \\(d-ésimo\\) dominio. 5.3.2.1 Práctica en STAN Sea \\(S_k\\) el conteo de personas en condición de pobreza en el \\(k-ésimo\\) departamento en la muestra. dataS &lt;- encuesta %&gt;% transmute( dam = dam_ee, y = ifelse(ingcorte &lt; lp, 1,0) ) %&gt;% group_by(dam) %&gt;% summarise(nd = n(), #Número de ensayos Sd = sum(y) #Número de éxito ) tba(dataS) dam nd Sd 1 6796 1733 2 1556 397 3 2013 979 4 2912 1093 5 466 125 6 1649 295 7 821 365 8 1199 268 9 2012 235 10 1200 561 11 2678 432 12 2543 744 13 2534 416 14 780 195 15 773 96 16 466 203 17 1059 214 18 2907 381 19 460 9 20 669 162 21 3381 1012 22 2318 625 23 2260 368 24 909 138 25 9011 1840 26 401 55 27 963 171 28 923 157 29 1619 675 30 478 84 31 346 80 32 17969 4554 Creando código de STAN data { int&lt;lower=0&gt; K; // Número de provincia int&lt;lower=0&gt; n[K]; // Número de ensayos int&lt;lower=0&gt; s[K]; // Número de éxitos real a; real b; } parameters { real&lt;lower=0, upper=1&gt; theta[K]; // theta_d|s_d } model { for(kk in 1:K) { s[kk] ~ binomial(n[kk], theta[kk]); } to_vector(theta) ~ beta(a, b); } generated quantities { real spred[K]; // vector de longitud K for(kk in 1:K){ spred[kk] = binomial_rng(n[kk],theta[kk]); } } Preparando el código de STAN Binomial2 &lt;- &quot;Recursos/Día2/Sesion1/Data/modelosStan/3Binomial.stan&quot; Organizando datos para STAN sample_data &lt;- list(K = nrow(dataS), s = dataS$Sd, n = dataS$nd, a = 1, b = 1) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_Binomial2 &lt;- stan( file = Binomial2, # Stan program data = sample_data, # named list of data verbose = FALSE, warmup = 500, # number of warmup iterations per chain iter = 1000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) saveRDS(model_Binomial2, &quot;Recursos/Día2/Sesion1/0Recursos/Binomial/model_Binomial2.rds&quot;) model_Binomial2 &lt;- readRDS(&quot;Recursos/Día2/Sesion1/0Recursos/Binomial/model_Binomial2.rds&quot;) La estimación del parámetro \\(\\theta\\) es: tabla_Bin1 &lt;-summary(model_Binomial2, pars = &quot;theta&quot;)$summary tabla_Bin1 %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta[1] 0.2550 1e-04 0.0054 0.2443 0.2514 0.2549 0.2586 0.2663 5541.426 0.9984 theta[2] 0.2557 2e-04 0.0111 0.2346 0.2480 0.2555 0.2633 0.2775 4685.553 0.9988 theta[3] 0.4863 2e-04 0.0112 0.4639 0.4790 0.4863 0.4937 0.5081 4275.709 0.9995 theta[4] 0.3754 1e-04 0.0090 0.3578 0.3692 0.3756 0.3815 0.3930 4356.266 0.9993 theta[5] 0.2688 3e-04 0.0210 0.2310 0.2543 0.2682 0.2831 0.3099 5505.855 0.9987 theta[6] 0.1792 1e-04 0.0095 0.1612 0.1729 0.1790 0.1858 0.1983 5539.281 0.9985 theta[7] 0.4447 3e-04 0.0172 0.4108 0.4336 0.4445 0.4562 0.4795 4289.643 0.9989 theta[8] 0.2240 2e-04 0.0115 0.2019 0.2161 0.2238 0.2315 0.2470 4261.208 0.9993 theta[9] 0.1172 1e-04 0.0077 0.1023 0.1121 0.1170 0.1222 0.1328 3835.345 0.9994 theta[10] 0.4673 2e-04 0.0142 0.4402 0.4577 0.4671 0.4769 0.4949 5121.700 0.9992 theta[11] 0.1617 1e-04 0.0071 0.1483 0.1568 0.1614 0.1667 0.1760 5501.146 0.9983 theta[12] 0.2930 1e-04 0.0089 0.2759 0.2870 0.2928 0.2988 0.3105 4834.824 0.9987 theta[13] 0.1644 1e-04 0.0073 0.1503 0.1595 0.1643 0.1691 0.1788 5452.961 0.9981 theta[14] 0.2505 2e-04 0.0148 0.2216 0.2404 0.2505 0.2598 0.2813 3949.950 0.9985 theta[15] 0.1253 2e-04 0.0120 0.1024 0.1170 0.1250 0.1334 0.1484 3561.371 0.9985 theta[16] 0.4359 3e-04 0.0228 0.3920 0.4206 0.4356 0.4507 0.4811 4413.229 0.9989 theta[17] 0.2030 2e-04 0.0122 0.1803 0.1949 0.2024 0.2106 0.2285 3553.277 0.9984 theta[18] 0.1313 1e-04 0.0061 0.1193 0.1272 0.1313 0.1355 0.1428 3265.019 0.9987 theta[19] 0.0217 1e-04 0.0068 0.0105 0.0168 0.0211 0.0258 0.0367 4589.526 0.9989 theta[20] 0.2427 3e-04 0.0163 0.2119 0.2310 0.2426 0.2539 0.2754 3692.533 0.9985 theta[21] 0.2995 1e-04 0.0081 0.2833 0.2941 0.2995 0.3047 0.3152 4654.262 0.9994 theta[22] 0.2701 1e-04 0.0091 0.2520 0.2642 0.2701 0.2759 0.2884 4987.638 0.9986 theta[23] 0.1630 1e-04 0.0080 0.1477 0.1573 0.1628 0.1684 0.1788 3848.725 0.9985 theta[24] 0.1524 2e-04 0.0114 0.1310 0.1442 0.1522 0.1603 0.1752 3602.961 0.9989 theta[25] 0.2042 1e-04 0.0041 0.1964 0.2014 0.2041 0.2070 0.2122 4184.041 0.9995 theta[26] 0.1388 3e-04 0.0177 0.1069 0.1265 0.1381 0.1505 0.1760 4957.831 0.9985 theta[27] 0.1783 2e-04 0.0118 0.1560 0.1700 0.1783 0.1863 0.2028 4550.942 0.9987 theta[28] 0.1706 2e-04 0.0125 0.1467 0.1618 0.1705 0.1796 0.1950 4629.408 0.9993 theta[29] 0.4171 2e-04 0.0126 0.3926 0.4084 0.4168 0.4257 0.4418 5023.648 0.9989 theta[30] 0.1772 3e-04 0.0176 0.1442 0.1651 0.1764 0.1884 0.2137 4571.020 0.9988 theta[31] 0.2328 4e-04 0.0227 0.1895 0.2177 0.2324 0.2477 0.2811 4051.155 0.9993 theta[32] 0.2535 1e-04 0.0032 0.2473 0.2514 0.2535 0.2557 0.2597 3530.149 0.9992 Para validar las cadenas (s1 &lt;- mcmc_areas(as.array(model_Binomial2, pars = &quot;theta&quot;))) # ggsave(filename = &quot;Recursos/Día2/Sesion1/0Recursos/Binomial/Binomial1.png&quot;,plot = s1) (s2 &lt;- mcmc_trace(as.array(model_Binomial2, pars = &quot;theta&quot;))) # ggsave(filename = &quot;Recursos/Día2/Sesion1/0Recursos/Binomial/Binomial2.png&quot;, # plot = s2,width = 20, height = 20, units = &quot;cm&quot;) y_pred_B &lt;- as.array(model_Binomial2, pars = &quot;spred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 200) y_pred2 &lt;- y_pred_B[rowsrandom, ] g1 &lt;- ggplot(data = dataS, aes(x = Sd))+ geom_histogram(aes(y = ..density..)) + geom_density(size = 2, color = &quot;blue&quot;) + labs(y = &quot;&quot;)+ theme_bw(10) + yaxis_title(FALSE) + xaxis_title(FALSE) + yaxis_text(FALSE) + yaxis_ticks(FALSE) g2 &lt;- ppc_dens_overlay(y = dataS$Sd, y_pred2) g1/g2 5.3.3 Modelo de unidad: Normal con media desconocida Suponga que \\(Y_1,\\cdots,Y_n\\) son variables independientes e idénticamente distribuidos con distribución \\(Normal(\\theta,\\sigma^2)\\) con \\(\\theta\\) desconocido pero \\(\\sigma^2\\) conocido. De esta forma, la función de verosimilitud de los datos está dada por \\[ \\begin{align*} p(\\mathbf{Y} \\mid \\theta) &amp;=\\prod_{i=1}^n\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_i-\\theta)^2\\right\\}I_\\mathbb{R}(y) \\\\ &amp;=(2\\pi\\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(y_i-\\theta)^2\\right\\} \\end{align*} \\] Como el parámetro \\(\\theta\\) puede tomar cualquier valor en los reales, es posible asignarle una distribución previa \\(\\theta \\sim Normal(\\mu,\\tau^2)\\). Bajo este marco de referencia se tienen los siguientes resultados La distribución posterior del parámetro de interés \\(\\theta\\) sigue una distribución \\[ \\begin{equation*} \\theta|\\mathbf{Y} \\sim Normal(\\mu_n,\\tau^2_n) \\end{equation*} \\] En donde \\[ \\begin{equation} \\mu_n=\\frac{\\frac{n}{\\sigma^2}\\bar{Y}+\\frac{1}{\\tau^2}\\mu}{\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}} \\ \\ \\ \\ \\ \\ \\ \\text{y} \\ \\ \\ \\ \\ \\ \\ \\tau_n^2=\\left(\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}\\right)^{-1} \\end{equation} \\] Obejtivo Estimar el ingreso medio de la población, es decir, \\[ \\bar{Y} = \\frac{\\sum_Uy_i}{N} \\] donde, \\(y_i\\) es el ingreso de las personas. El estimador de \\(\\bar{Y}\\) esta dado por \\[ \\hat{\\bar{Y}} = \\frac{\\sum_{s}w_{i}y_{i}}{\\sum_s{w_i}} \\] y obtener \\(\\widehat{Var}\\left(\\hat{\\bar{Y}}\\right)\\). 5.3.3.1 Práctica en STAN Sea \\(Y\\) el logaritmo del ingreso dataNormal &lt;- encuesta %&gt;% transmute( dam_ee , logIngreso = log(ingcorte +1)) %&gt;% filter(dam_ee == 1) #3 media &lt;- mean(dataNormal$logIngreso) Sd &lt;- sd(dataNormal$logIngreso) g1 &lt;- ggplot(dataNormal,aes(x = logIngreso))+ geom_density(size = 2, color = &quot;blue&quot;) + stat_function(fun =dnorm, args = list(mean = media, sd = Sd), size =2) + theme_bw(base_size = 20) + labs(y = &quot;&quot;, x = (&quot;Log(Ingreso)&quot;)) g2 &lt;- ggplot(dataNormal, aes(sample = logIngreso)) + stat_qq() + stat_qq_line() + theme_bw(base_size = 20) g1|g2 Creando código de STAN data { int&lt;lower=0&gt; n; // Número de observaciones real y[n]; // LogIngreso real &lt;lower=0&gt; Sigma; // Desviación estándar } parameters { real theta; } model { y ~ normal(theta, Sigma); theta ~ normal(0, 1000); // Distribución previa } generated quantities { real ypred[n]; // Vector de longitud n for(kk in 1:n){ ypred[kk] = normal_rng(theta,Sigma); } } Preparando el código de STAN NormalMedia &lt;- &quot;Recursos/Día2/Sesion1/Data/modelosStan/4NormalMedia.stan&quot; Organizando datos para STAN sample_data &lt;- list(n = nrow(dataNormal), Sigma = sd(dataNormal$logIngreso), y = dataNormal$logIngreso) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_NormalMedia &lt;- stan( file = NormalMedia, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_NormalMedia, &quot;Recursos/Día2/Sesion1/0Recursos/Normal/model_NormalMedia.rds&quot;) model_NormalMedia &lt;- readRDS(&quot;Recursos/Día2/Sesion1/0Recursos/Normal/model_NormalMedia.rds&quot;) La estimación del parámetro \\(\\theta\\) es: tabla_Nor1 &lt;- summary(model_NormalMedia, pars = &quot;theta&quot;)$summary tabla_Nor1 %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 9.0982 4e-04 0.0095 9.0786 9.0917 9.0985 9.1046 9.1167 654.8346 1.0008 posterior_theta &lt;- as.array(model_NormalMedia, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) y_pred_B &lt;- as.array(model_NormalMedia, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(dataNormal$logIngreso), y_pred2)/ ppc_dens_overlay(y = exp(as.numeric(dataNormal$logIngreso))-1, exp(y_pred2)-1) + xlim(0,240000) "],["modelos-multiparamétricos.html", "5.4 Modelos multiparamétricos", " 5.4 Modelos multiparamétricos La distribución normal univariada que tiene dos parámetros: la media \\(\\theta\\) y la varianza \\(\\sigma^2\\). La distribución multinomial cuyo parámetro es un vector de probabilidades \\(\\boldsymbol{\\theta}\\). 5.4.1 Modelo de unidad: Normal con media y varianza desconocida Supongamos que se dispone de realizaciones de un conjunto de variables independientes e idénticamente distribuidas \\(Y_1,\\cdots,Y_n\\sim N(\\theta,\\sigma^2)\\). Cuando se desconoce tanto la media como la varianza de la distribución es necesario plantear diversos enfoques y situarse en el más conveniente, según el contexto del problema. En términos de la asignación de las distribuciones previas para \\(\\theta\\) y \\(\\sigma^2\\) es posible: Suponer que la distribución previa \\(p(\\theta)\\) es independiente de la distribución previa \\(p(\\sigma^2)\\) y que ambas distribuciones son informativas. Suponer que la distribución previa \\(p(\\theta)\\) es independiente de la distribución previa \\(p(\\sigma^2)\\) y que ambas distribuciones son no informativas. Suponer que la distribución previa para \\(\\theta\\) depende de \\(\\sigma^2\\) y escribirla como \\(p(\\theta \\mid \\sigma^2)\\), mientras que la distribución previa de \\(\\sigma^2\\) no depende de \\(\\theta\\) y se puede escribir como \\(p(\\sigma^2)\\). La distribución previa para el parámetro \\(\\theta\\) será \\[ \\begin{equation*} \\theta \\sim Normal(0,10000) \\end{equation*} \\] Y la distribución previa para el parámetro \\(\\sigma^2\\) será \\[ \\begin{equation*} \\sigma^2 \\sim IG(0.0001,0.0001) \\end{equation*} \\] La distribución posterior condicional de \\(\\theta\\) es \\[ \\begin{equation} \\theta \\mid \\sigma^2,\\mathbf{Y} \\sim Normal(\\mu_n,\\tau_n^2) \\end{equation} \\] En donde las expresiones para \\(\\mu_n\\) y \\(\\tau_n^2\\) están dados previamente. En el siguiente enlace enconará el libro: Modelos Bayesianos con R y STAN donde puede profundizar en el desarrollo matemático de los resultados anteriores. Obejtivo Estimar el ingreso medio de las personas, es decir, \\[ \\bar{Y} = \\frac{\\sum_Uy_i}{N} \\] donde, \\(y_i\\) es el ingreso de las personas. El estimador de \\(\\bar{Y}\\) esta dado por \\[ \\hat{\\bar{Y}} = \\frac{\\sum_{s}w_{i}y_{i}}{\\sum_s{w_i}} \\] y obtener \\(\\widehat{Var}\\left(\\hat{\\bar{Y}}\\right)\\). 5.4.1.1 Práctica en STAN Sea \\(Y\\) el logaritmo del ingreso dataNormal &lt;- encuesta %&gt;% transmute(dam_ee, logIngreso = log(ingcorte +1)) %&gt;% filter(dam_ee == 1) Creando código de STAN data { int&lt;lower=0&gt; n; real y[n]; } parameters { real sigma; real theta; } transformed parameters { real sigma2; sigma2 = pow(sigma, 2); } model { y ~ normal(theta, sigma); theta ~ normal(0, 1000); sigma2 ~ inv_gamma(0.001, 0.001); } generated quantities { real ypred[n]; // vector de longitud n for(kk in 1:n){ ypred[kk] = normal_rng(theta,sigma); } } Preparando el código de STAN NormalMeanVar &lt;- &quot;Recursos/Día2/Sesion1/Data/modelosStan/5NormalMeanVar.stan&quot; Organizando datos para STAN sample_data &lt;- list(n = nrow(dataNormal), y = dataNormal$logIngreso) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_NormalMedia &lt;- stan( file = NormalMeanVar, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_NormalMedia,&quot;Recursos/Día2/Sesion1/0Recursos/Normal/model_NormalMedia2.rds&quot;) model_NormalMedia &lt;- readRDS(&quot;Recursos/Día2/Sesion1/0Recursos/Normal/model_NormalMedia2.rds&quot;) La estimación del parámetro \\(\\theta\\) y \\(\\sigma^2\\) es: tabla_Nor2 &lt;- summary(model_NormalMedia, pars = c(&quot;theta&quot;, &quot;sigma2&quot;, &quot;sigma&quot;))$summary tabla_Nor2 %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat theta 9.0991 3e-04 0.0099 9.0801 9.0924 9.0989 9.1057 9.1189 1569.114 1.0002 sigma2 0.6318 2e-04 0.0108 0.6101 0.6244 0.6314 0.6392 0.6531 1935.498 0.9991 sigma 0.7948 2e-04 0.0068 0.7811 0.7902 0.7946 0.7995 0.8081 1935.196 0.9991 posterior_theta &lt;- as.array(model_NormalMedia, pars = &quot;theta&quot;) (mcmc_dens_chains(posterior_theta) + mcmc_areas(posterior_theta) ) / mcmc_trace(posterior_theta) posterior_sigma2 &lt;- as.array(model_NormalMedia, pars = &quot;sigma2&quot;) (mcmc_dens_chains(posterior_sigma2) + mcmc_areas(posterior_sigma2) ) / mcmc_trace(posterior_sigma2) posterior_sigma &lt;- as.array(model_NormalMedia, pars = &quot;sigma&quot;) (mcmc_dens_chains(posterior_sigma) + mcmc_areas(posterior_sigma) ) / mcmc_trace(posterior_sigma) y_pred_B &lt;- as.array(model_NormalMedia, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(exp(dataNormal$logIngreso)-1), y_pred2) + xlim(0,240000) 5.4.2 Modelo Multinomial En esta sección discutimos el modelamiento bayesiano de datos provenientes de una distribución multinomial que corresponde a una extensión multivariada de la distribución binomial. Suponga que \\(\\textbf{Y}=(Y_1,\\ldots,Y_p)&#39;\\) es un vector aleatorio con distribución multinomial, así, su distribución está parametrizada por el vector \\(\\boldsymbol{\\theta}=(\\theta_1,\\ldots,\\theta_p)&#39;\\) y está dada por la siguiente expresión \\[ \\begin{equation} p(\\mathbf{Y} \\mid \\boldsymbol{\\theta})=\\binom{n}{y_1,\\ldots,y_p}\\prod_{i=1}^p\\theta_i^{y_i} \\ \\ \\ \\ \\ \\theta_i&gt;0 \\texttt{ , } \\sum_{i=1}^py_i=n \\texttt{ y } \\sum_{i=1}^p\\theta_i=1 \\end{equation} \\] Donde \\[ \\begin{equation*} \\binom{n}{y_1,\\ldots,y_p}=\\frac{n!}{y_1!\\cdots y_p!}. \\end{equation*} \\] Como cada parámetro \\(\\theta_i\\) está restringido al espacio \\(\\Theta=[0,1]\\), entonces es posible asignar a la distribución de Dirichlet como la distribución previa del vector de parámetros. Por lo tanto la distribución previa del vector de parámetros \\(\\boldsymbol{\\theta}\\), parametrizada por el vector de hiperparámetros \\(\\boldsymbol{\\alpha}=(\\alpha_1,\\ldots,\\alpha_p)&#39;\\), está dada por \\[ \\begin{equation} p(\\boldsymbol{\\theta} \\mid \\boldsymbol{\\alpha})=\\frac{\\Gamma(\\alpha_1+\\cdots+\\alpha_p)}{\\Gamma(\\alpha_1)\\cdots\\Gamma(\\alpha_p)} \\prod_{i=1}^p\\theta_i^{\\alpha_i-1} \\ \\ \\ \\ \\ \\alpha_i&gt;0 \\texttt{ y } \\sum_{i=1}^p\\theta_i=1 \\end{equation} \\] La distribución posterior del parámetro \\(\\boldsymbol{\\theta}\\) sigue una distribución \\(Dirichlet(y_1+\\alpha_1,\\ldots,y_p+\\alpha_p)\\) Obejtivo Sea \\(N_1\\) el número de personas ocupadas, \\(N_2\\) Número de personas desocupadas, \\(N_3\\) es el número de personas inactivas en la población y \\(N = N_1 +N_2 + N_3\\). Entonces el objetivo es estimar el vector de parámetros \\(\\boldsymbol{P}=\\left(P_{1},P_{2},P_{3}\\right)\\), con \\(P_{k}=\\frac{N_{k}}{N}\\), para \\(k=1,2,3\\), El estimador de \\(\\boldsymbol{P}\\) esta dado por \\[ \\hat{\\boldsymbol{P}} =\\left(\\hat{P}_{1},\\hat{P}_{2},\\hat{P}_{3}\\right) \\] donde, \\[ \\hat{P}_{k} = \\frac{\\sum_{s}w_{i}y_{ik}}{\\sum_s{w_i}} = \\frac{\\hat{N}_k}{\\hat{N}} \\] y \\(y_{ik}\\) toma el valor 1 cuando la \\(i-ésima\\) persona responde la \\(k-ésima\\) categoría (Ocupado o Desocupado o Inactivo). Además, obtener \\(\\widehat{Var}\\left(\\hat{P}_{k}\\right)\\). 5.4.2.1 Práctica en STAN Sea \\(Y\\) condición de actividad laboral dataMult &lt;- encuesta %&gt;% filter(condact3 %in% 1:3) %&gt;% transmute( empleo = as_factor(condact3)) %&gt;% group_by(empleo) %&gt;% tally() %&gt;% mutate(theta = n/sum(n)) tba(dataMult) empleo n theta Ocupado 33047 0.5267 Desocupado 2371 0.0378 Inactivo 27324 0.4355 donde 1 corresponde a Ocupado, 2 son los Desocupado y 3 son Inactivo Creando código de STAN data { int&lt;lower=0&gt; k; // Número de cátegoria int y[k]; // Número de exitos vector[k] alpha; // Parámetro de las distribción previa } parameters { simplex[k] theta; } transformed parameters { real delta; // Tasa de desocupación delta = theta[2]/ (theta[2] + theta[1]); // (Desocupado)/(Desocupado + Ocupado) } model { y ~ multinomial(theta); theta ~ dirichlet(alpha); } generated quantities { int ypred[k]; ypred = multinomial_rng(theta, sum(y)); } Preparando el código de STAN Multinom &lt;- &quot;Recursos/Día2/Sesion1/Data/modelosStan/6Multinom.stan&quot; Organizando datos para STAN sample_data &lt;- list(k = nrow(dataMult), y = dataMult$n, alpha = c(0.5, 0.5, 0.5)) Para ejecutar STAN en R tenemos la librería rstan options(mc.cores = parallel::detectCores()) model_Multinom &lt;- stan( file = Multinom, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_Multinom, &quot;Recursos/Día2/Sesion1/0Recursos/Multinomial/model_Multinom.rds&quot;) model_Multinom &lt;- readRDS(&quot;Recursos/Día2/Sesion1/0Recursos/Multinomial/model_Multinom.rds&quot;) La estimación del parámetro \\(\\theta\\) y \\(\\delta\\) es: tabla_Mul1 &lt;- summary(model_Multinom, pars = c(&quot;delta&quot;, &quot;theta&quot;))$summary tabla_Mul1 %&gt;% tba() mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat delta 0.0670 0 0.0013 0.0644 0.0661 0.0670 0.0679 0.0695 1414.051 1.0014 theta[1] 0.5268 0 0.0019 0.5231 0.5255 0.5268 0.5280 0.5305 1692.834 0.9989 theta[2] 0.0378 0 0.0008 0.0363 0.0373 0.0378 0.0383 0.0393 1379.738 1.0018 theta[3] 0.4354 0 0.0019 0.4317 0.4341 0.4354 0.4367 0.4392 1633.676 0.9997 posterior_theta1 &lt;- as.array(model_Multinom, pars = &quot;theta[1]&quot;) (mcmc_dens_chains(posterior_theta1) + mcmc_areas(posterior_theta1) ) / mcmc_trace(posterior_theta1) posterior_theta2 &lt;- as.array(model_Multinom, pars = &quot;theta[2]&quot;) (mcmc_dens_chains(posterior_theta2) + mcmc_areas(posterior_theta2) ) / mcmc_trace(posterior_theta2) posterior_theta3 &lt;- as.array(model_Multinom, pars = &quot;theta[3]&quot;) (mcmc_dens_chains(posterior_theta3) + mcmc_areas(posterior_theta3) ) / mcmc_trace(posterior_theta3) posterior_delta &lt;- as.array(model_Multinom, pars = &quot;delta&quot;) (mcmc_dens_chains(posterior_delta) + mcmc_areas(posterior_delta) ) / mcmc_trace(posterior_delta) La imagen es muy pesada no se carga al repositorio. n &lt;- nrow(dataMult) y_pred_B &lt;- as.array(model_Multinom, pars = &quot;ypred&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, 1:n] ppc_dens_overlay(y = as.numeric(dataMult$n), y_pred2) "],["día-2---sesión-1--estimaciones-encft-y-función-generalizada-de-varianza.html", "Capítulo 6 Día 2 - Sesión 1- Estimaciones ENCFT y Función Generalizada de Varianza", " Capítulo 6 Día 2 - Sesión 1- Estimaciones ENCFT y Función Generalizada de Varianza Uno de los insumos más importantes en el modelo de áreas es la varianza del estimador directo, a nivel de dominio, la cual no puede calcularse de ningún modo. En correspondencia, este valor debe estimarse desde los datos recolectados en cada dominio. Sin embargo, en dominios en las que se cuenta con un tamaño de muestra muy pequeño, estas estimaciones no tendrán un buen comportamiento. Por ende, es muy útil utilizar un modelo de suavizamiento de las varianzas para eliminar el ruido y la volatilidad de estas estimaciones y extraer la verdadera señal del proceso Hidiroglou (2019) afirma que \\(E_{\\mathscr{MP}}\\left(\\hat{\\theta}^{dir}_d\\right)=\\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta}\\) y \\(V_{\\mathscr{MP}}\\left(\\hat{\\theta}^{dir}_d\\right)=\\sigma_{u}^2+\\tilde{\\sigma}^2_{d}\\), en donde el subíndice \\(\\mathscr{MP}\\) hace referencia a la inferencia doble que se debe tener en cuenta en este tipo de ajustes y define la medida de probabilidad conjunta entre el modelo y el diseño de muestreo. \\(\\mathscr{M}\\) hace referencia a la medida de probabilidad inducida por el modelamiento y la inclusión de las covariables auxiliares (\\(\\boldsymbol{x}_{d}\\)). \\(\\mathscr{P}\\) hace referencia a la medida de probabilidad inducida por el diseño de muestreo complejo que induce las estimaciones directas. La solución que acá se plantea se conoce con el nombre de Función Generalizada de Varianza, la cual consiste en ajustar un modelo log-lineal a la varianza directa estimada. Partiendo del hecho de que se tiene acceso a un estimador insesgado de \\(\\sigma^2\\), denotado por \\(\\hat{\\sigma}^2\\) se tiene que: \\[ E_{\\mathscr{MP}}\\left(\\hat{\\sigma}_{d}^{2}\\right)=E_{\\mathscr{M}}\\left(E_{\\mathscr{P}}\\left(\\hat{\\sigma}_{d}^{2}\\right)\\right)=E_{\\mathscr{M}}\\left(\\sigma_{d}^{2}\\right)=\\tilde{\\sigma}_{d}^{2} \\] La anterior igualdad puede interpretarse como que un estimador insesgado y simple de \\(\\tilde{\\sigma}_{d}^{2}\\) puede ser \\(\\hat{\\sigma}_{d}^{2}\\). Sin embargo, este estimador de muestreo es inestable cuando el tamaño de muestra es pequeño, que es justo el paradigma dominante en la estimación de áreas pequeñas. Rivest and Belmonte (2000) consideran modelos de suavizamiento para la estimación de las varianzas directas definidos de la siguiente manera: \\[ \\log\\left(\\hat{\\sigma}_{d}^{2}\\right)=\\boldsymbol{z}_{d}^{T}\\boldsymbol{\\alpha}+\\boldsymbol{\\varepsilon}_{d} \\] En donde \\(\\boldsymbol{z}_{d}\\) es un vector de covariables explicativas que son funciones de \\(\\boldsymbol{x}_{d}\\), \\(\\boldsymbol{\\alpha}\\) es un vector de parámetros que deben ser estimados, \\(\\boldsymbol{\\varepsilon}_{d}\\) son errores aleatorios con media cero y varianza constante, que se asumen idénticamente distribuidos condicionalmente sobre \\(\\boldsymbol{z}_{d}\\). Del anterior modelo, la estimación suavizada de la varianza de muestreo está dada por: \\[ \\tilde{\\sigma}_{d}^{2}=E_{\\mathscr{MP}}\\left(\\sigma_{d}^{2}\\right)=\\exp\\left(\\boldsymbol{z}_{d}^{T}\\boldsymbol{\\alpha}\\right)\\times\\Delta \\] En donde, \\(E_{\\mathscr{MP}}\\left(\\varepsilon_{d}\\right)=\\Delta\\). No hay necesidad de especificar una distribución paramétrica para los errores de este modelo. Al utilizar el método de los momentos, se tiene el siguiente estimador insesgado para \\(\\Delta\\): \\[ \\hat{\\Delta}=\\frac{\\sum_{d=1}^{D}\\hat{\\sigma}_{d}^{2}}{\\sum_{d=1}^{D}\\exp\\left(\\boldsymbol{z}_{d}^{T}\\boldsymbol{\\alpha}\\right)} \\] De la misma forma, al utilizar los procedimientos estándar en una regresión lineal, la estimación del coeficiente de parámetros de regresión está dada por la siguiente expresión: \\[ \\hat{\\boldsymbol{\\alpha}}=\\left(\\sum_{d=1}^{D}\\boldsymbol{z}_{d}\\boldsymbol{z}_{d}^{T}\\right)^{-1}\\sum_{d=1}^{D}\\boldsymbol{z}_{d}\\log\\left(\\hat{\\sigma}_{d}^{2}\\right) \\] Por último, el estimador suavizado de la varianza muestral está definido por: \\[ \\hat{\\tilde{\\sigma}}_{d}^{2}=\\exp\\left(\\boldsymbol{z}_{d}^{T}\\hat{\\boldsymbol{\\alpha}}\\right)\\hat{\\Delta} \\] "],["datos-de-la-encuesta.html", "6.1 Datos de la encuesta", " 6.1 Datos de la encuesta El siguiente bloque de código utiliza varias librerías en R (tidyverse y magrittr), así como también utiliza una función definida en otro archivo (source(“0Recursos/0Source_FH.R”)). Luego, el código carga la encuesta que esta almacenada en un archivo de datos en formato RDS y utiliza la función %&gt;% para encadenar una serie de transformaciones en los datos: transmute() se utiliza para seleccionar y renombrar columnas. En este caso, se seleccionan las columnas dam_ee, _fep,_upm y _estrato, y se re-nombran a dam, wkx, upm y _estrato, respectivamente. Se crea una nueva variable llamada pobreza que se establece en 1 si la variable ingcorte(ingreso percapital) es menor que la variable lp, y en 0 en caso contrario. library(tidyverse) library(magrittr) source(&quot;Recursos/Día2/Sesion2/0Recursos/0Source_FH.R&quot;) encuesta &lt;- readRDS(&quot;Recursos/Día2/Sesion2/Data/encuestaDOM21N1.rds&quot;) %&gt;% transmute( dam = haven::as_factor(dam_ee,levels = &quot;values&quot;), dam = str_pad(dam,width = 2,pad = &quot;0&quot;), dam2, wkx = `_fep`, upm = `_upm`, estrato = `_estrato`, pobreza = ifelse(ingcorte &lt; lp, 1 , 0)) dam: Corresponde al código asignado a la división administrativa mayor del país. dam2: Corresponde al código asignado a la segunda división administrativa del país. lp linea de pobreza definida por CEPAL. Factor de expansión por persona (wkx) dam dam2 wkx upm estrato pobreza 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 01 00101 137.0652 1 1 0 En el siguiente bloque de código utiliza las librerías survey y srvyr para crear un diseño de muestreo a partir de una base de datos de encuestas. El diseño de muestreo incluye información sobre las unidades primarias de muestreo (UPM), los pesos de muestreo (wkx), y los strata (estrato) utilizadas en el muestreo. Además, se utiliza la opción “survey.lonely.psu” para ajustar los tamaños de muestra en los grupos de unidades primarias de muestreo que no tienen otras unidades primarias de muestreo en el mismo grupo. library(survey) library(srvyr) options(survey.lonely.psu = &quot;adjust&quot;) diseno &lt;- as_survey_design( ids = upm, weights = wkx, strata = estrato, nest = TRUE, .data = encuesta ) summary(diseno) ## Stratified 1 - level Cluster Sampling design (with replacement) ## With (1056) clusters. ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.000762 0.005899 0.007954 0.009216 0.010773 0.031841 ## Stratum Sizes: ## 1 2 3 4 5 6 7 8 9 10 11 12 13 ## obs 6796 15469 2500 6602 2409 2482 2437 2196 2170 1866 1692 1447 1156 ## design.PSU 127 235 35 90 30 35 30 30 25 30 24 20 15 ## actual.PSU 127 235 35 90 30 35 30 30 25 30 24 20 15 ## 14 15 16 17 18 19 20 21 22 23 ## obs 3578 2764 1808 1331 5036 1555 2757 1600 4774 1646 ## design.PSU 50 40 20 15 50 15 35 20 65 20 ## actual.PSU 50 40 20 15 50 15 35 20 65 20 ## Data variables: ## [1] &quot;dam&quot; &quot;dam2&quot; &quot;wkx&quot; &quot;upm&quot; &quot;estrato&quot; &quot;pobreza&quot; Para la estimación directa de la proporción se emplea la función direct.supr, disponible en el archivo 0Source_FH.R. Está función realiza las estimaciones y criterios de calidad en una encuesta de muestreo complejo con diseño estratificado y por conglomerados. Toma cinco argumentos: design.base, variable, group, upm y estrato. La función comienza cargando varios paquetes, como rlang, tidyverse, dplyr, survey y srvyr. Luego, los argumentos group, variable, upm y estrato se convierten en argumentos utilizando la función enquo. La función utiliza la encuesta de muestreo complejo design.base para calcular las estimaciones de los parámetros y los criterios de calidad. Utiliza la función survey_mean() de la librería survey para calcular la media y los intervalos de confianza de la variable de interés. La función también calcula otros indicadores de calidad, como el coeficiente de variación, el tamaño de muestra efectivo y el efecto del diseño. Luego, utiliza la función as.data.frame() para convertir los resultados en un objeto de marco de datos. Además, la función calcula otros criterios de calidad para determinar si las estimaciones son confiables. En particular, evalúa si se cumple un umbral mínimo para el número de grados de libertad, si la muestra es suficientemente grande y si el efecto del diseño es razonable. La función también tiene la opción de incluir o excluir ciertos grupos de muestreo basados en sus características. directodam2 &lt;- direct.supr(design.base = diseno, variable = pobreza, group = dam2, upm = upm, estrato = estrato) directodam2 %&gt;% group_by(Flag) %&gt;% summarise(n = n()) %&gt;% arrange(n) %&gt;% tba() # saveRDS(directodam2, &quot;Data/directodam2.rds&quot;) Flag n Excluir 64 Incluir 79 Para los dominios que no son excluidos se hace la transformación arcoseno, calculo del DEFF y varianza base_sae &lt;- directodam2 %&gt;% filter(Flag != &quot;Excluir&quot;) %&gt;% transmute( dam2 = dam2, # Id para los dominios nd = n, # Número de observaciones por dominios n_effec = n.eff, # n efectivo. pobreza = p, # Estimación de la variable pobreza_T = asin(sqrt(pobreza)), # Transformación arcoseno vardir = ee ^ 2, # Estimación de la varianza directa cv = CV, var_zd = 1 / (4 * n_effec), # Varianza para la tranformación arcsin deff_dam2 = deff # Deff por dominio ) # View(base_sae) tba(head(base_sae)) dam2 nd n_effec pobreza pobreza_T vardir cv var_zd deff_dam2 00101 6796 382.3874 0.2225 0.4912 0.0004 8.4371 0.0007 17.7726 00201 531 254.4720 0.1822 0.4409 0.0004 11.3979 0.0010 2.0867 00206 230 58.1282 0.3366 0.6190 0.0031 16.6251 0.0043 3.9568 00301 666 144.3395 0.4266 0.7117 0.0043 15.4187 0.0017 4.6141 00302 261 559.2612 0.4461 0.7314 0.0014 8.3930 0.0004 0.4667 00303 566 40.0367 0.5587 0.8442 0.0142 21.3212 0.0062 14.1370 seguidamente se realiza la transformación \\(\\log(\\hat{\\sigma}^2_d)\\), además se realiza la selección de las columnas identificador del municipio (dam2), la estimación directa (pobreza), El número de personas en el dominio (nd) y la varianza estimada del para la estimación directa vardir,siendo esta la que transforma mediante la función log(). baseFGV &lt;- base_sae %&gt;% select(dam2, pobreza, nd, vardir) %&gt;% mutate(ln_sigma2 = log(vardir)) "],["análisis-gráfico.html", "6.2 Análisis gráfico", " 6.2 Análisis gráfico El primer gráfico, p1, muestra una gráfica de dispersión de la variable ln_sigma2 en función de la variable pobreza, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como pobreza. El segundo gráfico, p2, muestra una gráfica de dispersión de la variable ln_sigma2 en función de la variable nd, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como Tamaño de muestra. El tercer gráfico, p3, muestra una gráfica de dispersión de la variable ln_sigma2 en función del producto de pobreza y nd, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como Número de pobres. El cuarto gráfico, p4, muestra una gráfica de dispersión de la variable ln_sigma2 en función de la raíz cuadrada de la variable pobreza, con una línea suave que representa una estimación de la tendencia. El eje x está etiquetado como Raiz cuadrada de pobreza. En general, los gráficos estan diseñados para explorar la relación entre ln_sigma2 y diferentes variables independientes, como pobreza, nd, y la raíz cuadrada de la pobreza. La elección de utilizar la función “loess” para suavizar las líneas en lugar de una línea recta puede ayudar a visualizar mejor las tendencias generales en los datos. theme_set(theme_bw()) # pobreza vs Ln_sigma2 # p1 &lt;- ggplot(baseFGV, aes(x = pobreza, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;pobreza&quot;) # Tamaño de muestra vs Ln_sigma2 # p2 &lt;- ggplot(baseFGV, aes(x = nd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Tamaño de muestra&quot;) # Número de pobres vs Ln_sigma2 # p3 &lt;- ggplot(baseFGV, aes(x = pobreza * nd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Número de pobres&quot;) # Raiz_pobreza vs Ln_sigma2 # p4 &lt;- ggplot(baseFGV, aes(x = sqrt(pobreza), y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Raiz cuadrada de pobreza&quot;) library(patchwork) (p1 | p2) / (p3 | p4) "],["modelo-para-la-varianza.html", "6.3 Modelo para la varianza", " 6.3 Modelo para la varianza El código ajusta un modelo de regresión lineal múltiple (utilizando la función lm()), donde ln_sigma2 es la variable respuesta y las variables predictoras son pobreza, nd, y varias transformaciones de éstas. El objetivo de este modelo es estimar la función generalizada de varianza (FGV) para los dominios observados. library(gtsummary) FGV1 &lt;- lm(ln_sigma2 ~ pobreza + I(sqrt(nd)) + I(sqrt(pobreza)) + I(sqrt(nd^pobreza)) , data = baseFGV) tbl_regression(FGV1) %&gt;% add_glance_table(include = c(r.squared, adj.r.squared)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #ybddhfvzen .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #ybddhfvzen .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ybddhfvzen .gt_caption { padding-top: 4px; padding-bottom: 4px; } #ybddhfvzen .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ybddhfvzen .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #ybddhfvzen .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ybddhfvzen .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #ybddhfvzen .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #ybddhfvzen .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #ybddhfvzen .gt_column_spanner_outer:first-child { padding-left: 0; } #ybddhfvzen .gt_column_spanner_outer:last-child { padding-right: 0; } #ybddhfvzen .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #ybddhfvzen .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #ybddhfvzen .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #ybddhfvzen .gt_from_md > :first-child { margin-top: 0; } #ybddhfvzen .gt_from_md > :last-child { margin-bottom: 0; } #ybddhfvzen .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #ybddhfvzen .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #ybddhfvzen .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #ybddhfvzen .gt_row_group_first td { border-top-width: 2px; } #ybddhfvzen .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ybddhfvzen .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #ybddhfvzen .gt_first_summary_row.thick { border-top-width: 2px; } #ybddhfvzen .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ybddhfvzen .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #ybddhfvzen .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #ybddhfvzen .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #ybddhfvzen .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #ybddhfvzen .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ybddhfvzen .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #ybddhfvzen .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #ybddhfvzen .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #ybddhfvzen .gt_left { text-align: left; } #ybddhfvzen .gt_center { text-align: center; } #ybddhfvzen .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ybddhfvzen .gt_font_normal { font-weight: normal; } #ybddhfvzen .gt_font_bold { font-weight: bold; } #ybddhfvzen .gt_font_italic { font-style: italic; } #ybddhfvzen .gt_super { font-size: 65%; } #ybddhfvzen .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #ybddhfvzen .gt_asterisk { font-size: 100%; vertical-align: 0; } #ybddhfvzen .gt_indent_1 { text-indent: 5px; } #ybddhfvzen .gt_indent_2 { text-indent: 10px; } #ybddhfvzen .gt_indent_3 { text-indent: 15px; } #ybddhfvzen .gt_indent_4 { text-indent: 20px; } #ybddhfvzen .gt_indent_5 { text-indent: 25px; } Characteristic Beta 95% CI1 p-value pobreza -40 -64, -15 0.002 I(sqrt(nd)) -0.06 -0.08, -0.03 I(sqrt(pobreza)) 31 15, 47 I(sqrt(nd^pobreza)) 1.4 0.14, 2.7 0.030 R² 0.298 Adjusted R² 0.261 1 CI = Confidence Interval Después de tener la estimación del modelo se debe obtener el valor de la constante \\(\\Delta\\) para lo cual se usa el siguiente código. delta.hat = sum(baseFGV$vardir) / sum(exp(fitted.values(FGV1))) De donde se obtiene que \\(\\Delta = 1.6825614\\). Final es posible obtener la varianza suavizada ejecutando el siguiente comando. hat.sigma &lt;- data.frame(dam2 = baseFGV$dam2, hat_var = delta.hat * exp(fitted.values(FGV1))) baseFGV &lt;- left_join(baseFGV, hat.sigma) tba(head(baseFGV, 10)) dam2 pobreza nd vardir ln_sigma2 hat_var 00101 0.2225 6796 0.0004 -7.9505 0.0004 00201 0.1822 531 0.0004 -7.7493 0.0039 00206 0.3366 230 0.0031 -5.7661 0.0041 00301 0.4266 666 0.0043 -5.4432 0.0050 00302 0.4461 261 0.0014 -6.5697 0.0029 00303 0.5587 566 0.0142 -4.2552 0.0075 00304 0.5406 412 0.0116 -4.4550 0.0042 00401 0.3359 1219 0.0010 -6.9320 0.0042 00402 0.1496 172 0.0007 -7.2136 0.0047 00403 0.4644 309 0.0015 -6.4935 0.0031 Validación del modelo para la FGV par(mfrow = c(2, 2)) plot(FGV1) Comparación entre la varianza estimada versus la pronosticada por la FGV ggplot(baseFGV , aes(y = vardir, x = hat_var)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + labs(x = &quot;FGV&quot;, y = &quot;VarDirEst&quot;) + ylab(&quot;Varianza del Estimador Directo&quot;) Predicción de la varianza suavizada base_sae &lt;- base_sae %&gt;% left_join(hat.sigma, by = &quot;dam2&quot;) Ahora, realizamos un gráfico de linea para ver la volatilidad es la estimaciones de las varianzas. ggplot(base_sae %&gt;% arrange(nd), aes(x = 1:nrow(base_sae))) + geom_line(aes(y = vardir, color = &quot;VarDirEst&quot;)) + geom_line(aes(y = hat_var, color = &quot;FGV&quot;)) + labs(y = &quot;Varianzas&quot;, x = &quot;Tamaño muestral&quot;, color = &quot; &quot;) + scale_x_continuous(breaks = seq(1, nrow(base_sae), by = 10), labels = base_sae$nd[order(base_sae$nd)][seq(1, nrow(base_sae), by = 10)]) + scale_color_manual(values = c(&quot;FGV&quot; = &quot;Blue&quot;, &quot;VarDirEst&quot; = &quot;Red&quot;)) El siguiente código utiliza la función mutate() del paquete dplyr para crear nuevas variables de la base de datos base_sae y luego guarda el resultado en un archivo RDS llamado base_FH_2018.rds. En concreto, el código realiza las siguientes operaciones: La variable deff_dam2 se ajusta a 1 cuando es NaN. La variable deff_FGV se calcula a partir de otras dos variables hat_var y vardir. Si vardir es 0, entonces deff_FGV se ajusta a 1. En caso contrario, se divide hat_var por vardir / deff_dam2 para obtener deff_FGV. La variable deff_FGV se regulariza utilizando el criterio MDS: si deff_FGV es menor que 1, se ajusta a 1. Finalmente, se calcula la variable n_eff_FGV dividiendo nd (el tamaño de la muestra) por deff_FGV. base_FH &lt;- base_sae %&gt;% mutate( deff_dam2 = ifelse(is.nan(deff_dam2), 1, deff_dam2), deff_FGV = ifelse( vardir == 0 , 1, hat_var / (vardir / deff_dam2) ), # Criterio MDS para regularizar el DeffFGV deff_FGV = ifelse(deff_FGV &lt; 1, 1, deff_FGV), n_eff_FGV = nd / deff_FGV ) saveRDS(object = base_FH, &quot;Recursos/Día2/Sesion2/Data/base_FH_2018.rds&quot;) "],["día-2---sesión-3--modelo-de-fay-herriot---estimación-de-la-pobreza.html", "Capítulo 7 Día 2 - Sesión 3- Modelo de Fay Herriot - Estimación de la pobreza", " Capítulo 7 Día 2 - Sesión 3- Modelo de Fay Herriot - Estimación de la pobreza El modelo de Fay Herriot, propuesto por Fay y Herriot (1979), es un modelo estadístico de área y es el más comúnmente utilizado, cabe tener en cuenta, que dentro de la metodología de estimación en áreas pequeñas, los modelos de área son los de mayor aplicación, ya que lo más factible es no contar con la información a nivel de individuo, pero si encontrar no solo los datos a nivel de área, sino también información auxiliar asociada a estos datos. Este modelo lineal mixto, fue el primero en incluir efectos aleatorios a nivel de área, lo que implica que la mayoría de la información que se introduce al modelo corresponde a agregaciaciones usualmente, departamentos, regiones, provincias, municipios entre otros, donde las estimaciones que se logran con el modelo se obtienen sobre estas agregaciones o subpoblaciones. El modelo FH enlaza indicadores de las áreas \\(\\theta_d\\), \\(d = 1, \\cdots , D\\), asumiendo que varían respeto a un vector de \\(p\\) covariables, \\(\\boldsymbol{x}_d\\) , de forma constante. El modelo esta dado por la ecuación \\[ \\theta_d = \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d ,\\ \\ \\ \\ \\ d = 1, \\cdots , D \\] \\(u_d\\) es el término de error, o el efecto aleatorio, diferente para cada área dado por \\[ \\begin{eqnarray*} u_{d} &amp; \\stackrel{iid}{\\sim} &amp; \\left(0,\\sigma_{u}^{2}\\right) \\end{eqnarray*} \\] Sin embargo, los verdaderos valores de los indicadores \\(\\theta_d\\) no son observables. Entonces, usamos el estimador directo \\(\\hat{\\theta}^{DIR}_d\\) para \\(\\theta_d\\) , lo que conlleva un error debido al muestro. \\(\\hat{\\theta}^{DIR}_d\\) todavía se considera insesgado bajo el diseño muestral. Podemos definir, entonces, \\[ \\hat{\\theta}^{DIR}_d = \\theta_d + e_d, \\ \\ \\ \\ \\ \\ d = 1, \\cdots , D \\] donde \\(e_d\\) es el error debido al muestreo, \\(e_{d} \\stackrel{ind}{\\sim} \\left(0,\\sigma^2\\right)\\) Dichas varianzas \\(\\sigma^2_d = var_{\\mathscr{P}}\\left(\\hat{\\theta}^{DIR}_d\\mid\\theta_d\\right)\\), \\(d = 1,\\cdots,D\\) se estiman con los microdatos de la encuesta. Por tanto, el modelo se hace, \\[ \\hat{\\theta}^{DIR}_d = \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d + e_d, \\ \\ \\ \\ \\ \\ d = 1, \\cdots , D \\] El BLUP (best linear unbiased predictor) bajo el modelo FH de \\(\\theta_d\\) viene dado por \\[ \\begin{eqnarray*} \\tilde{\\theta}_{d}^{FH} &amp; = &amp; \\boldsymbol{x}^{T}_{d}\\tilde{\\boldsymbol{\\beta}}+\\tilde{u}_{d} \\end{eqnarray*} \\] Si sustituimos \\(\\tilde{u}_d = \\gamma_d\\left(\\hat{\\theta}^{DIR}_d - \\boldsymbol{x}^{T}_{d}\\tilde{\\boldsymbol{\\beta}} \\right)\\) en el BLUP bajo el modelo FH, obtenemos \\[ \\begin{eqnarray*} \\tilde{\\theta}_{d}^{FH} &amp; = &amp; \\gamma_d\\hat{\\theta}^{DIR}_{d}+(1-\\gamma_d)\\boldsymbol{x}^{T}_{d}\\tilde{\\boldsymbol{\\beta}} \\end{eqnarray*} \\] siendo \\(\\gamma_d=\\frac{\\sigma^2_u}{\\sigma^2_u + \\sigma^2_d}\\). Habitualmente, no sabemos el verdadero valor de \\(\\sigma^2_u\\) efectos aleatorios \\(u_d\\). Sea \\(\\hat{\\sigma}^2_u\\) un estimador consistente para \\(\\sigma^2_u\\). Entonces, obtenemos el BLUP empírico (empirical BLUP, EBLUP) de \\(\\theta_d\\) , \\[ \\begin{eqnarray*} \\tilde{\\theta}_{d}^{FH} &amp; = &amp; \\hat{\\gamma_d}\\hat{\\theta}^{DIR}_{d}+(1-\\hat{\\gamma_d})\\boldsymbol{x}^{T}_{d}\\hat{\\boldsymbol{\\beta}} \\end{eqnarray*} \\] donde \\(\\hat{\\gamma_d}=\\frac{\\hat{\\sigma}^2_u}{\\hat{\\sigma}^2_u + \\sigma^2_d}\\). Modelo de área para la estimación de la pobreza El modelo bayesiano estaría definido como: \\[ \\begin{eqnarray*} \\hat{Y}_d\\mid\\theta_d,\\sigma_d^2 &amp; \\sim &amp; N\\left(\\theta_d,\\sigma_d^2\\right)\\\\ \\theta_d &amp; = &amp; \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta}+u_d \\end{eqnarray*} \\] donde \\(u_d \\sim N(0 , \\sigma^2_u)\\) y \\(\\hat{Y}_d\\) es la estimación directa de la pobreza en el \\(d-ésimo\\) dominio. Las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma^2_u\\) \\[ \\begin{eqnarray*} \\beta_p &amp; \\sim &amp; N(0, 10000)\\\\ \\sigma^2_u &amp;\\sim &amp; IG(0.0001, 0.0001) \\end{eqnarray*} \\] "],["procedimiento-de-estimación.html", "7.1 Procedimiento de estimación", " 7.1 Procedimiento de estimación Este código utiliza las librerías tidyverse y magrittr para procesamiento y analizar datos. La función readRDS() es utilizada para cargar un archivo de datos en formato RDS, que contiene las estimaciones directas y la varianza suvizada para la proporción de personas en condición de pobreza correspondientes al año 2018. Luego, se utiliza el operador %&gt;% de la librería magrittr para encadenar la selección de las columnas de interés, que corresponden a los nombres dam2, nd, pobreza, vardir y hat_var. library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/base_FH_2018.rds&quot;) %&gt;% select(dam2, nd, pobreza, vardir, hat_var) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Ahora, se realiza una unión completa (full_join) entre el conjunto de datos base_FH y los predictores statelevel_predictors_df utilizando la variable dam2 como clave de unión. Se utiliza la función tba() para imprimir las primeras 10 filas y 8 columnas del conjunto de datos resultante de la unión anterior. La unión completa (full_join) combina los datos de ambos conjuntos, manteniendo todas las filas de ambos, y llenando con valores faltantes (NA) en caso de no encontrar coincidencias en la variable de unión (dam2 en este caso). La función tba() imprime una tabla en formato HTML en la consola de R que muestra las primeras 10 filas y 8 columnas del conjunto de datos resultante de la unión. base_FH &lt;- full_join(base_FH, statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[1:10,1:8]) dam2 nd pobreza vardir hat_var modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 00101 6796 0.2225 0.0004 0.0004 3.6127 -1.1835 -1.5653 00201 531 0.1822 0.0004 0.0039 -0.0553 0.4449 0.2100 00206 230 0.3366 0.0031 0.0041 0.5157 -0.1468 -0.1811 00301 666 0.4266 0.0043 0.0050 0.1364 0.5744 1.1660 00302 261 0.4461 0.0014 0.0029 -0.5103 0.2531 1.0880 00303 566 0.5587 0.0142 0.0075 -0.6591 0.6249 1.2229 00304 412 0.5406 0.0116 0.0042 -0.5573 1.4586 2.7337 00401 1219 0.3359 0.0010 0.0042 0.3979 -0.0833 -0.4490 00402 172 0.1496 0.0007 0.0047 -0.3661 -0.0114 -0.2863 00403 309 0.4644 0.0015 0.0031 -1.0446 0.4542 0.5702 # View(base_FH) "],["preparando-los-insumos-para-stan.html", "7.2 Preparando los insumos para STAN", " 7.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados. Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[1:10,1:8]) dam2 nd pobreza vardir hat_var modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 00202 NA NA NA NA -0.3758 0.0000 0.1482 00203 NA NA NA NA -0.9259 0.5732 -0.1402 00204 NA NA NA NA -1.3166 1.1111 0.4438 00205 NA NA NA NA -0.7474 2.1155 1.2271 00207 NA NA NA NA 1.7368 -0.7648 -0.4861 00208 NA NA NA NA -0.5942 0.3212 -0.1697 00209 NA NA NA NA -1.5280 3.0192 1.9428 00210 NA NA NA NA -1.0038 0.5778 0.2678 00305 NA NA NA NA -0.8480 1.5047 3.2004 00404 NA NA NA NA -0.5678 1.0735 0.9856 Definir matriz de efectos fijos. Define un modelo lineal utilizando la función formula(), que incluye varias variables predictoras, como la edad, la etnia, la tasa de desocupación, entre otras. Utiliza la función model.matrix() para generar matrices de diseño (Xdat y Xs) a partir de los datos observados (data_dir) y no observados (data_syn) para utilizar en la construcción de modelos de regresión. La función model.matrix() convierte las variables categóricas en variables binarias (dummy), de manera que puedan ser utilizadas. formula_mod &lt;- formula(~ sexo2 + anoest2 + anoest3 + anoest4 + edad2 + edad3 + edad4 + edad5 + tasa_desocupacion + luces_nocturnas + cubrimiento_cultivo + alfabeta) ## Dominios observados Xdat &lt;- model.matrix(formula_mod, data = data_dir) ## Dominios no observados Xs &lt;- model.matrix(formula_mod, data = data_syn) Ahora, se utiliza la función setdiff() para identificar las columnas de Xdat que no están presentes en \\(X_s\\), es decir, las variables que no se encuentran en los datos no observados. A continuación, se crea una matriz temporal (temp) con ceros para las columnas faltantes de \\(X_s\\), y se agregan estas columnas a \\(X_s\\) utilizando cbind(). El resultado final es una matriz Xs con las mismas variables que Xdat, lo que asegura que se puedan realizar comparaciones adecuadas entre los datos observados y no observados en la construcción de modelos de regresión. En general, este código es útil para preparar los datos para su posterior análisis y asegurar que los modelos de regresión sean adecuados para su uso. temp &lt;- setdiff(colnames(Xdat),colnames(Xs)) temp &lt;- matrix( 0, nrow = nrow(Xs), ncol = length(temp), dimnames = list(1:nrow(Xs), temp) ) Xs &lt;- cbind(Xs,temp)[,colnames(Xdat)] Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$pobreza), # Estimación directa sigma_e = sqrt(data_dir$hat_var) # Error de estimación ) Rutina implementada en STAN data { int&lt;lower=0&gt; N1; // number of data items int&lt;lower=0&gt; N2; // number of data items for prediction int&lt;lower=0&gt; p; // number of predictors matrix[N1, p] X; // predictor matrix matrix[N2, p] Xs; // predictor matrix vector[N1] y; // predictor matrix vector[N1] sigma_e; // known variances } parameters { vector[p] beta; // coefficients for predictors real&lt;lower=0&gt; sigma2_u; vector[N1] u; } transformed parameters{ vector[N1] theta; vector[N1] thetaSyn; vector[N1] thetaFH; vector[N1] gammaj; real&lt;lower=0&gt; sigma_u; thetaSyn = X * beta; theta = thetaSyn + u; sigma_u = sqrt(sigma2_u); gammaj = to_vector(sigma_u ./ (sigma_u + sigma_e)); thetaFH = (gammaj) .* y + (1-gammaj).*thetaSyn; } model { // likelihood y ~ normal(theta, sigma_e); // priors beta ~ normal(0, 100); u ~ normal(0, sigma_u); sigma2_u ~ inv_gamma(0.0001, 0.0001); } generated quantities{ vector[N2] y_pred; for(j in 1:N2) { y_pred[j] = normal_rng(Xs[j] * beta, sigma_u); } } Compilando el modelo en STAN. A continuación mostramos la forma de compilar el código de STAN desde R. En este código se utiliza la librería rstan para ajustar un modelo bayesiano utilizando el archivo 17FH_normal.stan que contiene el modelo escrito en el lenguaje de modelado probabilístico Stan. En primer lugar, se utiliza la función stan() para ajustar el modelo a los datos de sample_data. Los argumentos que se pasan a stan() incluyen el archivo que contiene el modelo (fit_FH_normal), los datos (sample_data), y los argumentos para controlar el proceso de ajuste del modelo, como el número de iteraciones para el período de calentamiento (warmup) y el período de muestreo (iter), y el número de núcleos de la CPU para utilizar en el proceso de ajuste (cores). Además, se utiliza la función parallel::detectCores() para detectar automáticamente el número de núcleos disponibles en la CPU, y se establece la opción mc.cores para aprovechar el número máximo de núcleos disponibles para el ajuste del modelo. El resultado del ajuste del modelo es almacenado en model_FH_normal, que contiene una muestra de la distribución posterior del modelo, la cual puede ser utilizada para realizar inferencias sobre los parámetros del modelo y las predicciones. En general, este código es útil para ajustar modelos bayesianos utilizando Stan y realizar inferencias posteriores. library(rstan) fit_FH_normal &lt;- &quot;Recursos/Día2/Sesion3/Data/modelosStan/17FH_normal.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_normal &lt;- stan( file = fit_FH_normal, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(object = model_FH_normal, file = &quot;Recursos/Día2/Sesion3/Data/model_FH_normal.rds&quot;) Leer el modelo model_FH_normal&lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/model_FH_normal.rds&quot;) 7.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(posterior) library(patchwork) y_pred_B &lt;- as.array(model_FH_normal, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_V\\). posterior_sigma2_u &lt;- as.array(model_FH_normal, pars = &quot;sigma2_u&quot;) (mcmc_dens_chains(posterior_sigma2_u) + mcmc_areas(posterior_sigma2_u) ) / mcmc_trace(posterior_sigma2_u) #traceplot(model_FH_normal, pars = &quot;sigma2_u&quot;, inc_warmup = TRUE) Como método de validación se comparan las diferentes elementos de la estimación del modelo de FH obtenidos en STAN theta &lt;- summary(model_FH_normal,pars = &quot;theta&quot;)$summary %&gt;% data.frame() thetaSyn &lt;- summary(model_FH_normal,pars = &quot;thetaSyn&quot;)$summary %&gt;% data.frame() theta_FH &lt;- summary(model_FH_normal,pars = &quot;thetaFH&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate( thetadir = pobreza, theta_pred = theta$mean, thetaSyn = thetaSyn$mean, thetaFH = theta_FH$mean, theta_pred_EE = theta$sd, Cv_theta_pred = theta_pred_EE/theta_pred ) # saveRDS(data_dir,&quot;Recursos/Día2/Sesion3/0Recursos/data_dir.rds&quot;) # Estimación predicción del modelo vs ecuación ponderada de FH p11 &lt;- ggplot(data_dir, aes(x = theta_pred, y = thetaFH)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) # Estimación con la ecuación ponderada de FH Vs estimación sintética p12 &lt;- ggplot(data_dir, aes(x = thetaSyn, y = thetaFH)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) # Estimación con la ecuación ponderada de FH Vs estimación directa p21 &lt;- ggplot(data_dir, aes(x = thetadir, y = thetaFH)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) # Estimación directa Vs estimación sintética p22 &lt;- ggplot(data_dir, aes(x = thetadir, y = thetaSyn)) + geom_point() + geom_abline(slope = 1,intercept = 0, colour = &quot;red&quot;) + theme_bw(10) (p11+p12)/(p21+p22) Estimación del FH de la pobreza en los dominios NO observados. theta_syn_pred &lt;- summary(model_FH_normal,pars = &quot;y_pred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate( theta_pred = theta_syn_pred$mean, thetaSyn = theta_pred, thetaFH = theta_pred, theta_pred_EE = theta_syn_pred$sd, Cv_theta_pred = theta_pred_EE/theta_pred) #saveRDS(data_syn,&quot;Recursos/Día2/Sesion3/0Recursos/data_syn.rds&quot;) tba(data_syn %&gt;% slice(1:10) %&gt;% select(dam2:hat_var,theta_pred:Cv_theta_pred)) dam2 nd pobreza vardir hat_var theta_pred thetaSyn thetaFH theta_pred_EE Cv_theta_pred 00202 NA NA NA NA 0.2939 0.2939 0.2939 0.0934 0.3177 00203 NA NA NA NA 0.2816 0.2816 0.2816 0.0881 0.3131 00204 NA NA NA NA 0.2930 0.2930 0.2930 0.0916 0.3128 00205 NA NA NA NA 0.1812 0.1812 0.1812 0.0977 0.5392 00207 NA NA NA NA 0.3500 0.3500 0.3500 0.0921 0.2632 00208 NA NA NA NA 0.2330 0.2330 0.2330 0.1001 0.4294 00209 NA NA NA NA 0.2275 0.2275 0.2275 0.1214 0.5338 00210 NA NA NA NA 0.2784 0.2784 0.2784 0.1013 0.3639 00305 NA NA NA NA 0.4831 0.4831 0.4831 0.0975 0.2019 00404 NA NA NA NA 0.4305 0.4305 0.4305 0.1088 0.2527 consolidando las bases de estimaciones para dominios observados y NO observados. estimacionesPre &lt;- bind_rows(data_dir, data_syn) %&gt;% select(dam2, theta_pred) "],["proceso-de-benchmark.html", "7.3 Proceso de Benchmark", " 7.3 Proceso de Benchmark Del censo extraer el total de personas por DAM2 total_pp &lt;- readRDS(file = &quot;Recursos/Día2/Sesion3/Data/total_personas_dam2.rds&quot;) N_dam_pp &lt;- total_pp %&gt;% group_by(region) %&gt;% mutate(region_pp = sum(pp_dam2) ) tba(N_dam_pp %&gt;% slice(1:20)) region nombre_region dam dam2 id_municipio pp_dam2 region_pp 01 Región Cibao Norte 09 00901 010901 179829 1516957 01 Región Cibao Norte 09 00902 010902 6911 1516957 01 Región Cibao Norte 09 00903 010903 37378 1516957 01 Región Cibao Norte 09 00904 010904 7820 1516957 01 Región Cibao Norte 18 01801 011801 158756 1516957 01 Región Cibao Norte 18 01802 011802 18868 1516957 01 Región Cibao Norte 18 01803 011803 6333 1516957 01 Región Cibao Norte 18 01804 011804 22058 1516957 01 Región Cibao Norte 18 01805 011805 12639 1516957 01 Región Cibao Norte 18 01806 011806 16464 1516957 01 Región Cibao Norte 18 01807 011807 49593 1516957 01 Región Cibao Norte 18 01808 011808 17169 1516957 01 Región Cibao Norte 18 01809 011809 19717 1516957 01 Región Cibao Norte 25 02501 012501 691262 1516957 01 Región Cibao Norte 25 02502 012502 42092 1516957 01 Región Cibao Norte 25 02503 012503 16993 1516957 01 Región Cibao Norte 25 02504 012504 25539 1516957 01 Región Cibao Norte 25 02505 012505 38628 1516957 01 Región Cibao Norte 25 02506 012506 51695 1516957 01 Región Cibao Norte 25 02507 012507 37349 1516957 02 Región Cibao Sur 13 01301 021301 248089 710821 02 Región Cibao Sur 13 01302 021302 59052 710821 02 Región Cibao Sur 13 01303 021303 56803 710821 02 Región Cibao Sur 13 01304 021304 30261 710821 02 Región Cibao Sur 24 02401 022401 76554 710821 02 Región Cibao Sur 24 02402 022402 13759 710821 02 Región Cibao Sur 24 02403 022403 22117 710821 02 Región Cibao Sur 24 02404 022404 38962 710821 02 Región Cibao Sur 28 02801 022801 125338 710821 02 Región Cibao Sur 28 02802 022802 18952 710821 02 Región Cibao Sur 28 02803 022803 20934 710821 03 Región Cibao Nordeste 06 00601 030601 188118 624186 03 Región Cibao Nordeste 06 00602 030602 14062 624186 03 Región Cibao Nordeste 06 00603 030603 15709 624186 03 Región Cibao Nordeste 06 00604 030604 17864 624186 03 Región Cibao Nordeste 06 00605 030605 33663 624186 03 Región Cibao Nordeste 06 00606 030606 14661 624186 03 Región Cibao Nordeste 06 00607 030607 5497 624186 03 Región Cibao Nordeste 14 01401 031401 76993 624186 03 Región Cibao Nordeste 14 01402 031402 24524 624186 03 Región Cibao Nordeste 14 01403 031403 24240 624186 03 Región Cibao Nordeste 14 01404 031404 15168 624186 03 Región Cibao Nordeste 19 01901 031901 39557 624186 03 Región Cibao Nordeste 19 01902 031902 27765 624186 03 Región Cibao Nordeste 19 01903 031903 24871 624186 03 Región Cibao Nordeste 20 02001 032001 58156 624186 03 Región Cibao Nordeste 20 02002 032002 24509 624186 03 Región Cibao Nordeste 20 02003 032003 18829 624186 04 Región Cibao Noroeste 05 00501 040501 28071 394068 04 Región Cibao Noroeste 05 00502 040502 15624 394068 04 Región Cibao Noroeste 05 00503 040503 6951 394068 04 Región Cibao Noroeste 05 00504 040504 7274 394068 04 Región Cibao Noroeste 05 00505 040505 6035 394068 04 Región Cibao Noroeste 15 01501 041501 24644 394068 04 Región Cibao Noroeste 15 01502 041502 14921 394068 04 Región Cibao Noroeste 15 01503 041503 35923 394068 04 Región Cibao Noroeste 15 01504 041504 10559 394068 04 Región Cibao Noroeste 15 01505 041505 9136 394068 04 Región Cibao Noroeste 15 01506 041506 14424 394068 04 Región Cibao Noroeste 26 02601 042601 34540 394068 04 Región Cibao Noroeste 26 02602 042602 11183 394068 04 Región Cibao Noroeste 26 02603 042603 11753 394068 04 Región Cibao Noroeste 27 02701 042701 76863 394068 04 Región Cibao Noroeste 27 02702 042702 62205 394068 04 Región Cibao Noroeste 27 02703 042703 23962 394068 05 Región Valdesia 02 00201 050201 91345 1028129 05 Región Valdesia 02 00202 050202 11243 1028129 05 Región Valdesia 02 00203 050203 17620 1028129 05 Región Valdesia 02 00204 050204 20041 1028129 05 Región Valdesia 02 00205 050205 15257 1028129 05 Región Valdesia 02 00206 050206 19020 1028129 05 Región Valdesia 02 00207 050207 11235 1028129 05 Región Valdesia 02 00208 050208 17647 1028129 05 Región Valdesia 02 00209 050209 5263 1028129 05 Región Valdesia 02 00210 050210 5640 1028129 05 Región Valdesia 17 01701 051701 157316 1028129 05 Región Valdesia 17 01702 051702 27028 1028129 05 Región Valdesia 21 02101 052101 232769 1028129 05 Región Valdesia 21 02102 052102 15466 1028129 05 Región Valdesia 21 02103 052103 124193 1028129 05 Región Valdesia 21 02104 052104 31057 1028129 05 Región Valdesia 21 02105 052105 84312 1028129 05 Región Valdesia 21 02106 052106 42325 1028129 05 Región Valdesia 21 02107 052107 30268 1028129 05 Región Valdesia 21 02108 052108 9540 1028129 06 Región Enriquillo 03 00301 060301 36511 368594 06 Región Enriquillo 03 00302 060302 15702 368594 06 Región Enriquillo 03 00303 060303 26772 368594 06 Región Enriquillo 03 00304 060304 10619 368594 06 Región Enriquillo 03 00305 060305 7709 368594 06 Región Enriquillo 04 00401 060401 83619 368594 06 Región Enriquillo 04 00402 060402 14823 368594 06 Región Enriquillo 04 00403 060403 13164 368594 06 Región Enriquillo 04 00404 060404 15390 368594 06 Región Enriquillo 04 00405 060405 21605 368594 06 Región Enriquillo 04 00406 060406 3970 368594 06 Región Enriquillo 04 00407 060407 9112 368594 06 Región Enriquillo 04 00408 060408 8042 368594 06 Región Enriquillo 04 00409 060409 4703 368594 06 Región Enriquillo 04 00410 060410 8186 368594 06 Región Enriquillo 04 00411 060411 4491 368594 06 Región Enriquillo 10 01001 061001 16510 368594 06 Región Enriquillo 10 01002 061002 12029 368594 06 Región Enriquillo 10 01003 061003 8310 368594 06 Región Enriquillo 10 01004 061004 5668 368594 07 Región EL Valle 07 00701 070701 25924 295362 07 Región EL Valle 07 00702 070702 6533 295362 07 Región EL Valle 07 00703 070703 8344 295362 07 Región EL Valle 07 00704 070704 10587 295362 07 Región EL Valle 07 00705 070705 7281 295362 07 Región EL Valle 07 00706 070706 4360 295362 07 Región EL Valle 22 02201 072201 132177 295362 07 Región EL Valle 22 02202 072202 9685 295362 07 Región EL Valle 22 02203 072203 20843 295362 07 Región EL Valle 22 02204 072204 13062 295362 07 Región EL Valle 22 02205 072205 44163 295362 07 Región EL Valle 22 02206 072206 12403 295362 08 Región Yuma 08 00801 080801 66867 606323 08 Región Yuma 08 00802 080802 20813 606323 08 Región Yuma 11 01101 081101 251243 606323 08 Región Yuma 11 01102 081102 21967 606323 08 Región Yuma 12 01201 081201 139671 606323 08 Región Yuma 12 01202 081202 16558 606323 08 Región Yuma 12 01203 081203 89204 606323 09 Región Higuamo 23 02301 092301 195307 561431 09 Región Higuamo 23 02302 092302 22573 561431 09 Región Higuamo 23 02303 092303 8901 561431 09 Región Higuamo 23 02304 092304 30051 561431 09 Región Higuamo 23 02305 092305 19034 561431 09 Región Higuamo 23 02306 092306 14592 561431 09 Región Higuamo 29 02901 092901 46723 561431 09 Región Higuamo 29 02902 092902 31889 561431 09 Región Higuamo 29 02903 092903 31096 561431 09 Región Higuamo 29 02904 092904 55348 561431 09 Región Higuamo 29 02905 092905 20900 561431 09 Región Higuamo 30 03001 093001 61517 561431 09 Región Higuamo 30 03002 093002 16272 561431 09 Región Higuamo 30 03003 093003 7228 561431 10 Región Ozama 01 00101 100101 965040 3339410 10 Región Ozama 32 03201 103201 948885 3339410 10 Región Ozama 32 03202 103202 363321 3339410 10 Región Ozama 32 03203 103203 529390 3339410 10 Región Ozama 32 03204 103204 142019 3339410 10 Región Ozama 32 03205 103205 43963 3339410 10 Región Ozama 32 03206 103206 272776 3339410 10 Región Ozama 32 03207 103207 74016 3339410 Obtener las estimaciones directa por región o el nivel de agregación en el cual la encuesta es representativa. En este código, se lee un archivo RDS de una encuesta y se utilizan las funciones transmute() y paste0() para seleccionar y transformar las variables de interés. En primer lugar, se crea una variable dam que corresponde al identificador de la división administrativa mayor de la encuesta. A continuación, se utiliza la columna dam_ee para crear una variable dam, se selecciona la variable dam2 que corresponde al identificador de la división administrativa municipal de segundo nivel (subdivisión del departamento) de la encuesta. Luego, se crea una variable wkx que corresponde al peso de la observación en la encuesta, y una variable upm que corresponde al identificador del segmento muestral en la encuesta. La variable estrato se crea utilizando la función paste0(), que concatena los valores de dam y area_ee (una variable que indica el área geográfica en la que se encuentra la vivienda de la encuesta). Finalmente, se crea una variable pobreza que toma el valor 1 si el ingreso de la vivienda es menor que un umbral lp, y 0 en caso contrario. encuesta &lt;- readRDS(&quot;Recursos/Día2/Sesion3/Data/encuestaDOM21N1.rds&quot;) %&gt;% transmute( dam = haven::as_factor(dam_ee,levels = &quot;values&quot;), dam = str_pad(dam,width = 2,pad = &quot;0&quot;), dam2, wkx = `_fep`, upm = `_upm`, estrato =`_estrato`, pobreza = ifelse(ingcorte &lt; lp, 1 , 0)) %&gt;% inner_join(N_dam_pp %&gt;% select(region,dam2) ) El código está realizando un análisis de datos de encuestas utilizando el paquete survey de R. Primero, se crea un objeto diseno de diseño de encuestas usando la función as_survey_design() del paquete srvyr, que incluye los identificadores de la unidad primaria de muestreo (upm), los pesos (wkx), las estratos (estrato) y los datos de la encuesta (encuesta). Posteriormente, se agrupa el objeto diseno por la variable “Agregado” y se calcula la media de la variable pobreza con un intervalo de confianza para toda la población utilizando la función survey_mean(). El resultado se guarda en el objeto directoDam y se muestra en una tabla. library(survey) library(srvyr) options(survey.lonely.psu = &quot;adjust&quot;) diseno &lt;- as_survey_design( ids = upm, weights = wkx, strata = estrato, nest = TRUE, .data = encuesta ) directoDam &lt;- diseno %&gt;% group_by(region) %&gt;% summarise( theta_dir = survey_mean(pobreza, vartype = c(&quot;ci&quot;)) ) tba(directoDam) region theta_dir theta_dir_low theta_dir_upp 01 0.1696 0.1472 0.1919 02 0.1618 0.1230 0.2007 03 0.1808 0.1371 0.2245 04 0.1714 0.1269 0.2160 05 0.2629 0.2287 0.2972 06 0.4221 0.3741 0.4702 07 0.2957 0.2316 0.3599 08 0.1998 0.1605 0.2392 09 0.2258 0.1817 0.2700 10 0.2409 0.2213 0.2604 Realizar el consolidando información obtenida en 1 y 2. temp &lt;- estimacionesPre %&gt;% inner_join(N_dam_pp %&gt;% select(region,dam2,pp_dam2,region_pp) ) %&gt;% inner_join(directoDam ) tba(temp %&gt;% slice(1:10)) dam2 theta_pred region pp_dam2 region_pp theta_dir theta_dir_low theta_dir_upp 00101 0.2204 10 965040 3339410 0.2409 0.2213 0.2604 00201 0.2234 05 91345 1028129 0.2629 0.2287 0.2972 00206 0.3097 05 19020 1028129 0.2629 0.2287 0.2972 00301 0.4158 06 36511 368594 0.4221 0.3741 0.4702 00302 0.4343 06 15702 368594 0.4221 0.3741 0.4702 00303 0.4579 06 26772 368594 0.4221 0.3741 0.4702 00304 0.4922 06 10619 368594 0.4221 0.3741 0.4702 00401 0.3379 06 83619 368594 0.4221 0.3741 0.4702 00402 0.2213 06 14823 368594 0.4221 0.3741 0.4702 00403 0.4380 06 13164 368594 0.4221 0.3741 0.4702 Con la información organizada realizar el calculo de los pesos para el Benchmark R_dam2 &lt;- temp %&gt;% group_by(region) %&gt;% summarise( R_dam_RB = unique(theta_dir) / sum((pp_dam2 / region_pp ) * theta_pred) ) tba(R_dam2) region R_dam_RB 01 1.0526 02 0.9339 03 1.1303 04 1.0137 05 1.0035 06 1.0894 07 0.9750 08 1.0018 09 0.8851 10 0.9941 calculando los pesos para cada dominio. pesos &lt;- temp %&gt;% mutate(W_i = pp_dam2 / region_pp) %&gt;% select(dam2, W_i) tba(pesos %&gt;% slice(1:10)) dam2 W_i 00101 0.2890 00201 0.0888 00206 0.0185 00301 0.0991 00302 0.0426 00303 0.0726 00304 0.0288 00401 0.2269 00402 0.0402 00403 0.0357 Realizar la estimación FH Benchmark En este proceso, se realiza la adición de una nueva columna denominada R_dam_RB, que es obtenida a partir de un objeto denominado R_dam2. Posteriormente, se agrega una nueva columna denominada theta_pred_RBench, la cual es igual a la multiplicación de R_dam_RB y theta_pred. Finalmente, se hace un left_join con el dataframe pesos, y se seleccionan únicamente las columnas dam, dam2, W_i, theta_pred y theta_pred_RBench para ser presentadas en una tabla (tba) que muestra únicamente las primeras 10 filas. estimacionesBench &lt;- estimacionesPre %&gt;% inner_join(N_dam_pp %&gt;% select(region,dam2) )%&gt;% left_join(R_dam2, by = c(&quot;region&quot;)) %&gt;% mutate(theta_pred_RBench = R_dam_RB * theta_pred) %&gt;% left_join(pesos) %&gt;% select(region, dam2, W_i, theta_pred, theta_pred_RBench) tba(estimacionesBench %&gt;% slice(1:10)) region dam2 W_i theta_pred theta_pred_RBench 10 00101 0.2890 0.2204 0.2191 05 00201 0.0888 0.2234 0.2242 05 00206 0.0185 0.3097 0.3108 06 00301 0.0991 0.4158 0.4529 06 00302 0.0426 0.4343 0.4731 06 00303 0.0726 0.4579 0.4988 06 00304 0.0288 0.4922 0.5362 06 00401 0.2269 0.3379 0.3681 06 00402 0.0402 0.2213 0.2411 06 00403 0.0357 0.4380 0.4771 Validación: Estimación FH con Benchmark estimacionesBench %&gt;% group_by(region) %&gt;% summarise(theta_reg_RB = sum(W_i * theta_pred_RBench)) %&gt;% left_join(directoDam, by = &quot;region&quot;) %&gt;% tba() region theta_reg_RB theta_dir theta_dir_low theta_dir_upp 01 0.1696 0.1696 0.1472 0.1919 02 0.1618 0.1618 0.1230 0.2007 03 0.1808 0.1808 0.1371 0.2245 04 0.1714 0.1714 0.1269 0.2160 05 0.2629 0.2629 0.2287 0.2972 06 0.4221 0.4221 0.3741 0.4702 07 0.2957 0.2957 0.2316 0.3599 08 0.1998 0.1998 0.1605 0.2392 09 0.2258 0.2258 0.1817 0.2700 10 0.2409 0.2409 0.2213 0.2604 "],["validación-de-los-resultados..html", "7.4 Validación de los resultados.", " 7.4 Validación de los resultados. Este código junta las estimaciones del modelo con pesos de benchmarking con los valores observados y sintéticos, y luego resume las estimaciones combinadas para compararlas con la estimación directa obtenida anteriormente. temp &lt;- estimacionesBench %&gt;% left_join( bind_rows( data_dir %&gt;% select(dam2, thetaSyn, thetaFH), data_syn %&gt;% select(dam2, thetaSyn, thetaFH))) %&gt;% group_by(region) %&gt;% summarise(thetaSyn = sum(W_i * thetaSyn), thetaFH = sum(W_i * theta_pred), theta_RBench = sum(W_i * theta_pred_RBench) ) %&gt;% left_join(directoDam, by = &quot;region&quot;) %&gt;% mutate(id = 1:n()) temp %&lt;&gt;% gather(key = &quot;Metodo&quot;,value = &quot;Estimacion&quot;, -id, -region, -theta_dir_upp, -theta_dir_low) ggplot(data = temp, aes(x = id, y = Estimacion, shape = Metodo)) + geom_point(aes(color = Metodo), size = 2) + geom_line(aes(y = theta_dir_low), linetype = 2) + geom_line(aes(y = theta_dir_upp), linetype = 2) + theme_bw(10) + labs(y = &quot;&quot;, x = &quot;&quot;) "],["mapa-de-pobreza.html", "7.5 Mapa de pobreza", " 7.5 Mapa de pobreza Este es un bloque de código se cargan varios paquetes (sp, sf, tmap) y realiza algunas operaciones. Primero, realiza una unión (left_join) entre las estimaciones de ajustadas por el Benchmarking (estimacionesBench) y las estimaciones del modelo (data_dir, data_syn), utilizando la variable dam2 como clave para la unión. Luego, lee un archivo Shapefile que contiene información geoespacial del país. A continuación, crea un mapa temático (tmap) utilizando la función tm_shape() y agregando capas con la función tm_polygons(). El mapa representa una variable theta_pred_RBench utilizando una paleta de colores llamada “YlOrRd” y establece los cortes de los intervalos de la variable con la variable brks_lp. Finalmente, la función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). library(sp) library(sf) library(tmap) estimacionesBench %&lt;&gt;% left_join( bind_rows( data_dir %&gt;% select(dam2, theta_pred_EE , Cv_theta_pred), data_syn %&gt;% select(dam2, theta_pred_EE , Cv_theta_pred))) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día2/Sesion3/Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(estimacionesBench, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.1,0.15, 0.2, 0.3, 0.4, 0.6, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;theta_pred_RBench&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) tmap_save( Mapa_lp, &quot;Recursos/Día2/Sesion3/0Recursos/Mapa_DOM_pobreza_normal.png&quot;, width = 2000, height = 1500, asp = 0 ) Mapa_lp "],["día-3---sesión-1--modelos-de-área---estimación-de-la-pobreza-y-la-transformación-arcoseno..html", "Capítulo 8 Día 3 - Sesión 1- Modelos de área - Estimación de la pobreza y la transformación ArcoSeno.", " Capítulo 8 Día 3 - Sesión 1- Modelos de área - Estimación de la pobreza y la transformación ArcoSeno. En su concepción más básica, el modelo de Fay-Herriot es una combinación lineal de covariables. Sin embargo, el resultado de esta combinación pueden tomar valores que se salen del rango aceptable en el que puede estar una proporción; es decir, en general el estimador de Fay-Herriot \\(\\theta \\in R\\), mientras que el estimador directo \\(\\theta \\in (0,1)\\). La transformación arcoseno esta dada por: \\[ \\hat{z}_d = arcsin\\left( \\sqrt{ \\hat{\\theta}_d} \\right) \\] donde \\[ Var\\left( \\hat{z}_d \\right) = \\frac{\\widehat{DEFF}_d}{4\\times n_d} = \\frac{1}{4\\times n_{d,efectivo} } \\] El modelo de Fay-Herriot estaría definido de la siguiente forma: \\[ \\begin{eqnarray*} Z_d \\mid \\mu_d,\\sigma^2_d &amp; \\sim &amp; N(\\mu_d, \\sigma^2_d)\\\\ \\mu_d &amp; = &amp; \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d \\\\ \\theta_d &amp; = &amp; \\left(sin(\\mu_d)\\right)^2 \\end{eqnarray*} \\] donde \\(u_d \\sim N(0 , \\sigma^2)\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{u}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,1000 \\right)\\\\ \\sigma_{u}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] "],["procedimiento-de-estimación-1.html", "8.1 Procedimiento de estimación", " 8.1 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/base_FH_2018.rds&quot;) %&gt;% transmute(dam2, ## id dominios pobreza, T_pobreza = asin(sqrt(pobreza)), ## creando zd n_effec = n_eff_FGV, ## n efectivo varhat = 1/(4*n_effec) ## varianza para zd ) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH, statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 pobreza T_pobreza n_effec varhat modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 00101 0.2225 0.4912 332.3384 0.0008 3.6127 -1.1835 -1.5653 00201 0.1822 0.4409 28.0165 0.0089 -0.0553 0.4449 0.2100 00206 0.3366 0.6190 44.7971 0.0056 0.5157 -0.1468 -0.1811 00301 0.4266 0.7117 125.6580 0.0020 0.1364 0.5744 1.1660 00302 0.4461 0.7314 261.0000 0.0010 -0.5103 0.2531 1.0880 00303 0.5587 0.8442 75.7938 0.0033 -0.6591 0.6249 1.2229 00304 0.5406 0.8261 154.4069 0.0016 -0.5573 1.4586 2.7337 00401 0.3359 0.6182 105.4750 0.0024 0.3979 -0.0833 -0.4490 00402 0.1496 0.3972 59.6357 0.0042 -0.3661 -0.0114 -0.2863 00403 0.4644 0.7498 197.2378 0.0013 -1.0446 0.4542 0.5702 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;anoest2&quot; , &quot;anoest3&quot;, &quot;anoest4&quot;, &quot;edad2&quot; , &quot;edad3&quot; , &quot;edad4&quot; , &quot;edad5&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;alfabeta&quot; ) "],["preparando-los-insumos-para-stan-1.html", "8.2 Preparando los insumos para STAN", " 8.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(T_pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[,1:8] %&gt;% slice(1:10)) dam2 pobreza T_pobreza n_effec varhat modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 00202 NA NA NA NA -0.3758 0.0000 0.1482 00203 NA NA NA NA -0.9259 0.5732 -0.1402 00204 NA NA NA NA -1.3166 1.1111 0.4438 00205 NA NA NA NA -0.7474 2.1155 1.2271 00207 NA NA NA NA 1.7368 -0.7648 -0.4861 00208 NA NA NA NA -0.5942 0.3212 -0.1697 00209 NA NA NA NA -1.5280 3.0192 1.9428 00210 NA NA NA NA -1.0038 0.5778 0.2678 00305 NA NA NA NA -0.8480 1.5047 3.2004 00404 NA NA NA NA -0.5678 1.0735 0.9856 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- cbind(inter = 1,data_dir[,names_cov]) ## Dominios no observados Xs &lt;- cbind(inter = 1,data_syn[,names_cov]) Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$T_pobreza), sigma_e = sqrt(data_dir$varhat) ) Compilando el modelo en STAN library(rstan) fit_FH_arcoseno &lt;- &quot;Recursos/Día3/Sesion1/Data/modelosStan/15FH_arcsin_normal.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_arcoseno &lt;- stan( file = fit_FH_arcoseno, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_arcoseno, &quot;Recursos/Día3/Sesion1/Data/model_FH_arcoseno.rds&quot;) model_FH_arcoseno &lt;- readRDS(&quot;Recursos/Día3/Sesion1/Data/model_FH_arcoseno.rds&quot;) 8.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_arcoseno, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_u\\). posterior_sigma2_u &lt;- as.array(model_FH_arcoseno, pars = &quot;sigma2_u&quot;) (mcmc_dens_chains(posterior_sigma2_u) + mcmc_areas(posterior_sigma2_u) ) / mcmc_trace(posterior_sigma2_u) # traceplot(model_FH_arcoseno,pars = &quot;sigma2_u&quot;,inc_warmup = TRUE) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_arcoseno,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_arcoseno = theta_FH$mean, pred_arcoseno_EE = theta_FH$sd, Cv_pred = pred_arcoseno_EE/pred_arcoseno) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_arcoseno,pars = &quot;theta_pred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_arcoseno = theta_FH_pred$mean, pred_arcoseno_EE = theta_FH_pred$sd, Cv_pred = pred_arcoseno_EE/pred_arcoseno) "],["mapa-de-pobreza-1.html", "8.3 Mapa de pobreza", " 8.3 Mapa de pobreza El siguiente bloque de código carga los paquetes sp, sf y tmap, y realiza algunas operaciones. Primero, une (rbind) las estimaciones de los dominios observados y los no observados (data_dir, data_syn) y selecciona las variables dam2, pobreza, pred_arcoseno, pred_arcoseno_EE y Cv_pred utilizando la función select(). Luego, lee un archivo Shapefile que contiene información geoespacial del país. A continuación, crea un mapa temático (tmap) utilizando la función tm_shape() y agregando capas con la función tm_polygons(). El mapa representa dos variables llamadas pobreza y pred_arcoseno, utilizando una paleta de colores llamada “YlOrRd” y establece los cortes de los intervalos de las variables con la variable brks_lp. Finalmente, la función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, pobreza, pred_arcoseno, pred_arcoseno_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día3/Sesion1/Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.15, 0.3, 0.45, 0.6, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;pobreza&quot;, &quot;pred_arcoseno&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) tmap_save( Mapa_lp, &quot;Recursos/Día3/Sesion1/0Recursos/Mapa_arcoseno.PNG&quot;, width = 2000, height = 1500, asp = 0 ) Mapa_lp "],["mapa-del-coeficiente-de-variación..html", "8.4 Mapa del coeficiente de variación.", " 8.4 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de pobreza(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) tmap_save( Mapa_cv, &quot;Recursos/Día3/Sesion1/0Recursos/Mapa_arcoseno_cv.PNG&quot;, width = 2000, height = 1500, asp = 0 ) Mapa_cv "],["día-3---sesión-2--modelos-de-área---estimación-de-la-pobreza-en-familias-beta-y-binomial.html", "Capítulo 9 Día 3 - Sesión 2- Modelos de área - Estimación de la pobreza en familias beta y binomial ", " Capítulo 9 Día 3 - Sesión 2- Modelos de área - Estimación de la pobreza en familias beta y binomial "],["modelo-de-fay-herriot-de-variable-respuesta-beta..html", "9.1 Modelo de Fay Herriot de variable respuesta beta.", " 9.1 Modelo de Fay Herriot de variable respuesta beta. El modelo beta-logístico fue inicialmente considerado por Jiang y Lahiri (2006b) para un enfoque EBP en uno de sus ejemplos ilustrativos para estimar medias de dominio de población finita. El modelo Fay Herriot beta-logístico estaría dado por las siguientes expresiones \\[ \\begin{eqnarray*} \\hat{p}_{d} \\mid P_d &amp; \\sim &amp; beta(a_d, b_d)\\\\ \\end{eqnarray*} \\] La función del enlace es \\[ \\begin{eqnarray*} logit(P_{d}) \\mid \\boldsymbol{\\beta}, \\sigma^2_u &amp; \\sim &amp; N(\\boldsymbol{x}_d^T\\boldsymbol{\\beta},\\sigma^2_u)\\\\ \\end{eqnarray*} \\] Los parámetros \\(a_d\\) y \\(b_d\\) son estimados así: \\[ \\begin{eqnarray*} a_d &amp;=&amp; P_d \\times \\phi_d\\\\ b_d &amp;=&amp; (1 - P_d) \\times \\phi_d\\\\ \\end{eqnarray*} \\] donde \\[\\phi_d = \\frac{n_d}{\\widehat{DEFF}_d} -1 = n_{d,efecctivo} -1\\] Las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma^2_u\\) \\[ \\begin{eqnarray*} \\beta_k &amp;\\sim&amp; N(0, 10000)\\\\ \\sigma^2_u &amp;\\sim&amp; IG(0.0001,0.0001) \\end{eqnarray*} \\] 9.1.1 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/base_FH_2018.rds&quot;) %&gt;% select(dam2, pobreza, n_eff_FGV) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH,statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 pobreza n_eff_FGV modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano 00101 0.2225 332.3384 3.6127 -1.1835 -1.5653 -1.1560 7.2782 00201 0.1822 28.0165 -0.0553 0.4449 0.2100 0.0684 -0.0682 00206 0.3366 44.7971 0.5157 -0.1468 -0.1811 1.1894 -0.1191 00301 0.4266 125.6580 0.1364 0.5744 1.1660 0.2836 -0.1721 00302 0.4461 261.0000 -0.5103 0.2531 1.0880 -0.5047 -0.3326 00303 0.5587 75.7938 -0.6591 0.6249 1.2229 0.1100 -0.3174 00304 0.5406 154.4069 -0.5573 1.4586 2.7337 -0.8314 -0.2399 00401 0.3359 105.4750 0.3979 -0.0833 -0.4490 -0.7770 0.1784 00402 0.1496 59.6357 -0.3661 -0.0114 -0.2863 -0.5372 -0.2723 00403 0.4644 197.2378 -1.0446 0.4542 0.5702 -0.4029 -0.4017 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;anoest2&quot; , &quot;anoest3&quot;, &quot;anoest4&quot;, &quot;edad2&quot; , &quot;edad3&quot; , &quot;edad4&quot; , &quot;edad5&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;alfabeta&quot; ) 9.1.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[,1:8] %&gt;% slice(1:10)) dam2 pobreza n_eff_FGV modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano 00202 NA NA -0.3758 0.0000 0.1482 -0.2345 -0.2855 00203 NA NA -0.9259 0.5732 -0.1402 -0.5511 -0.3822 00204 NA NA -1.3166 1.1111 0.4438 -0.5027 -0.3835 00205 NA NA -0.7474 2.1155 1.2271 -0.5838 -0.3345 00207 NA NA 1.7368 -0.7648 -0.4861 0.7170 -0.0609 00208 NA NA -0.5942 0.3212 -0.1697 -0.3627 -0.3044 00209 NA NA -1.5280 3.0192 1.9428 -0.8078 -0.4046 00210 NA NA -1.0038 0.5778 0.2678 -0.4900 -0.3898 00305 NA NA -0.8480 1.5047 3.2004 -0.8621 -0.3140 00404 NA NA -0.5678 1.0735 0.9856 -1.1497 -0.3840 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- data_dir[,names_cov] ## Dominios no observados Xs &lt;- data_syn[,names_cov] Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$pobreza), phi = data_dir$n_eff_FGV - 1 ) Compilando el modelo en STAN library(rstan) fit_FH_beta_logitic &lt;- &quot;Recursos/Día3/Sesion2/Data/modelosStan/16FH_beta_logitc.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_beta_logitic &lt;- stan( file = fit_FH_beta_logitic, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_beta_logitic, file = &quot;Recursos/Día3/Sesion2/Data/model_FH_beta_logitic.rds&quot;) model_FH_beta_logitic &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/model_FH_beta_logitic.rds&quot;) 9.1.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_beta_logitic, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_u\\). posterior_sigma2_u &lt;- as.array(model_FH_beta_logitic, pars = &quot;sigma2_u&quot;) (mcmc_dens_chains(posterior_sigma2_u) + mcmc_areas(posterior_sigma2_u) ) / mcmc_trace(posterior_sigma2_u) # traceplot(model_FH_beta_logitic, pars = &quot;sigma2_u&quot;,inc_warmup = TRUE) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_beta_logitic,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_beta_logit = theta_FH$mean, pred_beta_logit_EE = theta_FH$sd, Cv_pred = pred_beta_logit_EE/pred_beta_logit) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_beta_logitic,pars = &quot;thetapred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_beta_logit = theta_FH_pred$mean, pred_beta_logit_EE = theta_FH_pred$sd, Cv_pred = pred_beta_logit_EE/pred_beta_logit) 9.1.2.2 Mapa de pobreza El mapa muestra el nivel de pobreza en diferentes áreas de Colombia, basado en dos variables, pobreza y pred_beta_logit. Primero, se cargan los paquetes necesarios sp, sf y tmap. Luego, se lee la información de los datos en R y se combinan utilizando la función rbind(). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, pobreza, pred_beta_logit, pred_beta_logit_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día3/Sesion2/Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.15, 0.3, 0.45, 0.6, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;pobreza&quot;, &quot;pred_beta_logit&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) tmap_save( Mapa_lp, &quot;Recursos/Día3/Sesion2/0Recursos/Beta.PNG&quot;, width = 2000, height = 1500, asp = 0 ) Mapa_lp 9.1.2.3 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de pobreza(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) tmap_save( Mapa_cv, &quot;Recursos/Día3/Sesion2/0Recursos/Beta_cv.PNG&quot;, width = 2000, height = 1500, asp = 0 ) Mapa_cv "],["modelo-fay-herriot-de-variable-respuesta-beta..html", "9.2 Modelo Fay Herriot de variable respuesta beta.", " 9.2 Modelo Fay Herriot de variable respuesta beta. El modelo lineal de Fay-Herriot puede ser reemplazado por un modelo mixto lineal generalizado (GLMM). Esto se puede hacer cuando los datos observados \\(Y_d\\) son inherentemente discretos, como cuando son recuentos (no ponderados) de personas u hogares muestreados con ciertas características. Uno de estos modelos supone una distribución binomial para \\(Y_d\\) con probabilidad de éxito \\(\\theta_d\\), y una logística modelo de regresión para \\(\\theta_d\\) con errores normales en la escala logit. El modelo resultante es \\[ \\begin{eqnarray*} Y_{d}\\mid \\theta_{d},n_{d} &amp; \\sim &amp; Bin\\left(n_{d},\\theta_{d}\\right) \\end{eqnarray*} \\] para \\(d=1,\\dots,D\\) y \\[ \\begin{eqnarray*} logit\\left(\\theta_{d}\\right)=\\log\\left(\\frac{\\theta_{d}}{1-\\theta_{d}}\\right) &amp; = &amp; \\boldsymbol{x}_{d}^{T}\\boldsymbol{\\beta}+u_{d} \\end{eqnarray*} \\] donde \\(u_{d}\\sim N\\left(0,\\sigma_{u}^{2}\\right)\\) y \\(n_{d}\\) es el tamaño de la muestra para el área \\(d\\). El modelo anterior se puede aplicar fácilmente a recuentos de muestras no ponderadas \\(Y_d\\), pero esto ignora cualquier aspecto complejo del diseño de la encuesta. En muestras complejas donde las \\(Y_d\\) son estimaciones ponderadas, surgen dos problemas. En primer lugar, los posibles valores de el \\(Y_d\\) no serán los números enteros \\(0, 1, \\dots , n_d\\) para cualquier definición directa de tamaño de muestra \\(n_d\\). En su lugar, \\(Y_d\\) tomará un valor de un conjunto finito de números desigualmente espaciados determinados por las ponderaciones de la encuesta que se aplican a los casos de muestra en el dominio \\(d\\). En segundo lugar, la varianza muestral de \\(Y_d\\) implícito en la distribución Binomial, es decir, \\(n_d \\times \\theta_d (1-\\theta_d)\\), será incorrecto. Abordamos estos dos problemas al definir un tamaño de muestra efectivo \\(\\tilde{n}_d\\), y un número de muestra efectivo de éxitos \\(\\tilde{Y_d}\\) determinó mantener: (i) la estimación directa \\(\\hat{\\theta}_i\\), de la pobreza y (ii) una estimación de la varianza de muestreo correspondiente,\\(\\widehat{Var}(\\hat{\\theta}_d)\\). Es posible suponer que \\[ \\begin{eqnarray*} \\tilde{n}_{d} &amp; \\sim &amp; \\frac{\\check{\\theta}_{d}\\left(1-\\check{\\theta}_{d}\\right)}{\\widehat{Var}\\left(\\hat{\\theta}_{d}\\right)} \\end{eqnarray*} \\] donde \\(\\check{\\theta}_{d}\\) es una preliminar perdicción basada en el modelo para la proporción poblacional \\(\\theta_d\\) y \\(\\widehat{Var}\\left(\\hat{\\theta}_{d}\\right)\\) depende de\\(\\check{\\theta}_{d}\\) a través de una función de varianza generalizada ajustada (FGV). Note que \\(\\tilde{Y}_{d}=\\tilde{n}_{d}\\times\\hat{\\theta}_{d}\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{u}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,10000\\right)\\\\ \\sigma_{u}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] 9.2.1 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/base_FH_2018.rds&quot;) %&gt;% select(dam2, pobreza, n_eff_FGV) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH,statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 pobreza n_eff_FGV modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano 00101 0.2225 332.3384 3.6127 -1.1835 -1.5653 -1.1560 7.2782 00201 0.1822 28.0165 -0.0553 0.4449 0.2100 0.0684 -0.0682 00206 0.3366 44.7971 0.5157 -0.1468 -0.1811 1.1894 -0.1191 00301 0.4266 125.6580 0.1364 0.5744 1.1660 0.2836 -0.1721 00302 0.4461 261.0000 -0.5103 0.2531 1.0880 -0.5047 -0.3326 00303 0.5587 75.7938 -0.6591 0.6249 1.2229 0.1100 -0.3174 00304 0.5406 154.4069 -0.5573 1.4586 2.7337 -0.8314 -0.2399 00401 0.3359 105.4750 0.3979 -0.0833 -0.4490 -0.7770 0.1784 00402 0.1496 59.6357 -0.3661 -0.0114 -0.2863 -0.5372 -0.2723 00403 0.4644 197.2378 -1.0446 0.4542 0.5702 -0.4029 -0.4017 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;anoest2&quot; , &quot;anoest3&quot;, &quot;anoest4&quot;, &quot;edad2&quot; , &quot;edad3&quot; , &quot;edad4&quot; , &quot;edad5&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;alfabeta&quot; ) 9.2.2 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[1:10,1:8]) dam2 pobreza n_eff_FGV modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano 00202 NA NA -0.3758 0.0000 0.1482 -0.2345 -0.2855 00203 NA NA -0.9259 0.5732 -0.1402 -0.5511 -0.3822 00204 NA NA -1.3166 1.1111 0.4438 -0.5027 -0.3835 00205 NA NA -0.7474 2.1155 1.2271 -0.5838 -0.3345 00207 NA NA 1.7368 -0.7648 -0.4861 0.7170 -0.0609 00208 NA NA -0.5942 0.3212 -0.1697 -0.3627 -0.3044 00209 NA NA -1.5280 3.0192 1.9428 -0.8078 -0.4046 00210 NA NA -1.0038 0.5778 0.2678 -0.4900 -0.3898 00305 NA NA -0.8480 1.5047 3.2004 -0.8621 -0.3140 00404 NA NA -0.5678 1.0735 0.9856 -1.1497 -0.3840 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- data_dir[,names_cov] ## Dominios no observados Xs &lt;- data_syn[,names_cov] Obteniendo el tamaño de muestra efectivo \\(\\tilde{n}_d\\), y el número de muestra efectivo de éxitos \\(\\tilde{Y_d}\\) n_effec = round(data_dir$n_eff_FGV) y_effect = round((data_dir$pobreza)*n_effec) Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados n_effec = n_effec, y_effect = y_effect # Estimación directa. ) Compilando el modelo en STAN library(rstan) fit_FH_binomial &lt;- &quot;Recursos/Día3/Sesion2/Data/modelosStan/14FH_binomial.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_Binomial &lt;- stan( file = fit_FH_binomial, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_Binomial, file = &quot;Recursos/Día3/Sesion2/Data/model_FH_Binomial.rds&quot;) Leer el modelo model_FH_Binomial &lt;- readRDS(&quot;Recursos/Día3/Sesion2/Data/model_FH_Binomial.rds&quot;) 9.2.2.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_Binomial, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$pobreza), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma_u\\). posterior_sigma_u &lt;- as.array(model_FH_Binomial, pars = &quot;sigma_u&quot;) (mcmc_dens_chains(posterior_sigma_u) + mcmc_areas(posterior_sigma_u) ) / mcmc_trace(posterior_sigma_u) # traceplot(model_FH_Binomial,pars = &quot;sigma_u&quot;,inc_warmup = TRUE) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_Binomial,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_binomial = theta_FH$mean, pred_binomial_EE = theta_FH$sd, Cv_pred = pred_binomial_EE/pred_binomial) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_Binomial,pars = &quot;thetaLP&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_binomial = theta_FH_pred$mean, pred_binomial_EE = theta_FH_pred$sd, Cv_pred = pred_binomial_EE/pred_binomial) 9.2.2.2 Mapa de pobreza El mapa muestra el nivel de pobreza en diferentes áreas de Colombia, basado en dos variables, pobreza y pred_binomial. Primero, se cargan los paquetes necesarios sp, sf y tmap. Luego, se lee la información de los datos en R y se combinan utilizando la función rbind(). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, pobreza, pred_binomial, pred_binomial_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día3/Sesion2/Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- c(0,0.15, 0.3, 0.45, 0.6, 1) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;pobreza&quot;, &quot;pred_binomial&quot;), breaks = brks_lp, title = &quot;Mapa de pobreza&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 2.5) tmap_save( Mapa_lp, &quot;Recursos/Día3/Sesion2/0Recursos/Binomial3.PNG&quot;, width = 3000, height = 2000, asp = 0 ) Mapa_lp 9.2.2.3 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de pobreza(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout( legend.only = FALSE, legend.height = 0.95, legend.width = 0.95, asp = 0, legend.text.size = 1, legend.title.size = 1 ) tmap_save( Mapa_cv, &quot;Recursos/Día3/Sesion2/0Recursos/Binomial3_cv.PNG&quot;, width = 3000, height = 2000, asp = 0 ) Mapa_cv "],["día-3---sesión-3--modelos-de-área---estimación-de-la-informalidad-laboral..html", "Capítulo 10 Día 3 - Sesión 3- Modelos de área - Estimación de la informalidad laboral.", " Capítulo 10 Día 3 - Sesión 3- Modelos de área - Estimación de la informalidad laboral. La informalidad laboral es un fenómeno que ha sido objeto de estudio en la República Dominicana y en Latinoamérica debido a su impacto en el mercado laboral y en el desarrollo social. Según “La informalidad en el mercado laboral urbano de la República Dominicana”, la informalidad laboral se refiere a la falta de registro y protección social de los trabajadores, así como a la ausencia de derechos laborales y condiciones de trabajo dignas. A pesar de que existe una definición común, la medición de la informalidad varía según el enfoque y la metodología utilizada, lo cual puede generar diferencias en los resultados obtenidos. En la República Dominicana, la informalidad laboral es un fenómeno que afecta principalmente a los trabajadores del sector informal, que representan más de la mitad de la fuerza laboral del país. Este sector se caracteriza por la falta de protección social, la inestabilidad laboral y la baja remuneración, lo que limita las oportunidades de desarrollo de los trabajadores y sus familias. Además, la informalidad laboral tiene un impacto negativo en la economía del país, ya que reduce la recaudación fiscal y limita la inversión en programas sociales y de desarrollo. Es importante conocer estas estimaciones de la informalidad laboral para comprender las desigualdades económicas y laborales en el país y desarrollar medidas para proteger los derechos laborales de los trabajadores informales y mejorar la economía del país en general. "],["estimaciones-directas..html", "10.1 Estimaciones directas.", " 10.1 Estimaciones directas. En este apartado realizaremos las estimaciones directas para los dominios que fueron seleccionados en la muestra, dado que estos fueron no planeados. Las estimaciones directas son una herramienta comúnmente utilizada en la estadística inferencial para obtener información sobre una población a partir de una muestra. Sin embargo, estas estimaciones pueden presentar problemas cuando la muestra es pequeña, lo que puede conducir a una falta de precisión en las estimaciones y a una mayor incertidumbre en las conclusiones que se puedan extraer. encuestaDOM &lt;- readRDS(&quot;Recursos/Día3/Sesion3/Data/encuestaDOM.Rds&quot;) encuestaDOM &lt;- encuestaDOM %&gt;% transmute( dam2 = id_dominio, upm = str_pad(string = upm,width = 9,pad = &quot;0&quot;), estrato = str_pad(string = estrato,width = 5,pad = &quot;0&quot;), factor_anual = factor_expansion / 4, pet, ocupado,orden_sector ) %&gt;% filter(ocupado == 1 &amp; pet == 1) Para la definición del diseño se hace uso de la librería survey como se muestra en el siguiente código options(survey.lonely.psu= &#39;adjust&#39; ) disenoDOM &lt;- encuestaDOM %&gt;% as_survey_design( strata = estrato, ids = upm, weights = factor_anual, nest=T ) 10.1.1 Calculo del indicador La informalidad laboral en República Dominicana se define como el trabajo que se realiza al margen de las leyes tributarias y laborales, así como aquel que busca evadir sus obligaciones fiscales ante las agencias del gobierno. Para definir el indicador de la informalidad laboral en República Dominicana, se utiliza la siguiente fórmula: \\[ Tas\\ de\\ informalidad\\ laboral = \\frac{Número\\ de\\ trabajadores\\ informales}{ Población\\ económicamente\\ activa} \\times 100. \\] Este bloque de código realiza lo siguiente: Se agrupa la encuesta por dam2 Se calcula el tamaño muestral no ponderado (n()). Se calcula la razón de la variable orden_sector igual a 2 sobre la variable constante igual a 1 mediante el uso de survey_ratio(), que utiliza los pesos de muestreo para producir estimaciones de varianza y errores estándar apropiados para el muestreo complejo. La función survey_ratio() también permite calcular intervalos de confianza y coeficientes de variación. indicador_dom &lt;- disenoDOM %&gt;% group_by(dam2) %&gt;% summarise( n = unweighted(n()), Rd = survey_ratio( numerator = orden_sector == 2 , denominator = 1, vartype = c(&quot;se&quot;, &quot;ci&quot;, &quot;var&quot;, &quot;cv&quot;), deff = T ) ) Ahora, como parte del proceso es necesario incorporar la información del número de upm por dam2, para lo cual se hace n_upm &lt;- encuestaDOM %&gt;% distinct(dam2, upm) %&gt;% group_by(dam2) %&gt;% tally(name = &quot;n_upm&quot;,sort = TRUE) indicador_dom &lt;- inner_join(n_upm,indicador_dom) saveRDS(object = indicador_dom, file = &quot;Recursos/Día3/Sesion3/Data/indicador_dom.rds&quot;) dam2 n_upm n Rd Rd_se Rd_low Rd_upp Rd_var Rd_cv Rd_deff 0101 126 2951 0.4147 0.0234 0.3688 0.4605 0.0005 0.0564 6.6763 3201 108 2840 0.4233 0.0186 0.3868 0.4597 0.0003 0.0439 4.0432 2501 87 3057 0.4108 0.0192 0.3731 0.4485 0.0004 0.0467 4.6897 3203 59 1944 0.4858 0.0202 0.4462 0.5255 0.0004 0.0416 3.1956 3202 42 1046 0.4221 0.0247 0.3736 0.4706 0.0006 0.0585 2.6301 1101 38 1198 0.3788 0.0347 0.3107 0.4469 0.0012 0.0916 6.1659 3206 32 836 0.3968 0.0252 0.3474 0.4462 0.0006 0.0635 2.2273 0901 20 743 0.5236 0.0529 0.4198 0.6273 0.0028 0.1010 8.3883 1301 20 738 0.4899 0.0338 0.4236 0.5562 0.0011 0.0690 3.3902 2101 20 505 0.4522 0.0391 0.3756 0.5289 0.0015 0.0864 3.1216 "],["función-generalizada-de-varianza.html", "10.2 Función Generalizada de Varianza", " 10.2 Función Generalizada de Varianza La Función Generalizada de Varianza (FGV) es una técnica estadística utilizada para suavizar las estimaciones de las varianzas directas de los estimadores. Esta técnica busca estimar la varianza suavizada del estimador directo a través de un modelo log-lineal que involucra un vector de covariables auxiliares. La GVF es particularmente útil para modelar las varianzas de los estimadores directos, ya que permite lidiar con la naturaleza positiva de este parámetro. Además, esta técnica ha sido ampliamente utilizada en la literatura para estimar la varianza de los estimadores directos en diferentes contextos, incluyendo la estimación de ingreso per-cápita en los Estados Unidos, cifras oficiales del mercado de trabajo en Canadá y las tasas de pobreza comunal en la región. En este sentido, la GVF se plantea en términos de una relación log-lineal con un vector de covariables auxiliares que puede variar dependiendo del contexto en que se aplique. El proceso continua con la selección de las dam que posean una varianza estimada mayor que cero, un deff mayor que 1 y 2 o más UPMs. Para los dominios que superan estas condiciones se realiza la transformación \\(\\log(\\hat{\\sigma}^2_d)\\), además se realiza la selección de las columnas identificador del municipio (id_dominio), la estimación directa del indicador (Rd), El número de personas en el dominio (n) y la varianza estimada del para la estimación directa Rd_var,siendo esta la que transforma mediante la función log(). indicador_dom1 &lt;- indicador_dom %&gt;% filter(Rd_var&gt;0 &amp; Rd_deff&gt;=1 &amp; n_upm &gt;= 2) baseFGV &lt;- indicador_dom1 %&gt;% dplyr::select(dam2 , Rd, n, Rd_var) %&gt;% mutate(ln_sigma2 = log(Rd_var)) 10.2.1 Gráficas exploratorias El código muestra la creación de cuatro gráficos usando la librería ggplot2 y el uso de los datos baseFGV. Estos gráficos tienen como objetivo explorar la relación entre el logaritmo de la varianza y diferentes transformaciones de la n y Rd. El primer gráfico (p1) representa la relación entre la estimación directa y el logaritmo de la varianza. El segundo gráfico (p2) representa la relación entre el tamaño de muestra y el logaritmo de la varianza. El tercer gráfico (p3) representa la relación entre \\(n_d \\times Rd\\) y el logaritmo de la varianza. Finalmente, el cuarto gráfico (p4) representa la relación entre la raíz cuadrada de la estimación directa y el logaritmo de la varianza. library(patchwork) p1 &lt;- ggplot(baseFGV, aes(x = Rd, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Formal&quot;) p2 &lt;- ggplot(baseFGV, aes(x = n, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Tamaño de muestra&quot;) p3 &lt;- ggplot(baseFGV, aes(x = Rd * n, y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Número de Formales&quot;) p4 &lt;- ggplot(baseFGV, aes(x = sqrt(Rd), y = ln_sigma2)) + geom_point() + geom_smooth(method = &quot;loess&quot;) + xlab(&quot;Raiz cuadrada de tasa de formalidad&quot;) (p1 | p2) / (p3 | p4) rm(&#39;p1&#39;,&#39;p2&#39;,&#39;p3&#39;,&#39;p4&#39;) 10.2.2 Ajustando el modelo log-lineal de la varianza El código ajusta un modelo de regresión lineal múltiple (utilizando la función lm()), donde ln_sigma2 es la variable respuesta y las variables predictoras son Rd, n, y varias transformaciones de éstas. El objetivo de este modelo es estimar la función generalizada de varianza (FGV) para los dominios observados. library(gtsummary) FGV1 &lt;- lm(ln_sigma2 ~ 1 + Rd + n + I(n ^ 2) + I(Rd * n) + I(sqrt(Rd)) + I(sqrt(n)) + I(sqrt(Rd * n)) , data = baseFGV) tbl_regression(FGV1) %&gt;% add_glance_table(include = c(r.squared, adj.r.squared)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #iguswyzxws .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #iguswyzxws .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #iguswyzxws .gt_caption { padding-top: 4px; padding-bottom: 4px; } #iguswyzxws .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #iguswyzxws .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #iguswyzxws .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iguswyzxws .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #iguswyzxws .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #iguswyzxws .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #iguswyzxws .gt_column_spanner_outer:first-child { padding-left: 0; } #iguswyzxws .gt_column_spanner_outer:last-child { padding-right: 0; } #iguswyzxws .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #iguswyzxws .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #iguswyzxws .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #iguswyzxws .gt_from_md > :first-child { margin-top: 0; } #iguswyzxws .gt_from_md > :last-child { margin-bottom: 0; } #iguswyzxws .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #iguswyzxws .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #iguswyzxws .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #iguswyzxws .gt_row_group_first td { border-top-width: 2px; } #iguswyzxws .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #iguswyzxws .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #iguswyzxws .gt_first_summary_row.thick { border-top-width: 2px; } #iguswyzxws .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iguswyzxws .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #iguswyzxws .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #iguswyzxws .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #iguswyzxws .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #iguswyzxws .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #iguswyzxws .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #iguswyzxws .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #iguswyzxws .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #iguswyzxws .gt_left { text-align: left; } #iguswyzxws .gt_center { text-align: center; } #iguswyzxws .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #iguswyzxws .gt_font_normal { font-weight: normal; } #iguswyzxws .gt_font_bold { font-weight: bold; } #iguswyzxws .gt_font_italic { font-style: italic; } #iguswyzxws .gt_super { font-size: 65%; } #iguswyzxws .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #iguswyzxws .gt_asterisk { font-size: 100%; vertical-align: 0; } #iguswyzxws .gt_indent_1 { text-indent: 5px; } #iguswyzxws .gt_indent_2 { text-indent: 10px; } #iguswyzxws .gt_indent_3 { text-indent: 15px; } #iguswyzxws .gt_indent_4 { text-indent: 20px; } #iguswyzxws .gt_indent_5 { text-indent: 25px; } Characteristic Beta 95% CI1 p-value Rd -22 -50, 5.8 0.12 n -0.01 -0.03, 0.01 0.3 I(n^2) 0.00 0.00, 0.00 0.5 I(Rd * n) 0.02 -0.01, 0.05 0.2 I(sqrt(Rd)) 45 -4.7, 94 0.076 I(sqrt(n)) 0.87 -0.48, 2.2 0.2 I(sqrt(Rd * n)) -1.4 -3.1, 0.34 0.11 R² 0.683 Adjusted R² 0.656 1 CI = Confidence Interval Después de tener la estimación del modelo se debe obtener el valor de la constante \\(\\Delta\\) para lo cual se usa el siguiente código. delta.hat = sum(baseFGV$Rd_var) / sum(exp(fitted.values(FGV1))) De donde se obtiene que \\(\\Delta = 1.2364739\\). Final es posible obtener la varianza suavizada ejecutando el siguiente comando. baseFGV &lt;- baseFGV %&gt;% mutate(hat_var = delta.hat * exp(fitted.values(FGV1))) 10.2.3 Validaciones sobre el modelo par(mfrow = c(2, 2)) plot(FGV1) varianza suavizada Vs varianza estimada ggplot(baseFGV, aes(x = Rd_var, y = hat_var)) + geom_point() + geom_smooth(method = &quot;loess&quot;) Este código está realizando una Consolidación de los dominios observados y no observados para lo cual hace una unión izquierda (left_join()) entre: indicador_dom y baseFGV de la cual selecciona las columnas de id_dominio y hat_var. El argumento by = id_dominio especifica que la unión debe realizarse mediante la columna id_dominio. Luego, se utiliza la función mutate() para crear dos nuevas variables. La primera variable Rd_var se asigna el valor de Rd_var de baseFGV si hat_var no es un valor nulo (NA), de lo contrario se le asigna un valor NA_real_ (NA pero de tipo numérico). De manera similar, se crea la variable Rd_deff con el valor de Rd_deff de baseFGV si hat_var no es nulo, de lo contrario se le asigna un valor NA_real_. base_sae &lt;- left_join(indicador_dom, baseFGV %&gt;% select(dam2, hat_var), by = &quot;dam2&quot;) %&gt;% mutate( Rd_var = ifelse(is.na(hat_var), NA_real_, Rd_var), Rd_deff = ifelse(is.na(hat_var), NA_real_, Rd_deff) ) Ahora, se debe estimar deff_FGV y n_eff_FGV a parir de la varianza suvizada (hat_var). base_FH &lt;- base_sae %&gt;% mutate( Rd_deff = ifelse(is.nan(Rd_deff), 1, Rd_deff), deff_FGV = ifelse(Rd_var == 0 , 1, hat_var / (Rd_var / Rd_deff) #Fórmula del nuevo DEFF ), # Criterio MDS para regularizar el DeffFGV deff_FGV = ifelse(deff_FGV &lt;= 1, NA_real_, deff_FGV), #Deff estimado n_eff_FGV = n / deff_FGV, #Número efectivo de personas encuestadas # Si no se estimó varianza para ese municipio, también excluir # la estimación directa de este municipio, esto es relevante para el modelo FH hat_var = ifelse(deff_FGV &lt;= 1, NA_real_, hat_var), Rd = ifelse(is.na(hat_var), NA_real_, Rd) ) tba(head(base_FH %&gt;% select(dam2,n,n_upm,Rd, Rd_var,hat_var:n_eff_FGV), 10)) dam2 n n_upm Rd Rd_var hat_var deff_FGV n_eff_FGV 0101 2951 126 0.4147 0.0005 0.0005 5.9862 492.9681 3201 2840 108 0.4233 0.0003 0.0005 6.0488 469.5114 2501 3057 87 0.4108 0.0004 0.0005 6.2443 489.5639 3203 1944 59 0.4858 0.0004 0.0006 5.0816 382.5577 3202 1046 42 0.4221 0.0006 0.0011 4.5844 228.1662 1101 1198 38 0.3788 0.0012 0.0009 4.7384 252.8274 3206 836 32 0.3968 0.0006 0.0015 5.3642 155.8470 0901 743 20 0.5236 0.0028 0.0013 3.9091 190.0700 1301 738 20 0.4899 0.0011 0.0014 4.2704 172.8174 2101 505 20 0.4522 0.0015 0.0025 5.0969 99.0789 10.2.4 Otras validaciones sobre el resultado del modelo. Continuando con el proceso de validación se construye el siguiente gráfico de dispersión con la variable de la varianza del estimador directo en el eje y y la varianza FGV en el eje x, para los municipios que tienen valores válidos para ambas variables. La línea de regresión lineal se ajusta a los puntos usando el método de mínimos cuadrados. La visualización del gráfico permite evaluar si la FGV está capturando adecuadamente la variabilidad de la variable de interés (en este caso, la variable de varianza del estimador directo). Si la FGV captura la variabilidad, se espera que los puntos estén relativamente cerca de la línea de regresión, lo que indicaría que la FGV explica una gran parte de la variabilidad de la varianza del estimador directo. Por otro lado, si la FGV no captura la variabilidad, los puntos estarán más dispersos y alejados de la línea de regresión. nDom &lt;- sum(!is.na(base_FH$hat_var)) temp_FH &lt;- base_FH %&gt;% filter(!is.na(hat_var)) ggplot(temp_FH %&gt;% arrange(n), aes(x = hat_var, y = Rd_var)) + geom_point() + geom_smooth(method = &quot;lm&quot;, col = 2) + labs(x = &quot;FGV&quot;, y = &quot;VaRdirEst&quot;) + ylab(&quot;Varianza del Estimador Directo&quot;) Ahora, se realiza la comparación de la variabilidad de la varianza del estimador directo frente a la varianza suavizada a medida que el tamaño de muestra aumenta. El eje x representa el tamaño de la muestra y el eje y representa las varianzas. La línea azul representa la varianza FGV, mientras que la línea roja representa la varianza del estimador directo. En el gráfica es posible notar que la varianza FGV tiene una menos volatilidad que la varianza directa. ggplot(temp_FH %&gt;% arrange(n), aes(x = 1:nDom)) + geom_line(aes(y = Rd_var, color = &quot;VarDirEst&quot;)) + geom_line(aes(y = hat_var, color = &quot;FGV&quot;)) + labs(y = &quot;Varianzas&quot;, x = &quot;Tamaño muestral&quot;, color = &quot; &quot;) + scale_x_continuous(breaks = seq(1, nDom, by = 10), labels = temp_FH$n[order(temp_FH$n)][seq(1, nDom, by = 10)]) + scale_color_manual(values = c(&quot;FGV&quot; = &quot;Blue&quot;, &quot;VarDirEst&quot; = &quot;Red&quot;)) Siguiendo en la misma línea, se realiza la comparación del efectivo directo (n_eff_DIR) y el efectivo FGV (n_eff_DIR). El código que se muestra a continuación produce un gráfico que compara el tamaño de muestra efectivo obtenido a través de la estimación del DEFF con el tamaño de muestra directo. En el eje x se muestra el tamaño de muestra directo (n) y en el eje y se muestra el tamaño de muestra efectivo, calculado a través de la fórmula n/DEFF para la estimación directa (en rojo) y para la FGV (en azul). Se puede observar que, en general, el tamaño de muestra efectivo estimado a través de la FGV es menos variable que el estimado a través de la estimación directa, lo que indica que la FGV reduce la varianza de la estimación. Además, se puede observar que para algunos dominios, el tamaño de muestra efectivo estimado a través de la FGV es menor que el tamaño de muestra directo, lo que podría deberse a la estimación de la varianza a través de la FGV. En general, este gráfico es útil para comparar la eficiencia de la estimación a través de la FGV y la estimación directa para cada dominio. ggplot(temp_FH %&gt;% arrange(n), aes(x = 1:nDom)) + geom_line(aes(y = n / Rd_deff, color = &quot;n_eff_DIR&quot;)) + geom_line(aes(y = n_eff_FGV, color = &quot;n_eff_FGV&quot;)) + labs(y = &quot;Tamaño de muestra efectivo&quot;, x = &quot;Tamaño muestral&quot;, color = &quot; &quot;) + scale_x_continuous(breaks = seq(1, nDom, by = 10), labels = temp_FH$n[order(temp_FH$n)][seq(1, nDom, by = 10)]) + scale_color_manual(values = c(&quot;n_eff_FGV&quot; = &quot;Blue&quot;, &quot;n_eff_DIR&quot; = &quot;red&quot;)) Por último, guardamos la base resultante. saveRDS(object = base_FH, &quot;Recursos/Día3/Sesion3/Data/base_FH.Rds&quot;) "],["estimación-de-la-informalidad-laboral-con-un-modelo-de-área-con-tranformación-arcoseno..html", "10.3 Estimación de la informalidad laboral con un modelo de área con tranformación arcoseno.", " 10.3 Estimación de la informalidad laboral con un modelo de área con tranformación arcoseno. El Modelo de Fay-Herriot con transformación arcoseno es una técnica estadística ampliamente utilizada en la estimación de la media y la varianza de una población a partir de una muestra. Esta herramienta es particularmente útil cuando se trabaja con datos que no cumplen con los supuestos de normalidad, como es el caso de las proporciones o porcentajes limitados entre 0 y 1. La transformación arcoseno es una técnica matemática que se aplica a los datos para mejorar su distribución. Esta transformación se utiliza comúnmente en estadística para trabajar con datos que tienen una distribución asimétrica o no cumplen con la normalidad. La transformación arcoseno es especialmente útil para trabajar con variables como la informalidad laboral, que se define como la proporción de trabajadores informales en una población. En este contexto, el modelo de Fay-Herriot con transformación arcoseno se convierte en una herramienta valiosa para la estimación de la informalidad laboral en pequeñas áreas geográficas. Esta técnica permite la inclusión de información auxiliar, como las características socioeconómicas de las áreas geográficas, para mejorar la precisión y la confiabilidad de las estimaciones. Además, el modelo de Fay-Herriot con transformación arcoseno también permite la inclusión de covariables para tener en cuenta los factores socioeconómicos que pueden influir en la informalidad laboral. Al incorporar esta información adicional, se pueden obtener estimaciones más precisas y detalladas de la informalidad laboral en áreas geográficas específicas. Ahora, la transformación arcoseno para la estimación directa \\(\\theta_d\\) esta dada por: \\[ \\hat{z}_d = arcsin\\left( \\sqrt{ \\hat{\\theta}_d} \\right) \\] donde \\[ Var\\left( \\hat{z}_d \\right) = \\frac{\\widehat{DEFF}_d}{4\\times n_d} = \\frac{1}{4\\times n_{d,efectivo} } \\] Y el modelo de Fay-Herriot estaría definido de la siguiente forma: \\[ \\begin{eqnarray*} Z_d \\mid \\mu_d,\\sigma^2_d &amp; \\sim &amp; N(\\mu_d, \\sigma^2_d)\\\\ \\mu_d &amp; = &amp; \\boldsymbol{x}^{T}_{d}\\boldsymbol{\\beta} + u_d \\\\ \\theta_d &amp; = &amp; \\left(sin(\\mu_d)\\right)^2 \\end{eqnarray*} \\] donde \\(u_d \\sim N(0 , \\sigma^2)\\). Suponga de las distribuciones previas para \\(\\boldsymbol{\\beta}\\) y \\(\\sigma_{u}^{2}\\) son dadas por \\[ \\begin{eqnarray*} \\boldsymbol{\\beta} \\sim N\\left(0,1000 \\right)\\\\ \\sigma_{u}^{2} \\sim IG\\left(0.0001,0.0001\\right) \\end{eqnarray*} \\] "],["procedimiento-de-estimación-4.html", "10.4 Procedimiento de estimación", " 10.4 Procedimiento de estimación Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés library(tidyverse) library(magrittr) base_FH &lt;- readRDS(&quot;Recursos/Día3/Sesion3/Data/base_FH.rds&quot;) %&gt;% transmute(dam2, ## id dominios Rd, T_pobreza = asin(sqrt(Rd)), ## creando zd n_effec = n_eff_FGV, ## n efectivo varhat = 1/(4*n_effec) ## varianza para zd ) Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables es necesario hacer un ajuste a estas. statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día3/Sesion3/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) %&gt;% mutate(dam2 = str_sub(dam2,2,5)) Uniendo las dos bases de datos. base_FH &lt;- full_join(base_FH, statelevel_predictors_df, by = &quot;dam2&quot; ) tba(base_FH[,1:8] %&gt;% head(10)) dam2 Rd T_pobreza n_effec varhat modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 0101 0.4147 0.6996 492.9681 0.0005 3.6127 -1.1835 -1.5653 3201 0.4233 0.7083 469.5114 0.0005 2.7794 -1.1311 -1.4114 2501 0.4108 0.6957 489.5639 0.0005 1.4723 -0.9237 -1.0018 3203 0.4858 0.7712 382.5577 0.0007 1.3957 -0.8956 -0.6852 3202 0.4221 0.7072 228.1662 0.0011 3.2182 -1.1432 -1.3703 1101 0.3788 0.6630 252.8274 0.0010 0.1812 -0.3456 0.2598 3206 0.3968 0.6814 155.8470 0.0016 2.8725 -1.1422 -1.3920 0901 0.5236 0.8090 190.0700 0.0013 0.7267 -0.9136 -0.9395 1301 0.4899 0.7753 172.8174 0.0014 0.9296 -0.8801 -0.9322 2101 0.4522 0.7376 99.0789 0.0025 1.4404 -0.9892 -1.0458 Seleccionando las covariables para el modelo. names_cov &lt;- c( &quot;sexo2&quot; , &quot;tasa_desocupacion&quot; , &quot;luces_nocturnas&quot; , &quot;cubrimiento_cultivo&quot; , &quot;modificacion_humana&quot;, &quot;alfabeta&quot; ) "],["preparando-los-insumos-para-stan-4.html", "10.5 Preparando los insumos para STAN", " 10.5 Preparando los insumos para STAN Dividir la base de datos en dominios observados y no observados Dominios observados. data_dir &lt;- base_FH %&gt;% filter(!is.na(T_pobreza)) Dominios NO observados. data_syn &lt;- base_FH %&gt;% anti_join(data_dir %&gt;% select(dam2)) tba(data_syn[,1:8] %&gt;% slice(1:10)) dam2 Rd T_pobreza n_effec varhat modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado 2702 NA NA NA NA 0.8018 -0.7175 -0.7444 2901 NA NA NA NA 0.0542 -0.7779 -0.7341 1303 NA NA NA NA -0.5140 0.5302 0.4079 1804 NA NA NA NA -0.0336 -0.6339 -0.2478 2404 NA NA NA NA 0.3128 -0.7926 -0.7880 2601 NA NA NA NA -0.2175 1.4552 0.9138 2905 NA NA NA NA 0.1913 -0.3997 -0.5567 0202 NA NA NA NA -0.3758 0.0000 0.1482 0402 NA NA NA NA -0.3661 -0.0114 -0.2863 0404 NA NA NA NA -0.5678 1.0735 0.9856 Definir matriz de efectos fijos. ## Dominios observados Xdat &lt;- cbind(inter = 1,data_dir[,names_cov]) ## Dominios no observados Xs &lt;- cbind(inter = 1,data_syn[,names_cov]) Creando lista de parámetros para STAN sample_data &lt;- list( N1 = nrow(Xdat), # Observados. N2 = nrow(Xs), # NO Observados. p = ncol(Xdat), # Número de regresores. X = as.matrix(Xdat), # Covariables Observados. Xs = as.matrix(Xs), # Covariables NO Observados y = as.numeric(data_dir$T_pobreza), sigma_e = sqrt(data_dir$varhat) ) Compilando el modelo en STAN library(rstan) fit_FH_arcoseno &lt;- &quot;Recursos/Día3/Sesion3/Data/modelosStan/15FH_arcsin_normal.stan&quot; options(mc.cores = parallel::detectCores()) model_FH_arcoseno &lt;- stan( file = fit_FH_arcoseno, data = sample_data, verbose = FALSE, warmup = 500, iter = 1000, cores = 4 ) saveRDS(model_FH_arcoseno, &quot;Recursos/Día3/Sesion3/Data/model_FH_arcoseno.rds&quot;) model_FH_arcoseno &lt;- readRDS(&quot;Recursos/Día3/Sesion3/Data/model_FH_arcoseno.rds&quot;) 10.5.1 Resultados del modelo para los dominios observados. En este código, se cargan las librerías bayesplot, posterior y patchwork, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo. A continuación, se utiliza la función as.array() y as_draws_matrix() para extraer las muestras de la distribución posterior del parámetro theta del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función sample(), lo que resulta en la matriz y_pred2. Finalmente, se utiliza la función ppc_dens_overlay() de bayesplot para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (data_dir$pobreza) y las distribuciones predictivas posteriores simuladas para la misma variable (y_pred2). La función ppc_dens_overlay() produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan. library(bayesplot) library(patchwork) library(posterior) y_pred_B &lt;- as.array(model_FH_arcoseno, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(data_dir$Rd), y_pred2) Análisis gráfico de la convergencia de las cadenas de \\(\\sigma^2_u\\). posterior_sigma2_u &lt;- as.array(model_FH_arcoseno, pars = &quot;sigma2_u&quot;) (mcmc_dens_chains(posterior_sigma2_u) + mcmc_areas(posterior_sigma2_u) ) / mcmc_trace(posterior_sigma2_u) # traceplot(model_FH_arcoseno,pars = &quot;sigma2_u&quot;,inc_warmup = TRUE) # stan_plot(model_FH_arcoseno) #traceplot(model_FH_arcoseno,pars = &quot;beta&quot;,inc_warmup = TRUE) Estimación del FH de la pobreza en los dominios observados. theta_FH &lt;- summary(model_FH_arcoseno,pars = &quot;theta&quot;)$summary %&gt;% data.frame() data_dir %&lt;&gt;% mutate(pred_arcoseno = theta_FH$mean, pred_arcoseno_EE = theta_FH$sd, Cv_pred = pred_arcoseno_EE/pred_arcoseno) Estimación del FH de la pobreza en los dominios NO observados. theta_FH_pred &lt;- summary(model_FH_arcoseno,pars = &quot;theta_pred&quot;)$summary %&gt;% data.frame() data_syn &lt;- data_syn %&gt;% mutate(pred_arcoseno = theta_FH_pred$mean, pred_arcoseno_EE = theta_FH_pred$sd, Cv_pred = pred_arcoseno_EE/pred_arcoseno) "],["mapa-de-informalidad-laboral.html", "10.6 Mapa de informalidad laboral", " 10.6 Mapa de informalidad laboral El siguiente bloque de código carga los paquetes sp, sf y tmap y realiza una serie de operaciones. En primer lugar, une (rbind) las estimaciones de los dominios observados y no observados (data_dir, data_syn) y selecciona las variables dam2, pobreza (informalidad laboral), pred_arcoseno, pred_arcoseno_EE y Cv_pred utilizando la función select(). A continuación, lee un archivo Shapefile que contiene información geoespacial del país. Luego, crea un mapa temático (tmap) utilizando la función tm_shape() y agregando capas con la función tm_polygons(). El mapa representa dos variables llamadas pobreza y pred_arcoseno, utilizando una paleta de colores llamada “YlOrRd” y establece los cortes de los intervalos de las variables con la variable brks_lp. Finalmente, la función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). library(sp) library(sf) library(tmap) data_map &lt;- rbind(data_dir, data_syn) %&gt;% select(dam2, Rd, pred_arcoseno, pred_arcoseno_EE,Cv_pred ) ## Leer Shapefile del país ShapeSAE &lt;- read_sf(&quot;Recursos/Día3/Sesion3/Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) mapa &lt;- tm_shape(ShapeSAE %&gt;% left_join(data_map, by = &quot;dam2&quot;)) brks_lp &lt;- quantile(data_map$pred_arcoseno) tmap_options(check.and.fix = TRUE) Mapa_lp &lt;- mapa + tm_polygons( c(&quot;Rd&quot;, &quot;pred_arcoseno&quot;), breaks = brks_lp, title = &quot;Mapa de tasa\\nde informalidad&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 2.5) tmap_save( Mapa_lp, &quot;Recursos/Día3/Sesion3/0Recursos/Mapa_arcoseno.PNG&quot;, width = 3000, height = 2000, asp = 0 ) Mapa_lp "],["mapa-del-coeficiente-de-variación.-3.html", "10.7 Mapa del coeficiente de variación.", " 10.7 Mapa del coeficiente de variación. Ahora, se crea un segundo mapa temático (tmap) llamado Mapa_cv. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función tm_polygons(). El mapa representa la variable Cv_pred, utilizando una paleta de colores llamada “YlOrRd” y establece el título del mapa con el parámetro title. La función tm_layout() establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R. Mapa_cv &lt;- mapa + tm_polygons( c(&quot;Cv_pred&quot;), title = &quot;Mapa de tasa\\nde informalidad(cv)&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) + tm_layout(asp = 2.5) tmap_save( Mapa_cv, &quot;Recursos/Día3/Sesion3/0Recursos/Mapa_arcoseno_cv.PNG&quot;, width = 3000, height = 2000, asp = 0 ) Mapa_cv "],["día-4---sesión-1--modelo-de-unidad-para-la-estimación-del-ingreso-medio.html", "Capítulo 11 Día 4 - Sesión 1- Modelo de unidad para la estimación del ingreso medio", " Capítulo 11 Día 4 - Sesión 1- Modelo de unidad para la estimación del ingreso medio Uno de los primeros problemas a los que debemos enfrentarnos es la estimación del ingreso medio, la cual en una variable no simétrica que toma valores en los positivos. Sin embargo, empleando los métodos Bayesiano es posible obtener estimaciones de esta sin realizar una transformación Figura 11.1: Distribución del ingreso medio por dam2 "],["modelo-bayesiano..html", "11.1 Modelo bayesiano.", " 11.1 Modelo bayesiano. Para realizar la predicción del ingreso medio en dam2s no observadas se asume que: \\[ \\begin{eqnarray*} Y_{di} &amp;\\sim &amp; N\\left(\\mu_{di},\\sigma_y^{2}\\right)\\\\ \\mu_{di}&amp;=&amp;\\boldsymbol{x}_{di}^{T}\\boldsymbol{\\beta}+u_{d}+e_{di} \\end{eqnarray*} \\] Donde \\(Y_{di}\\) representa el ingreso medio de la \\(i-ésima\\) persona en el \\(d-ésimo\\) domino, \\(\\boldsymbol{X}\\) es la información disponible para la \\(i-ésima\\) persona del \\(d-ésimo\\) domino, \\(\\boldsymbol{\\beta}\\) es el vector de parámetros \\(u_d\\) es el efecto introducido por el \\(d-ésimo\\) dominio y \\(e_{di}\\) es el error de estimación para la \\(i-ésima\\) personas del \\(d-ésimo\\) dominio. Note, que \\(u_{d}\\sim N\\left(0,\\sigma^2_{u}\\right)\\) y \\(e_{di}\\sim N\\left(0,\\sigma_{e}^{2}\\right)\\). Para este caso se asumen las distribuciones previas \\[ \\begin{eqnarray*} \\beta_k &amp; \\sim &amp; N(0, 1000)\\\\ \\sigma^2_y &amp;\\sim &amp; IG(0.00203,0.00203) \\end{eqnarray*} \\] las cuales se toman no informativas. A continuación se muestra el proceso realizado para la obtención de la predicción del ingreso medio en dominios no observados. "],["proceso-de-estimación-en-r.html", "11.2 Proceso de estimación en R", " 11.2 Proceso de estimación en R Para desarrollar la metodología se hace uso de las siguientes librerías. # Interprete de STAN en R library(rstan) library(rstanarm) # Manejo de bases de datos. library(tidyverse) # Gráficas de los modelos. library(bayesplot) library(patchwork) # Organizar la presentación de las tablas library(kableExtra) library(printr) Un conjunto de funciones desarrolladas para realizar de forma simplificada los procesos están consignadas en la siguiente rutina. source(&quot;Recursos/Día4/Sesion1/0Recursos/funciones_mrp.R&quot;) Entre las funciones incluidas en el archivo encuentra plot_interaction: Esta crea un diagrama de lineas donde se estudia la interacción entre las variables, en el caso de presentar un traslape de las lineas se recomienda incluir el interacción en el modelo. Plot_Compare Puesto que es necesario realizar una homologar la información del censo y la encuesta es conveniente llevar a cabo una validación de las variables que han sido homologadas, por tanto, se espera que las proporciones resultantes del censo y la encuesta estén cercanas entre sí. Aux_Agregado: Esta es función permite obtener estimaciones a diferentes niveles de agregación, toma mucha relevancia cuando se realiza un proceso repetitivo. Las funciones están diseñada específicamente para este proceso 11.2.1 Encuesta de hogares Los datos empleados en esta ocasión corresponden a la ultima encuesta de hogares, la cual ha sido estandarizada por CEPAL y se encuentra disponible en BADEHOG encuesta &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/encuestaDOM21N1.rds&quot;) encuesta_mrp &lt;- encuesta %&gt;% transmute( dam = haven::as_factor(dam_ee,levels = &quot;values&quot;), dam = str_pad(string = dam, width = 2, pad = &quot;0&quot;), dam2, ingreso = ingcorte, lp, li, area = haven::as_factor(area_ee,levels = &quot;values&quot;), area = case_when(area == 1 ~ &quot;1&quot;, TRUE ~ &quot;0&quot;), logingreso = log(ingcorte + 1), sexo = as.character(sexo), anoest = case_when( edad &lt; 5 | anoest == -1 | is.na(anoest) ~ &quot;98&quot; , #No aplica anoest == 99 ~ &quot;99&quot;, #NS/NR anoest == 0 ~ &quot;1&quot;, # Sin educacion anoest %in% c(1:6) ~ &quot;2&quot;, # 1 - 6 anoest %in% c(7:12) ~ &quot;3&quot;, # 7 - 12 anoest &gt; 12 ~ &quot;4&quot;, # mas de 12 TRUE ~ &quot;Error&quot; ), edad = case_when( edad &lt; 15 ~ &quot;1&quot;, edad &lt; 30 ~ &quot;2&quot;, edad &lt; 45 ~ &quot;3&quot;, edad &lt; 65 ~ &quot;4&quot;, TRUE ~ &quot;5&quot;), fep = `_fep` ) tba(encuesta_mrp %&gt;% head(10)) dam dam2 ingreso lp li area logingreso sexo anoest edad fep 01 00101 54000.00 5622.81 3159.09 1 10.8968 1 4 3 137.0652 01 00101 16388.89 5622.81 3159.09 1 9.7044 2 3 4 137.0652 01 00101 16388.89 5622.81 3159.09 1 9.7044 1 3 5 137.0652 01 00101 16388.89 5622.81 3159.09 1 9.7044 1 4 2 137.0652 01 00101 6224.00 5622.81 3159.09 1 8.7363 2 2 4 137.0652 01 00101 6224.00 5622.81 3159.09 1 8.7363 1 3 3 137.0652 01 00101 6224.00 5622.81 3159.09 1 8.7363 2 4 2 137.0652 01 00101 20672.00 5622.81 3159.09 1 9.9366 2 1 5 137.0652 01 00101 8495.60 5622.81 3159.09 1 9.0474 1 4 3 137.0652 01 00101 8495.60 5622.81 3159.09 1 9.0474 2 3 3 137.0652 La base de datos de la encuesta tiene la siguientes columnas: dam: Corresponde al código asignado a la división administrativa mayor del país. dam2: Corresponde al código asignado a la segunda división administrativa del país. lp y li lineas de pobreza y pobreza extrema definidas por CEPAL. área división geográfica (Urbano y Rural). sexo Hombre y Mujer. Años de escolaridad (anoest) Rangos de edad (edad) Factor de expansión por persona (fep) Ahora, inspeccionamos el comportamiento de la variable de interés: media &lt;- mean(encuesta_mrp$logingreso) Sd &lt;- sd(encuesta_mrp$logingreso) ggplot(data = encuesta_mrp, aes(x = logingreso)) + geom_density(size =2, color = &quot;blue&quot;) + labs(y = &quot;&quot;) + stat_function(fun = dnorm, args = list(mean = media, sd = Sd), size =2) + theme_bw(base_size = 20) + theme(axis.text.y = element_blank(), axis.ticks = element_blank()) Figura 5.1: Distribuición del ingreso de las personas encuestadas La información auxiliar disponible ha sido extraída del censo e imágenes satelitales statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) tba(statelevel_predictors_df %&gt;% head(10)) dam2 modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion id_municipio 00101 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 00201 -0.0553 0.4449 0.2100 0.0684 -0.0682 -0.1511 0.8904 0.4933 0.2726 0.1849 0.1520 0.0614 0.3149 0.3022 0.0775 0.0082 0.1005 0.7220 0.2261 0.1300 0.9276 0.0664 0.0812 0.0249 0.1501 0.7975 0.3014 0.0007 050201 00202 -0.3758 0.0000 0.1482 -0.2345 -0.2855 -0.4234 0.6799 0.4697 0.2804 0.1895 0.1430 0.0515 0.3757 0.2405 0.0148 0.0014 0.1322 0.9230 0.2693 0.2884 0.9759 0.0625 0.0986 0.0673 0.0278 0.7140 0.3454 0.0001 050202 00203 -0.9259 0.5732 -0.1402 -0.5511 -0.3822 -0.5612 0.5814 0.4601 0.2665 0.1733 0.1586 0.0713 0.3778 0.2463 0.0219 0.0052 0.2579 0.7602 0.4824 0.2589 0.9919 0.1937 0.2342 0.1238 0.0485 0.7104 0.2755 0.0001 050203 00204 -1.3166 1.1111 0.4438 -0.5027 -0.3835 -0.6042 0.5708 0.4663 0.2647 0.1683 0.1673 0.0757 0.3306 0.2402 0.0440 0.0049 0.1672 0.6375 0.5040 0.3837 0.9759 0.1403 0.1354 0.0176 0.0873 0.6737 0.2671 0.0002 050204 00205 -0.7474 2.1155 1.2271 -0.5838 -0.3345 -0.5909 0.6937 0.4633 0.2849 0.2107 0.1473 0.0583 0.2794 0.2821 0.0562 0.0067 0.3800 0.6596 0.5014 0.2852 0.9894 0.2309 0.2498 0.0459 0.1016 0.6751 0.4973 0.0001 050205 00206 0.5157 -0.1468 -0.1811 1.1894 -0.1191 -0.4022 0.9563 0.4557 0.2910 0.1814 0.1495 0.0626 0.3793 0.2815 0.0427 0.0052 0.1301 0.8817 0.2565 0.1495 0.9659 0.0629 0.0472 0.0337 0.0835 0.8027 0.2200 0.0001 050206 00207 1.7368 -0.7648 -0.4861 0.7170 -0.0609 0.0042 0.5201 0.4783 0.2898 0.1675 0.1464 0.0531 0.3552 0.2901 0.0328 0.0061 0.2434 0.5775 0.2758 0.0950 0.9911 0.0717 0.2004 0.1304 0.0714 0.7778 0.3936 0.0001 050207 00208 -0.5942 0.3212 -0.1697 -0.3627 -0.3044 -0.4750 0.6625 0.4334 0.2943 0.1875 0.1523 0.0654 0.3557 0.2486 0.0250 0.0054 0.1908 0.8251 0.4152 0.1450 0.9907 0.1458 0.1517 0.0852 0.0509 0.6897 0.3051 0.0001 050208 00209 -1.5280 3.0192 1.9428 -0.8078 -0.4046 -0.6423 0.6798 0.4311 0.2858 0.1687 0.1628 0.0701 0.3648 0.2645 0.0752 0.0061 0.1893 0.5760 0.4096 0.3557 0.9978 0.1097 0.0941 0.0292 0.1357 0.7680 0.2189 0.0001 050209 11.2.2 Niveles de agregación para colapsar la encuesta Después de realizar una investigación en la literatura especializada y realizar estudios de simulación fue posible evidenciar que las predicciones obtenidas con la muestra sin agregar y la muestra agregada convergen a la media del dominio. Sin embargo, el realizar estas estimaciones con la muestra agregada reduce el tiempo computacional necesario para la convergencia de las cadenas MCMC. Con esto en mente se se realiza la identificación de las variables por las cuales se agregará la encuesta. byAgrega &lt;- c(&quot;dam&quot;, &quot;dam2&quot;, &quot;area&quot;, &quot;sexo&quot;, &quot;anoest&quot;, &quot;edad&quot; ) 11.2.3 Creando base con la encuesta agregada El resultado de agregar la base de dato se muestra a continuación: encuesta_df_agg &lt;- encuesta_mrp %&gt;% # Encuesta group_by_at(all_of(byAgrega)) %&gt;% # Agrupar por el listado de variables summarise(n = n(), # Número de observaciones # Ingreso medio de las personas con características similares. logingreso = mean(logingreso), .groups = &quot;drop&quot;) %&gt;% arrange(desc(n)) # Ordenar la base. La tabla obtenida es la siguiente: dam dam2 area sexo anoest edad n logingreso 01 00101 1 1 3 2 652 9.1000 01 00101 1 2 3 2 624 8.8678 32 03201 1 2 3 2 576 8.9571 32 03201 1 1 3 2 548 9.0968 25 02501 1 1 3 2 505 9.2633 25 02501 1 2 3 2 447 9.0084 01 00101 1 1 3 3 412 9.1381 01 00101 1 1 2 1 401 8.8231 32 03203 1 2 3 2 393 8.9166 32 03201 1 1 3 3 390 9.0601 El paso a seguir es unificar las tablas creadas. encuesta_df_agg &lt;- inner_join(encuesta_df_agg, statelevel_predictors_df) 11.2.4 Definiendo el modelo multinivel. Después de haber ordenado la encuesta, podemos pasar a la definición del modelo. options(MC.cores=parallel::detectCores()) # Permite procesar en paralelo. fit &lt;- stan_lmer( logingreso ~ # Ingreso medio (Y) (1 | dam2) + # Efecto aleatorio (ud) edad + # Efecto fijo (Variables X) sexo + tasa_desocupacion + luces_nocturnas + cubrimiento_cultivo + cubrimiento_urbano , weights = n, # Número de observaciones. data = encuesta_df_agg, # Encuesta agregada verbose = TRUE, # Muestre el avance del proceso chains = 4, # Número de cadenas. iter = 1000 # Número de realizaciones de la cadena ) saveRDS(fit, file = &quot;Recursos/Día4/Sesion1/Data/fit_ingresos.rds&quot;) Después de esperar un tiempo prudente se obtiene el siguiente modelo. fit &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/fit_ingresos.rds&quot;) tba(coef(fit)$dam2 %&gt;% head(10)) (Intercept) edad2 edad3 edad4 edad5 sexo2 tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano 00101 8.8056 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00201 8.8603 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00202 8.6616 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00203 8.6011 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00204 9.1334 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00205 8.6218 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00206 8.6877 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00208 8.7539 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00210 9.0558 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 00301 8.5342 0.2619 0.3041 0.5292 0.5353 -0.0924 25.7452 0.1079 0.0256 -0.0858 Validación del modelo library(posterior) library(bayesplot) (mcmc_dens_chains(fit,pars = &quot;sigma&quot;) + mcmc_areas(fit,pars = &quot;sigma&quot;))/ mcmc_trace(fit,pars = &quot;sigma&quot;) var_names &lt;- c(&quot;edad2&quot;, &quot;edad3&quot;, &quot;edad4&quot;, &quot;edad5&quot;, &quot;sexo2&quot;, &quot;luces_nocturnas&quot;, &quot;cubrimiento_urbano&quot;,&quot;cubrimiento_cultivo&quot;) mcmc_areas(fit,pars = var_names) mcmc_trace(fit,pars = var_names) encuesta_mrp2 &lt;- inner_join(encuesta_mrp, statelevel_predictors_df) y_pred_B &lt;- posterior_epred(fit, newdata = encuesta_mrp2) rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(encuesta_mrp2$logingreso), y_pred2)/ ppc_dens_overlay(y = exp(as.numeric(encuesta_mrp2$logingreso))-1, (exp(y_pred2)-1)) "],["proceso-de-estimación-y-predicción.html", "11.3 Proceso de estimación y predicción", " 11.3 Proceso de estimación y predicción Obtener el modelo es solo un paso más, ahora se debe realizar la predicción en el censo, el cual a sido previamente estandarizado y homologado con la encuesta. poststrat_df &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/censo_mrp_dam2.rds&quot;) %&gt;% left_join(statelevel_predictors_df) tba( poststrat_df %&gt;% arrange(desc(n)) %&gt;% head(10)) dam dam2 id_municipio nombre_region region area sexo edad anoest n modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion 32 03201 103201 Región Ozama 10 1 2 2 3 78858 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 32 03201 103201 Región Ozama 10 1 1 2 3 77566 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 1 2 3 76098 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 01 00101 100101 Región Ozama 10 1 2 2 3 76002 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 25 02501 012501 Región Cibao Norte 01 1 2 2 3 52770 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 25 02501 012501 Región Cibao Norte 01 1 1 2 3 51227 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 32 03201 103201 Región Ozama 10 1 1 1 2 50744 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 1 1 2 50015 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 32 03201 103201 Región Ozama 10 1 2 1 2 49652 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 2 1 2 49010 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 Note que la información del censo esta agregada. 11.3.1 Distribución posterior. Para obtener una distribución posterior de cada observación se hace uso de la función posterior_epred de la siguiente forma. epred_mat &lt;- posterior_epred(fit, newdata = poststrat_df, type = &quot;response&quot;) Como el interés es realizar comparaciones entre los países de la región se presenta la estimación del ingreso medio en términos de lineas de pobreza. Para esto procedemos así: Obteniendo las lineas de pobreza por cada post-estrato (lp &lt;- encuesta_mrp %&gt;% distinct(area,lp,li)) %&gt;% tba() area lp li 1 5622.81 3159.09 0 4876.69 3061.23 1 5710.40 3193.03 0 4949.12 3094.12 1 5844.03 3291.64 0 5070.47 3189.68 1 5973.59 3377.04 0 5185.77 3272.42 Ingreso en términos de lineas de pobreza. lp %&lt;&gt;% group_by(area) %&gt;% summarise(lp = mean(lp),li = mean(li)) lp &lt;- inner_join(poststrat_df,lp,by = &quot;area&quot;) %&gt;% select(lp) epred_mat &lt;- (exp(epred_mat)-1)/lp$lp 11.3.2 Estimación del ingreso medio nacional n_filtered &lt;- poststrat_df$n mrp_estimates &lt;- epred_mat %*% n_filtered / sum(n_filtered) (temp_ing &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 1.6535 0.0052 El resultado nos indica que el ingreso medio nacional es 1.65 lineas de pobreza 11.3.3 Estimación para el dam == “01”. Es importante siempre conservar el orden de la base, dado que relación entre la predicción y el censo en uno a uno. temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam == &quot;01&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam11 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 1.6709 0.0159 El resultado nos indica que el ingreso medio en el dam 01 es 1.67 lineas de pobreza 11.3.4 Estimación para la dam2 == “00203” temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam2 == &quot;00203&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam2_00203 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 1.2141 0.0394 El resultado nos indica que el ingreso medio en la dam2 00203 es 1.21 lineas de pobreza Después de comprender la forma en que se realiza la estimación de los dominios no observados procedemos el uso de la función Aux_Agregado que es desarrollada para este fin. (mrp_estimate_Ingresolp &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = NULL) ) %&gt;% tba() Nacional mrp_estimate mrp_estimate_se Nacional 1.6535 0.0052 El resultado nos indica que el ingreso medio nacional es 2 lineas de pobreza De forma similar es posible obtener los resultados para las divisiones administrativas. mrp_estimate_dam &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = &quot;dam&quot;) tba(mrp_estimate_dam %&gt;% head(10) ) dam mrp_estimate mrp_estimate_se 01 1.6709 0.0159 02 1.5548 0.0340 03 1.1277 0.0122 04 1.4136 0.0211 05 1.5726 0.0460 06 1.6536 0.0229 07 1.1500 0.0421 08 1.7535 0.0258 09 1.9046 0.0248 10 1.1804 0.0385 mrp_estimate_dam2 &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = &quot;dam2&quot;) tba(mrp_estimate_dam2 %&gt;% head(10) ) dam2 mrp_estimate mrp_estimate_se 00101 1.6709 0.0159 00201 1.6356 0.0339 00202 1.2880 0.0418 00203 1.2141 0.0394 00204 2.0706 0.0991 00205 1.2337 0.0582 00206 1.3713 0.0429 00207 1.5580 0.3652 00208 1.4348 0.0501 00209 1.4726 0.3456 El mapa resultante es el siguiente "],["estimación-de-la-pobreza-a-partir-del-ingreso.html", "11.4 Estimación de la pobreza a partir del ingreso", " 11.4 Estimación de la pobreza a partir del ingreso "],["proceso-de-estimación-y-predicción-1.html", "11.5 Proceso de estimación y predicción", " 11.5 Proceso de estimación y predicción source(&quot;Recursos/Día4/Sesion1/0Recursos/funciones_mrp.R&quot;) fit &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/fit_ingresos.rds&quot;) La información auxiliar disponible ha sido extraída del censo e imágenes satelitales statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) tba(statelevel_predictors_df %&gt;% head(10)) dam2 modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion id_municipio 00101 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 00201 -0.0553 0.4449 0.2100 0.0684 -0.0682 -0.1511 0.8904 0.4933 0.2726 0.1849 0.1520 0.0614 0.3149 0.3022 0.0775 0.0082 0.1005 0.7220 0.2261 0.1300 0.9276 0.0664 0.0812 0.0249 0.1501 0.7975 0.3014 0.0007 050201 00202 -0.3758 0.0000 0.1482 -0.2345 -0.2855 -0.4234 0.6799 0.4697 0.2804 0.1895 0.1430 0.0515 0.3757 0.2405 0.0148 0.0014 0.1322 0.9230 0.2693 0.2884 0.9759 0.0625 0.0986 0.0673 0.0278 0.7140 0.3454 0.0001 050202 00203 -0.9259 0.5732 -0.1402 -0.5511 -0.3822 -0.5612 0.5814 0.4601 0.2665 0.1733 0.1586 0.0713 0.3778 0.2463 0.0219 0.0052 0.2579 0.7602 0.4824 0.2589 0.9919 0.1937 0.2342 0.1238 0.0485 0.7104 0.2755 0.0001 050203 00204 -1.3166 1.1111 0.4438 -0.5027 -0.3835 -0.6042 0.5708 0.4663 0.2647 0.1683 0.1673 0.0757 0.3306 0.2402 0.0440 0.0049 0.1672 0.6375 0.5040 0.3837 0.9759 0.1403 0.1354 0.0176 0.0873 0.6737 0.2671 0.0002 050204 00205 -0.7474 2.1155 1.2271 -0.5838 -0.3345 -0.5909 0.6937 0.4633 0.2849 0.2107 0.1473 0.0583 0.2794 0.2821 0.0562 0.0067 0.3800 0.6596 0.5014 0.2852 0.9894 0.2309 0.2498 0.0459 0.1016 0.6751 0.4973 0.0001 050205 00206 0.5157 -0.1468 -0.1811 1.1894 -0.1191 -0.4022 0.9563 0.4557 0.2910 0.1814 0.1495 0.0626 0.3793 0.2815 0.0427 0.0052 0.1301 0.8817 0.2565 0.1495 0.9659 0.0629 0.0472 0.0337 0.0835 0.8027 0.2200 0.0001 050206 00207 1.7368 -0.7648 -0.4861 0.7170 -0.0609 0.0042 0.5201 0.4783 0.2898 0.1675 0.1464 0.0531 0.3552 0.2901 0.0328 0.0061 0.2434 0.5775 0.2758 0.0950 0.9911 0.0717 0.2004 0.1304 0.0714 0.7778 0.3936 0.0001 050207 00208 -0.5942 0.3212 -0.1697 -0.3627 -0.3044 -0.4750 0.6625 0.4334 0.2943 0.1875 0.1523 0.0654 0.3557 0.2486 0.0250 0.0054 0.1908 0.8251 0.4152 0.1450 0.9907 0.1458 0.1517 0.0852 0.0509 0.6897 0.3051 0.0001 050208 00209 -1.5280 3.0192 1.9428 -0.8078 -0.4046 -0.6423 0.6798 0.4311 0.2858 0.1687 0.1628 0.0701 0.3648 0.2645 0.0752 0.0061 0.1893 0.5760 0.4096 0.3557 0.9978 0.1097 0.0941 0.0292 0.1357 0.7680 0.2189 0.0001 050209 Obtener el modelo es solo un paso más, ahora se debe realizar la predicción en el censo, el cual a sido previamente estandarizado y homologado con la encuesta. poststrat_df &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/censo_mrp_dam2.rds&quot;) %&gt;% left_join(statelevel_predictors_df) tba( poststrat_df %&gt;% arrange(desc(n)) %&gt;% head(10)) dam dam2 id_municipio nombre_region region area sexo edad anoest n modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion 32 03201 103201 Región Ozama 10 1 2 2 3 78858 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 32 03201 103201 Región Ozama 10 1 1 2 3 77566 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 1 2 3 76098 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 01 00101 100101 Región Ozama 10 1 2 2 3 76002 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 25 02501 012501 Región Cibao Norte 01 1 2 2 3 52770 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 25 02501 012501 Región Cibao Norte 01 1 1 2 3 51227 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 32 03201 103201 Región Ozama 10 1 1 1 2 50744 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 1 1 2 50015 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 32 03201 103201 Región Ozama 10 1 2 1 2 49652 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 2 1 2 49010 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 Note que la información del censo esta agregada. 11.5.1 Distribución posterior. Para obtener una distribución posterior de cada observación se hace uso de la función posterior_epred de la siguiente forma. epred_mat &lt;- posterior_epred(fit, newdata = poststrat_df, type = &quot;response&quot;) dim(epred_mat) dim(poststrat_df) Como el interés es realizar comparaciones entre los países de la región se presenta la estimación del ingreso medio en términos de lineas de pobreza. Para esto procedemos así: Obteniendo las lineas de pobreza por cada post-estrato ( lp &lt;- readRDS(&quot;Recursos/Día4/Sesion1/Data/encuestaDOM21N1.rds&quot;) %&gt;% distinct(area_ee, lp, li) %&gt;% mutate( area = ifelse( haven::as_factor(area_ee, levels = &quot;values&quot;) == 1 , &quot;1&quot;, &quot;0&quot;), area_ee = NULL ) ) %&gt;% tba() lp li area 5622.81 3159.09 1 4876.69 3061.23 0 5710.40 3193.03 1 4949.12 3094.12 0 5844.03 3291.64 1 5070.47 3189.68 0 5973.59 3377.04 1 5185.77 3272.42 0 Ingreso en términos de lineas de pobreza. lp %&lt;&gt;% group_by(area) %&gt;% summarise(lp = mean(lp),li = mean(li)) lp &lt;- inner_join(poststrat_df,lp,by = &quot;area&quot;) %&gt;% select(lp) epred_mat_pobreza_lp &lt;- (exp(epred_mat)-1) &lt;= lp$lp epred_mat_pobreza_li &lt;- (exp(epred_mat)-1) &lt;= lp$li "],["estimación-de-la-pobreza.html", "11.6 Estimación de la pobreza", " 11.6 Estimación de la pobreza n_filtered &lt;- poststrat_df$n mrp_estimates &lt;- epred_mat_pobreza_lp %*% n_filtered / sum(n_filtered) (temp_ing &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() 11.6.1 Estimación para el dam == “01”. Es importante siempre conservar el orden de la base, dado que relación entre la predicción y el censo en uno a uno. temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam == &quot;01&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat_pobreza_lp[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam01 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0 0 El resultado nos indica que la proporción de personas en condición de pobreza en la dam 01 es 0 11.6.2 Estimación para la dam2 == “00203” temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam2 == &quot;00203&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat_pobreza_lp[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam2_00203 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.2487 0.052 El resultado nos indica que la proporción de personas en condición de pobreza en la dam2 = 00203 es 0.25 lineas de pobreza Después de comprender la forma en que se realiza la estimación de los dominios no observados procedemos el uso de la función Aux_Agregado que es desarrollada para este fin. (mrp_estimate_Ingresolp &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat_pobreza_lp, byMap = NULL) ) Nacional mrp_estimate mrp_estimate_se Nacional 0.034 0.0025 De forma similar es posible obtener los resultados para las divisiones administrativas. mrp_estimate_dam &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat_pobreza_lp, byMap = &quot;dam&quot;) tba(mrp_estimate_dam %&gt;% head(10)) dam2 mrp_estimate mrp_estimate_se 00101 0.0000 0.0000 00201 0.0000 0.0000 00202 0.1778 0.0704 00203 0.2487 0.0520 00204 0.0000 0.0000 00205 0.2179 0.0650 00206 0.0967 0.0551 00207 0.1062 0.1718 00208 0.0630 0.0395 00209 0.1465 0.1983 mrp_estimate_dam2 &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat_pobreza_lp, byMap = &quot;dam2&quot;) tba(mrp_estimate_dam2 %&gt;% head(10) ) dam2 mrp_estimate mrp_estimate_se 00101 0.0000 0.0000 00201 0.0000 0.0000 00202 0.1778 0.0704 00203 0.2487 0.0520 00204 0.0000 0.0000 00205 0.2179 0.0650 00206 0.0967 0.0551 00207 0.1062 0.1718 00208 0.0630 0.0395 00209 0.1465 0.1983 El mapa resultante es el siguiente "],["día-3---sesión-3--modelo-de-unidad-para-la-estimación-de-la-pobreza.html", "Capítulo 12 Día 3 - Sesión 3- Modelo de unidad para la estimación de la pobreza", " Capítulo 12 Día 3 - Sesión 3- Modelo de unidad para la estimación de la pobreza Lo primero a tener en cuenta, es que no se debe usar una regresión lineal cuando se tiene una variable de tipo binario como variable dependiente, ya que no es posible estimar la probabilidad del evento estudiado de manera directa, por esta razón se emplea una regresión logística, en la que para obtener las estimaciones de la probabilidad del evento estudiado se debe realizar una transformación (logit), lo cual consiste en tomar el logaritmo de la probabilidad de éxito entre la probabilidad de fracaso, de la siguiente manera: \\[ \\ln \\frac{\\theta}{1-\\theta} \\] donde \\(\\theta\\) representa la probabilidad de éxito del evento. "],["modelo-de-regresión-logistica..html", "12.1 Modelo de regresión logistica.", " 12.1 Modelo de regresión logistica. Sea \\[ y_{ji}=\\begin{cases} 1 &amp; ingreso_{ji}\\le lp\\\\ 0 &amp; e.o.c. \\end{cases} \\] donde \\(ingreso_{ji}\\) representa el ingreso de la \\(i\\)-ésima persona en el \\(j\\)-ésimo post-estrato y \\(lp\\) es un valor limite, en particular la linea de pobreza. Empleando un modelo de regresión logística de efecto aleatorios pretende establecer la relación entre la expectativa \\(\\theta_{ji}\\) de la variable dicotómica con las covariables de información auxiliar disponibles para ser incluidas. El procedimiento correspondiente a este proceso, modela el logaritmo del cociente entre la probabilidad de estar por debajo de la linea de pobreza a su complemento en relación al conjunto de covariables a nivel de unidad, \\(x_{ji}\\), y el efecto aleatorio \\(u_d\\). \\[ \\begin{eqnarray*} \\ln\\left(\\frac{\\theta_{ji}}{1-\\theta_{ji}}\\right)=\\boldsymbol{x}_{ji}^{T}\\boldsymbol{\\beta}+u_d \\end{eqnarray*} \\] Donde los coeficientes \\(\\boldsymbol{\\beta}\\) hacen referencia a los efectos fijos de las variables \\(x_{ji}^T\\) sobre las probabilidades de que la \\(i\\)-ésima persona este por debajo de la linea de pobreza; por otro lado, \\(u_d\\) son los efectos fijos aleatorios, donde \\(u_{d}\\sim N\\left(0,\\sigma^2_{u}\\right)\\). Para este caso se asumen las distribuciones previas \\[ \\begin{eqnarray*} \\beta_k &amp; \\sim &amp; N(0, 1000)\\\\ \\sigma^2_u &amp;\\sim &amp; IG(0.0001,0.0001) \\end{eqnarray*} \\] las cuales se toman no informativas. A continuación se muestra el proceso realizado para la obtención de la predicción de la tasa de pobreza. "],["proceso-de-estimación-en-r-1.html", "12.2 Proceso de estimación en R", " 12.2 Proceso de estimación en R Para desarrollar la metodología se hace uso de las siguientes librerías. # Interprete de STAN en R library(rstan) library(rstanarm) # Manejo de bases de datos. library(tidyverse) # Gráficas de los modelos. library(bayesplot) library(patchwork) # Organizar la presentación de las tablas library(kableExtra) library(printr) Un conjunto de funciones desarrolladas para realizar de forma simplificada los procesos están consignadas en la siguiente rutina. source(&quot;Recursos/Día4/Sesion2/0Recursos/funciones_mrp.R&quot;) Entre las funciones incluidas en el archivo encuentra plot_interaction: Esta crea un diagrama de lineas donde se estudia la interacción entre las variables, en el caso de presentar un traslape de las lineas se recomienda incluir el interacción en el modelo. Plot_Compare Puesto que es necesario realizar una homologar la información del censo y la encuesta es conveniente llevar a cabo una validación de las variables que han sido homologadas, por tanto, se espera que las proporciones resultantes del censo y la encuesta estén cercanas entre sí. Aux_Agregado: Esta es función permite obtener estimaciones a diferentes niveles de agregación, toma mucha relevancia cuando se realiza un proceso repetitivo. Las funciones están diseñada específicamente para este proceso 12.2.1 Encuesta de hogares Los datos empleados en esta ocasión corresponden a la ultima encuesta de hogares, la cual ha sido estandarizada por CEPAL y se encuentra disponible en BADEHOG encuesta &lt;- readRDS(&quot;Recursos/Día4/Sesion2/Data/encuestaDOM21N1.rds&quot;) encuesta_mrp &lt;- encuesta %&gt;% transmute( dam = haven::as_factor(dam_ee,levels = &quot;values&quot;), dam = str_pad(string = dam, width = 2, pad = &quot;0&quot;), dam2, ingreso = ingcorte, lp, li, area = haven::as_factor(area_ee,levels = &quot;values&quot;), area = case_when(area == 1 ~ &quot;1&quot;, TRUE ~ &quot;0&quot;), pobreza = ifelse(ingcorte &lt; lp,1,0), sexo = as.character(sexo), anoest = case_when( edad &lt; 5 | anoest == -1 | is.na(anoest) ~ &quot;98&quot; , #No aplica anoest == 99 ~ &quot;99&quot;, #NS/NR anoest == 0 ~ &quot;1&quot;, # Sin educacion anoest %in% c(1:6) ~ &quot;2&quot;, # 1 - 6 anoest %in% c(7:12) ~ &quot;3&quot;, # 7 - 12 anoest &gt; 12 ~ &quot;4&quot;, # mas de 12 TRUE ~ &quot;Error&quot; ), edad = case_when( edad &lt; 15 ~ &quot;1&quot;, edad &lt; 30 ~ &quot;2&quot;, edad &lt; 45 ~ &quot;3&quot;, edad &lt; 65 ~ &quot;4&quot;, TRUE ~ &quot;5&quot;), fep = `_fep` ) tba(encuesta_mrp %&gt;% head(10)) dam dam2 ingreso lp li area pobreza sexo anoest edad fep 01 00101 54000.00 5622.81 3159.09 1 0 1 4 3 137.0652 01 00101 16388.89 5622.81 3159.09 1 0 2 3 4 137.0652 01 00101 16388.89 5622.81 3159.09 1 0 1 3 5 137.0652 01 00101 16388.89 5622.81 3159.09 1 0 1 4 2 137.0652 01 00101 6224.00 5622.81 3159.09 1 0 2 2 4 137.0652 01 00101 6224.00 5622.81 3159.09 1 0 1 3 3 137.0652 01 00101 6224.00 5622.81 3159.09 1 0 2 4 2 137.0652 01 00101 20672.00 5622.81 3159.09 1 0 2 1 5 137.0652 01 00101 8495.60 5622.81 3159.09 1 0 1 4 3 137.0652 01 00101 8495.60 5622.81 3159.09 1 0 2 3 3 137.0652 La base de datos de la encuesta tiene la siguientes columnas: dam: Corresponde al código asignado a la división administrativa mayor del país. dam2: Corresponde al código asignado a la segunda división administrativa del país. lp y li lineas de pobreza y pobreza extrema definidas por CEPAL. área división geográfica (Urbano y Rural). sexo Hombre y Mujer. etnia En estas variable se definen tres grupos: afrodescendientes, indígenas y Otros. Años de escolaridad (anoest) Rangos de edad (edad) Factor de expansión por persona (fep) Ahora, inspeccionamos el comportamiento de la variable de interés: tab &lt;- encuesta_mrp %&gt;% group_by(pobreza) %&gt;% tally() %&gt;% mutate(prop = round(n/sum(n),2), pobreza = ifelse(pobreza == 1, &quot;Si&quot;, &quot;No&quot;)) ggplot(data = tab, aes(x = pobreza, y = prop)) + geom_bar(stat = &quot;identity&quot;) + labs(y = &quot;&quot;, x = &quot;&quot;) + geom_text(aes(label = paste(prop*100,&quot;%&quot;)), nudge_y=0.05) + theme_bw(base_size = 20) + theme(axis.text.y = element_blank(), axis.ticks = element_blank()) Figura 12.1: Proporción de personas por debajo de la linea de pobreza La información auxiliar disponible ha sido extraída del censo e imágenes satelitales statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día4/Sesion2/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) tba(statelevel_predictors_df %&gt;% head(10)) dam2 modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion id_municipio 00101 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 00201 -0.0553 0.4449 0.2100 0.0684 -0.0682 -0.1511 0.8904 0.4933 0.2726 0.1849 0.1520 0.0614 0.3149 0.3022 0.0775 0.0082 0.1005 0.7220 0.2261 0.1300 0.9276 0.0664 0.0812 0.0249 0.1501 0.7975 0.3014 0.0007 050201 00202 -0.3758 0.0000 0.1482 -0.2345 -0.2855 -0.4234 0.6799 0.4697 0.2804 0.1895 0.1430 0.0515 0.3757 0.2405 0.0148 0.0014 0.1322 0.9230 0.2693 0.2884 0.9759 0.0625 0.0986 0.0673 0.0278 0.7140 0.3454 0.0001 050202 00203 -0.9259 0.5732 -0.1402 -0.5511 -0.3822 -0.5612 0.5814 0.4601 0.2665 0.1733 0.1586 0.0713 0.3778 0.2463 0.0219 0.0052 0.2579 0.7602 0.4824 0.2589 0.9919 0.1937 0.2342 0.1238 0.0485 0.7104 0.2755 0.0001 050203 00204 -1.3166 1.1111 0.4438 -0.5027 -0.3835 -0.6042 0.5708 0.4663 0.2647 0.1683 0.1673 0.0757 0.3306 0.2402 0.0440 0.0049 0.1672 0.6375 0.5040 0.3837 0.9759 0.1403 0.1354 0.0176 0.0873 0.6737 0.2671 0.0002 050204 00205 -0.7474 2.1155 1.2271 -0.5838 -0.3345 -0.5909 0.6937 0.4633 0.2849 0.2107 0.1473 0.0583 0.2794 0.2821 0.0562 0.0067 0.3800 0.6596 0.5014 0.2852 0.9894 0.2309 0.2498 0.0459 0.1016 0.6751 0.4973 0.0001 050205 00206 0.5157 -0.1468 -0.1811 1.1894 -0.1191 -0.4022 0.9563 0.4557 0.2910 0.1814 0.1495 0.0626 0.3793 0.2815 0.0427 0.0052 0.1301 0.8817 0.2565 0.1495 0.9659 0.0629 0.0472 0.0337 0.0835 0.8027 0.2200 0.0001 050206 00207 1.7368 -0.7648 -0.4861 0.7170 -0.0609 0.0042 0.5201 0.4783 0.2898 0.1675 0.1464 0.0531 0.3552 0.2901 0.0328 0.0061 0.2434 0.5775 0.2758 0.0950 0.9911 0.0717 0.2004 0.1304 0.0714 0.7778 0.3936 0.0001 050207 00208 -0.5942 0.3212 -0.1697 -0.3627 -0.3044 -0.4750 0.6625 0.4334 0.2943 0.1875 0.1523 0.0654 0.3557 0.2486 0.0250 0.0054 0.1908 0.8251 0.4152 0.1450 0.9907 0.1458 0.1517 0.0852 0.0509 0.6897 0.3051 0.0001 050208 00209 -1.5280 3.0192 1.9428 -0.8078 -0.4046 -0.6423 0.6798 0.4311 0.2858 0.1687 0.1628 0.0701 0.3648 0.2645 0.0752 0.0061 0.1893 0.5760 0.4096 0.3557 0.9978 0.1097 0.0941 0.0292 0.1357 0.7680 0.2189 0.0001 050209 12.2.2 Niveles de agregación para colapsar la encuesta Después de realizar una investigación en la literatura especializada y realizar estudios de simulación fue posible evidenciar que las predicciones obtenidas con la muestra sin agregar y la muestra agregada convergen a la media del dominio. byAgrega &lt;- c(&quot;dam&quot;, &quot;dam2&quot;, &quot;area&quot;, &quot;sexo&quot;, &quot;anoest&quot;, &quot;edad&quot; ) 12.2.3 Creando base con la encuesta agregada El resultado de agregar la base de dato se muestra a continuación: encuesta_df_agg &lt;- encuesta_mrp %&gt;% # Encuesta group_by_at(all_of(byAgrega)) %&gt;% # Agrupar por el listado de variables summarise(n = n(), # Número de observaciones # conteo de personas con características similares. pobreza = sum(pobreza), no_pobreza = n-pobreza, .groups = &quot;drop&quot;) %&gt;% arrange(desc(pobreza)) # Ordenar la base. La tabla obtenida es la siguiente: dam dam2 area sexo anoest edad n pobreza no_pobreza 01 00101 1 2 3 2 624 221 403 32 03201 1 2 2 1 359 158 201 01 00101 1 1 2 1 401 155 246 32 03201 1 2 3 2 576 154 422 01 00101 1 2 2 1 348 148 200 32 03201 1 1 2 1 369 145 224 01 00101 1 1 3 2 652 135 517 32 03203 1 2 3 2 393 128 265 01 00101 1 1 98 1 302 127 175 25 02501 1 2 3 2 447 126 321 El paso a seguir es unificar las tablas creadas. encuesta_df_agg &lt;- inner_join(encuesta_df_agg, statelevel_predictors_df) 12.2.4 Definiendo el modelo multinivel. Después de haber ordenado la encuesta, podemos pasar a la definición del modelo. options(mc.cores = parallel::detectCores()) # Permite procesar en paralelo. fit &lt;- stan_glmer( cbind(pobreza, no_pobreza) ~ (1 | dam2) + # Efecto aleatorio (ud) edad + # Efecto fijo (Variables X) sexo + tasa_desocupacion + luces_nocturnas + cubrimiento_cultivo + cubrimiento_urbano , data = encuesta_df_agg, # Encuesta agregada verbose = TRUE, # Muestre el avance del proceso chains = 4, # Número de cadenas. iter = 1000, # Número de realizaciones de la cadena cores = 4, family = binomial(link = &quot;logit&quot;) ) saveRDS(fit, file = &quot;Recursos/Día4/Sesion2/Data/fit_pobreza.rds&quot;) Después de esperar un tiempo prudente se obtiene el siguiente modelo. fit &lt;- readRDS(&quot;Recursos/Día4/Sesion2/Data/fit_pobreza.rds&quot;) Validación del modelo library(posterior) library(bayesplot) var_names &lt;- c(&quot;edad2&quot;, &quot;edad3&quot;, &quot;edad4&quot;, &quot;edad5&quot;, &quot;sexo2&quot;, &quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;,&quot;cubrimiento_urbano&quot;) mcmc_areas(fit,pars = var_names) mcmc_trace(fit,pars = var_names) encuesta_mrp2 &lt;- inner_join(encuesta_mrp, statelevel_predictors_df) y_pred_B &lt;- posterior_epred(fit, newdata = encuesta_mrp2) rowsrandom &lt;- sample(nrow(y_pred_B), 100) y_pred2 &lt;- y_pred_B[rowsrandom, ] ppc_dens_overlay(y = as.numeric(encuesta_mrp2$pobreza), y_pred2) Figura 12.2: Tasa de pobreza por dam2 Los coeficientes del modelo para las primeras dam2 son: (Intercept) edad2 edad3 edad4 edad5 sexo2 tasa_desocupacion luces_nocturnas cubrimiento_cultivo cubrimiento_urbano 00101 -0.7843 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00201 -0.8704 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00202 -0.5086 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00203 -0.2080 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00204 -0.9745 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00205 -0.5200 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00206 -0.1536 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00208 -0.4769 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00210 -1.3939 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 00301 0.2809 -0.7164 -0.7355 -1.5045 -1.6397 0.2901 8.0861 -0.2643 -0.0691 0.197 "],["proceso-de-estimación-y-predicción-2.html", "12.3 Proceso de estimación y predicción", " 12.3 Proceso de estimación y predicción Obtener el modelo es solo un paso más, ahora se debe realizar la predicción en el censo, el cual fue estandarizado y homologado con la encuesta previamente. poststrat_df &lt;- readRDS(&quot;Recursos/Día4/Sesion2/Data/censo_mrp_dam2.rds&quot;) %&gt;% left_join(statelevel_predictors_df) tba( poststrat_df %&gt;% arrange(desc(n)) %&gt;% head(10)) dam dam2 id_municipio nombre_region region area sexo edad anoest n modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion 32 03201 103201 Región Ozama 10 1 2 2 3 78858 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 32 03201 103201 Región Ozama 10 1 1 2 3 77566 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 1 2 3 76098 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 01 00101 100101 Región Ozama 10 1 2 2 3 76002 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 25 02501 012501 Región Cibao Norte 01 1 2 2 3 52770 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 25 02501 012501 Región Cibao Norte 01 1 1 2 3 51227 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 32 03201 103201 Región Ozama 10 1 1 1 2 50744 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 1 1 2 50015 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 32 03201 103201 Región Ozama 10 1 2 1 2 49652 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 01 00101 100101 Región Ozama 10 1 2 1 2 49010 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 Note que la información del censo esta agregada. 12.3.1 Distribución posterior. Para obtener una distribución posterior de cada observación se hace uso de la función posterior_epred de la siguiente forma. epred_mat &lt;- posterior_epred(fit, newdata = poststrat_df, type = &quot;response&quot;) dim(epred_mat) dim(poststrat_df) 12.3.2 Estimación de la tasa de pobreza n_filtered &lt;- poststrat_df$n mrp_estimates &lt;- epred_mat %*% n_filtered / sum(n_filtered) (temp_ing &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.244 0.0022 El resultado indican la proporción de personas por debajo de la linea de probreza 0.24 lineas de pobreza 12.3.3 Estimación para el dam == “01”. Es importante siempre conservar el orden de la base, dado que relación entre la predicción y el censo en uno a uno. temp &lt;- poststrat_df %&gt;% mutate( Posi = 1:n()) temp &lt;- filter(temp, dam == &quot;01&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam01 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.2615 0.0053 El resultado nos indica que la tasa de pobreza en la dam 01 es 0.26 12.3.4 Estimación para la dam2 == “00203” temp &lt;- poststrat_df %&gt;% mutate(Posi = 1:n()) temp &lt;- filter(temp, dam2 == &quot;00203&quot;) %&gt;% select(n, Posi) n_filtered &lt;- temp$n temp_epred_mat &lt;- epred_mat[, temp$Posi] ## Estimando el CME mrp_estimates &lt;- temp_epred_mat %*% n_filtered / sum(n_filtered) (temp_dam2_00203 &lt;- data.frame( mrp_estimate = mean(mrp_estimates), mrp_estimate_se = sd(mrp_estimates) ) ) %&gt;% tba() mrp_estimate mrp_estimate_se 0.3566 0.0337 El resultado nos indica que la tasa de pobreza en la dam2 05001 es 0.36 Después de comprender la forma en que se realiza la estimación de los dominios no observados procedemos el uso de la función Aux_Agregado que es desarrollada para este fin. (mrp_estimate_Ingresolp &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = NULL) ) %&gt;% tba() Nacional mrp_estimate mrp_estimate_se Nacional 0.244 0.0022 De forma similar es posible obtener los resultados para las divisiones administrativas del país. mrp_estimate_dam &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = &quot;dam&quot;) tba(mrp_estimate_dam %&gt;% head(10)) dam mrp_estimate mrp_estimate_se 01 0.2615 0.0053 02 0.2599 0.0161 03 0.4945 0.0114 04 0.3811 0.0111 05 0.2812 0.0245 06 0.1845 0.0096 07 0.4678 0.0252 08 0.2237 0.0112 09 0.1357 0.0093 10 0.4550 0.0223 mrp_estimate_dam2 &lt;- Aux_Agregado(poststrat = poststrat_df, epredmat = epred_mat, byMap = &quot;dam2&quot;) tba(mrp_estimate_dam2 %&gt;% head(10) ) dam2 mrp_estimate mrp_estimate_se 00101 0.2615 0.0053 00201 0.2188 0.0175 00202 0.2939 0.0311 00203 0.3566 0.0337 00204 0.2157 0.0469 00205 0.2961 0.0436 00206 0.3471 0.0297 00207 0.2742 0.1614 00208 0.2932 0.0340 00209 0.2990 0.1686 El mapa resultante es el siguiente Figura 12.3: Tasa de pobreza por dam2 "],["día-4---sesión-3--modelos-de-unidad---estimación-de-head-ratio-para-h.html", "Capítulo 13 Día 4 - Sesión 3- Modelos de unidad - Estimación de head ratio para H", " Capítulo 13 Día 4 - Sesión 3- Modelos de unidad - Estimación de head ratio para H La pobreza es, y ha sido, uno de los temas principales en las agendas nacionales e internacionales de los países durante décadas. Un ejemplo reciente es el primer objetivo de la agenda 2030 para el Desarrollo Sostenible (ODS): “Poner fin a la pobreza en todas sus formas en todo el mundo”, así como su indicador 1.2.2 que mide “la proporción de hombres, mujeres y niños de todas las edades que viven en pobreza en todas sus dimensiones según las definiciones nacionales” Tradicionalmente los organismos nacionales e internacionales exigen la medida de pobreza unidimensional basada en ingresos y/o gastos. La pobreza es un fenómeno complejo que debe ser analizado considerando un conjunto de factores y no solo el monetario. En está ocasión se aborda el problema multidimensional de la pobreza utilizando métodos de áreas pequeñas proporcionando una estimación del índice de privación multidimensional (H) en Colombia. "],["índice-de-privación-multidimensional-h.html", "13.1 Índice de Privación Multidimensional (H)", " 13.1 Índice de Privación Multidimensional (H) El H propuesto por CEPAL es una herramienta comparable entre los países de la región, para estudiar los fenómenos de la pobreza considerando varios aspectos o dimensiones. En ningún caso el H busca reemplazar los indicadores pobreza unidimensional o multidimensional que hayan definido los países u organismos internacionales El índice requiere la información para cada individuo \\(i = 1,\\cdots,N_d\\) en \\(d = 1, \\cdots, D\\) dominios, donde \\(N_d\\) denota el tamaño de la población del dominio \\(d\\). El índice para el dominio \\(d\\) se calcula como: \\[ H_d = \\frac{1}{N_d}\\sum_{i=1}^{N_d}I\\left(q_{di} &gt; 0.4 \\right). \\] La función del índicador \\(I\\left( \\cdot \\right)\\) es igual a 1 cuando la condición \\(q_{di} &gt; 0.4\\). \\(q_{di}\\) es una cantidad ponderada de la siguiente forma: \\[ q_{di} = \\frac{1}{8}\\sum_{k=1}^{8}y_{di}^{k} \\] Donde: \\(y_{di}^{1}\\) = Privación en material de construcción de la vivienda \\(y_{di}^{2}\\) = Hacinamiento en el hogar. \\(y_{di}^{3}\\) = Privación de acceso al agua potable. \\(y_{di}^{4}\\) = Privación en saneamiento. \\(y_{di}^{5}\\) = Acceso al servicio energía eléctrica. \\(y_{di}^{6}\\) = Privación de acceso al combustible para cocinar. \\(y_{di}^{7}\\) = Privación en material de los techo \\(y_{di}^{8}\\) = Privación el material de las paredes. Note que, \\(y_{di}^{k}\\) es igual a 1 si la persona tiene privación en la \\(k-ésima\\) dimesión y 0 en el caso que de no tener la privación. "],["definición-del-modelo.html", "13.2 Definición del modelo", " 13.2 Definición del modelo En muchas aplicaciones, la variable de interés en áreas pequeñas puede ser binaria, esto es \\(y_{dj} = 0\\) o \\(1\\) que representa la ausencia (o no) de una característica específica. Para este caso, la estimación objetivo en cada dominio \\(d = 1,\\cdots , D\\) es la proporción \\(\\theta_d =\\frac{1}{N_d}\\sum_{i=1}^{N_d}y_{di}\\) de la población que tiene esta característica, siendo \\(\\theta_{di}\\) la probabilidad de que una determinada unidad \\(i\\) en el dominio \\(d\\) obtenga el valor \\(1\\). Bajo este escenario, el \\(\\theta_{di}\\) con una función de enlace logit se define como: \\[ logit(\\theta_{di}) = \\log \\left(\\frac{\\theta_{di}}{1-\\theta_{di}}\\right) = \\boldsymbol{x}_{di}^{T}\\boldsymbol{\\beta} + u_{d} \\] con \\(i=1,\\cdots,N_d\\), \\(d=1,\\cdots,D\\), \\(\\boldsymbol{\\beta}\\) un vector de parámetros de efecto fijo, y \\(u_d\\) el efecto aleatorio especifico del área para el dominio \\(d\\) con \\(u_d \\sim N\\left(0,\\sigma^2_u \\right)\\). \\(u_d\\) son independiente y \\(y_{di}\\mid u_d \\sim Bernoulli(\\theta_{di})\\) con \\(E(y_{di}\\mid u_d)=\\theta_{di}\\) y \\(Var(y_{di}\\mid u_d)=\\sigma_{di}^2=\\theta_{di}(1-\\theta_{di})\\). Además, \\(\\boldsymbol{x}_{di}^T\\) representa el vector \\(p\\times 1\\) de valores de \\(p\\) variables auxiliares. Entonces, \\(\\theta_{di}\\) se puede escribir como \\[ \\theta_{di} = \\frac{\\exp(\\boldsymbol{x}_{di}^T\\boldsymbol{\\beta} + u_{d})}{1+ \\exp(\\boldsymbol{x}_{di}^T\\boldsymbol{\\beta} + u_{d})} \\] De está forma podemos definir distribuciones previas \\[ \\begin{eqnarray*} \\beta_k &amp; \\sim &amp; N(0, 10000)\\\\ \\sigma^2_u &amp;\\sim &amp; IG(0.0001,0.0001) \\end{eqnarray*} \\] El modelo se debe estimar para cada una de las dimensiones. Obejtivo Estimar la proporción de personas que presentan la \\(k-\\)ésima carencia, es decir, \\[ P_d = \\frac{\\sum_{U_d}q_{di}}{N_d} \\] donde \\(q_{di}\\) toma el valor de 1 cuando la \\(i-\\)ésima persona presenta Privación Multidimensional y el valor de 0 en caso contrario. Note que, \\[ \\begin{equation*} \\bar{Y}_d = P_d = \\frac{\\sum_{s_d}q_{di} + \\sum_{s^c_d}q_{di}}{N_d} \\end{equation*} \\] Ahora, el estimador de \\(P\\) esta dado por: \\[ \\hat{P}_d = \\frac{\\sum_{s_d}q_{di} + \\sum_{s^c_d}\\hat{q}_{di}}{N_d} \\] donde \\[ \\hat{q}_{di} = \\frac{1}{8}\\sum_{k=1}^{8}\\hat{y}_{di}^{k} \\] \\[\\hat{y}_{di}^{k}=E_{\\mathscr{M}}\\left(y_{di}^{k}\\mid\\boldsymbol{x}_{d},\\boldsymbol{\\beta}\\right)\\], con \\(\\mathscr{M}\\) la medida de probabilidad inducida por el modelamiento. De esta forma se tiene que, \\[ \\hat{P}_d = \\frac{\\sum_{U_{d}}\\hat{q}_{di}}{N_d} \\] 13.2.1 Procesamiento del modelo en R. El proceso inicia con el cargue de las librerías. library(patchwork) library(lme4) library(tidyverse) library(rstan) library(rstanarm) library(magrittr) Los datos de la encuesta y el censo han sido preparados previamente, la información sobre la cual realizaremos la predicción corresponde a Colombia en el 2019 encuesta_H &lt;- readRDS(&quot;Recursos/Día4/Sesion3/Data/encuesta_ipm.rds&quot;) statelevel_predictors_df &lt;- readRDS(&quot;Recursos/Día4/Sesion3/Data/statelevel_predictors_df_dam2.rds&quot;) %&gt;% mutate_at(.vars = c(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x) as.numeric(scale(x))) byAgrega &lt;- c(&quot;dam&quot;, &quot;dam2&quot;, &quot;area&quot;, &quot;sexo&quot;,&quot;anoest&quot;, &quot;edad&quot; ) names_H &lt;- grep(pattern = &quot;nbi&quot;, names(encuesta_H),value = TRUE) encuesta_df &lt;- map(setNames(names_H,names_H), function(y){ encuesta_H$temp &lt;- encuesta_H[[y]] encuesta_H %&gt;% group_by_at(all_of(byAgrega)) %&gt;% summarise(n = n(), yno = sum(temp), ysi = n - yno, .groups = &quot;drop&quot;) %&gt;% inner_join(statelevel_predictors_df) }) Privación en material de construcción de la vivienda Tabla 13.1: nbi_matviv dam dam2 area sexo anoest edad n yno ysi modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion id_municipio 01 00101 1 1 3 2 652 27 625 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 01 00101 1 2 3 2 624 24 600 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 32 03201 1 2 3 2 575 22 553 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 103201 32 03201 1 1 3 2 547 39 508 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 103201 25 02501 1 1 3 2 505 25 480 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 012501 25 02501 1 2 3 2 447 15 432 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 012501 Hacinamiento dam dam2 area sexo anoest edad n yno ysi modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion id_municipio 01 00101 1 1 3 2 652 221 431 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 01 00101 1 2 3 2 624 207 417 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 32 03201 1 2 3 2 575 181 394 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 103201 32 03201 1 1 3 2 547 167 380 2.7794 -1.1311 -1.4114 -0.3529 4.1625 3.8009 0.9256 0.5173 0.2869 0.2158 0.1599 0.0502 0.2161 0.4041 0.1677 0.0161 0.0200 0.7131 0.0571 0.1791 0.7701 0.0102 0.0245 0.0153 0.2883 0.9252 0.1870 0.0074 103201 25 02501 1 1 3 2 505 101 404 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 012501 25 02501 1 2 3 2 447 89 358 1.4723 -0.9237 -1.0018 0.3619 1.3166 1.6641 0.8601 0.5084 0.2837 0.2250 0.1564 0.0596 0.2622 0.3832 0.1282 0.0114 0.0189 0.8665 0.1021 0.1307 0.7972 0.0134 0.0136 0.0160 0.2118 0.8939 0.1787 0.0044 012501 13.2.2 Definiendo el modelo multinivel. Para cada dimensión que compone el H se ajusta el siguiente modelo mostrado en el script. En este código se incluye el uso de la función future_map que permite procesar en paralelo cada modelo O puede compilar cada por separado. library(furrr) library(rstanarm) plan(multisession, workers = 4) fit &lt;- future_map(encuesta_df, function(xdat){ stan_glmer( cbind(yno, ysi) ~ (1 | dam2) + (1 | dam) + (1|edad) + area + (1|anoest) + sexo + tasa_desocupacion + luces_nocturnas + modificacion_humana, family = binomial(link = &quot;logit&quot;), data = xdat, cores = 7, chains = 4, iter = 300 )}, .progress = TRUE) saveRDS(object = fit, &quot;Recursos/Día4/Sesion3/Data/fits_H.rds&quot;) Terminado la compilación de los modelos después de realizar validaciones sobre esto, pasamos hacer las predicciones en el censo. 13.2.3 Proceso de estimación y predicción Los modelos fueron compilados de manera separada, por tanto, disponemos de un objeto .rds por cada dimensión del H fit_agua &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_agua.rds&quot;) fit_combustible &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_combus.rds&quot;) fit_techo &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_techo.rds&quot;) fit_energia &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_elect.rds&quot;) fit_hacinamiento &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_hacina.rds&quot;) fit_paredes &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_pared.rds&quot;) fit_material &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_matviv.rds&quot;) fit_saneamiento &lt;- readRDS(file = &quot;Recursos/Día4/Sesion3/Data/fits_bayes_nbi_saneamiento.rds&quot;) Ahora, debemos leer la información del censo y crear los post-estrato censo_H &lt;- readRDS(&quot;Recursos/Día4/Sesion3/Data/censo_mrp_dam2.rds&quot;) poststrat_df &lt;- censo_H %&gt;% group_by_at(byAgrega) %&gt;% summarise(n = sum(n), .groups = &quot;drop&quot;) %&gt;% arrange(desc(n)) tba(head(poststrat_df)) dam dam2 area sexo anoest edad n 32 03201 1 2 3 2 78858 32 03201 1 1 3 2 77566 01 00101 1 1 3 2 76098 01 00101 1 2 3 2 76002 25 02501 1 2 3 2 52770 25 02501 1 1 3 2 51227 Para realizar la predicción en el censo debemos incluir la información auxiliar poststrat_df &lt;- inner_join(poststrat_df, statelevel_predictors_df) dim(poststrat_df) ## [1] 14120 36 Para cada uno de los modelos anteriores debe tener las predicciones, para ejemplificar el proceso tomaremos el departamento de la Guajira de Colombia Privación de acceso al agua potable. temp &lt;- poststrat_df epred_mat_agua &lt;- posterior_epred( fit_agua, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Privación de acceso al combustible para cocinar. epred_mat_combustible &lt;- posterior_epred( fit_combustible, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Privación en material de los techo. epred_mat_techo &lt;- posterior_epred( fit_techo, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Acceso al servicio energía eléctrica. epred_mat_energia &lt;- posterior_epred( fit_energia, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Hacinamiento en el hogar. epred_mat_hacinamiento &lt;- posterior_epred( fit_hacinamiento, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Privación el material de las paredes. epred_mat_paredes &lt;- posterior_epred( fit_paredes, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Privación en material de construcción de la vivienda epred_mat_material &lt;- posterior_epred( fit_material, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Privación en saneamiento. epred_mat_saneamiento &lt;- posterior_epred( fit_saneamiento, newdata = temp, type = &quot;response&quot;, allow.new.levels = TRUE ) Los resultados anteriores se deben procesarse en términos de carencia (1) y no carencia (0) para la \\(k-esima\\) dimensión . Privación de acceso al agua potable. epred_mat_agua_dummy &lt;- rbinom(n = nrow(epred_mat_agua) * ncol(epred_mat_agua) , 1, epred_mat_agua) epred_mat_agua_dummy &lt;- matrix( epred_mat_agua_dummy, nrow = nrow(epred_mat_agua), ncol = ncol(epred_mat_agua) ) Privación de acceso al combustible para cocinar. epred_mat_combustible_dummy &lt;- rbinom(n = nrow(epred_mat_combustible) * ncol(epred_mat_combustible) , 1, epred_mat_combustible) epred_mat_combustible_dummy &lt;- matrix( epred_mat_combustible_dummy, nrow = nrow(epred_mat_combustible), ncol = ncol(epred_mat_combustible) ) Acceso al servicio energía eléctrica epred_mat_energia_dummy &lt;- rbinom(n = nrow(epred_mat_energia) * ncol(epred_mat_energia) , 1, epred_mat_energia) epred_mat_energia_dummy &lt;- matrix( epred_mat_energia_dummy, nrow = nrow(epred_mat_energia), ncol = ncol(epred_mat_energia) ) Hacinamiento en el hogar. epred_mat_hacinamiento_dummy &lt;- rbinom( n = nrow(epred_mat_hacinamiento) * ncol(epred_mat_hacinamiento) , 1, epred_mat_hacinamiento ) epred_mat_hacinamiento_dummy &lt;- matrix( epred_mat_hacinamiento_dummy, nrow = nrow(epred_mat_hacinamiento), ncol = ncol(epred_mat_hacinamiento) ) Privación el material de las paredes. epred_mat_paredes_dummy &lt;- rbinom(n = nrow(epred_mat_paredes) * ncol(epred_mat_paredes) , 1, epred_mat_paredes) epred_mat_paredes_dummy &lt;- matrix( epred_mat_paredes_dummy, nrow = nrow(epred_mat_paredes), ncol = ncol(epred_mat_paredes) ) Privación en material de construcción de la vivienda epred_mat_material_dummy &lt;- rbinom(n = nrow(epred_mat_material) * ncol(epred_mat_material) , 1, epred_mat_material) epred_mat_material_dummy &lt;- matrix( epred_mat_material_dummy, nrow = nrow(epred_mat_material), ncol = ncol(epred_mat_material) ) Privación en saneamiento. epred_mat_saneamiento_dummy &lt;- rbinom(n = nrow(epred_mat_saneamiento) * ncol(epred_mat_saneamiento) , 1, epred_mat_saneamiento) epred_mat_saneamiento_dummy &lt;- matrix( epred_mat_saneamiento_dummy, nrow = nrow(epred_mat_saneamiento), ncol = ncol(epred_mat_saneamiento) ) Privación en material de los techo. epred_mat_techo_dummy &lt;- rbinom(n = nrow(epred_mat_techo) * ncol(epred_mat_techo) , 1, epred_mat_techo) epred_mat_techo_dummy &lt;- matrix( epred_mat_techo_dummy, nrow = nrow(epred_mat_techo), ncol = ncol(epred_mat_techo) ) Con las variables dummy creadas es posible estimar el H epred_mat_H &lt;- (1/8) * ( epred_mat_material_dummy + epred_mat_hacinamiento_dummy + epred_mat_agua_dummy + epred_mat_saneamiento_dummy + epred_mat_energia_dummy + epred_mat_paredes_dummy + epred_mat_combustible_dummy + epred_mat_techo_dummy) Ahora, debemos dicotomizar la variable nuevamente. epred_mat_H[epred_mat_H &lt;= 0.4] &lt;- 0 epred_mat_H[epred_mat_H != 0] &lt;- 1 Finalmente realizamos el calculo del H así: mean(colSums(t(epred_mat_H)*poststrat_df$n)/sum(poststrat_df$n)) ## [1] 0.008795743 También es posible utilizar la función Aux_Agregado para las estimaciones. Para obtener el resultado por municipio procedemos así: source(&quot;Recursos/Día4/Sesion3/0Recursos/funciones_mrp.R&quot;) mrp_estimate_dam2 &lt;- Aux_Agregado(poststrat = temp, epredmat = epred_mat_H, byMap = &quot;dam2&quot;) tba(mrp_estimate_dam2 %&gt;% head(10)) dam2 mrp_estimate mrp_estimate_se 00101 0.0011 0.0056 00201 0.0010 0.0037 00202 0.0010 0.0039 00203 0.0143 0.0136 00204 0.0006 0.0034 00205 0.0002 0.0018 00206 0.0060 0.0117 00207 0.0072 0.0187 00208 0.0015 0.0054 00209 0.0024 0.0067 El siguiente paso es realizar el mapa de los resultados library(sp) library(sf) library(tmap) ShapeSAE &lt;- read_sf(&quot;Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) Los resultados nacionales son mostrados en el mapa. brks_ing &lt;- c(0,0.05,0.1,0.15, 0.20 ,0.3, 1) maps3 &lt;- tm_shape(ShapeSAE %&gt;% left_join(mrp_estimate_dam2, by = &quot;dam2&quot;)) Mapa_ing3 &lt;- maps3 + tm_polygons( &quot;mrp_estimate&quot;, breaks = brks_ing, title = &quot;H&quot;, palette = &quot;YlOrRd&quot;, colorNA = &quot;white&quot; ) tmap_save( Mapa_ing3, &quot;Recursos/Día4/Sesion3/Data/DOM_H.jpeg&quot;, width = 2000, height = 1500, asp = 0 ) Mapa_ing3 Los resultado para cada componente puede ser mapeado de forma similar. Para obtener el resultado por municipio procedemos así: Indicador dam2 mrp_estimate Material 00101 0.0466 Material 00201 0.0337 Material 00202 0.0333 Material 00203 0.0562 Material 00204 0.0193 Material 00205 0.0148 Material 00206 0.0885 Material 00207 0.0746 Material 00208 0.0884 Material 00209 0.0430 "],["día-5---sesión-1--modelo-de-área-para-estadísticas-del-mercado-de-trabajo.html", "Capítulo 14 Día 5 - Sesión 1- Modelo de área para estadísticas del mercado de trabajo", " Capítulo 14 Día 5 - Sesión 1- Modelo de área para estadísticas del mercado de trabajo La Encuesta Nacional Continua de Fuerza de Trabajo (ENCFT) es una investigación estadística que se realiza en la República Dominicana para proporcionar información precisa y amplia sobre las variables laborales, sociodemográficas y económicas que permiten caracterizar y analizar la dinámica y heterogeneidad del mercado de trabajo en el país. La ENCFT se lleva a cabo mediante una muestra probabilística de hogares, donde se encuestan a los jefes de hogar o a cualquier otro miembro del hogar mayor de 14 años, y se realiza de manera trimestral en todo el territorio nacional. La encuesta permite conocer información relevante acerca de la población económicamente activa, la población ocupada y desocupada, la tasa de actividad y la tasa de desempleo, entre otros indicadores, lo que la convierte en una herramienta valiosa para la elaboración de políticas públicas y programas de empleo. La ENCFT es una encuesta continua, lo que permite hacer seguimiento a la evolución del mercado de trabajo y evaluar el impacto de las políticas públicas y los programas de empleo. "],["definición-del-modelo-multinomial.html", "14.1 Definición del modelo multinomial", " 14.1 Definición del modelo multinomial Sea \\(K\\) el número de categorías de la variable de interés \\(\\sim multinimial\\left(\\boldsymbol{\\theta}\\right)\\), con \\(\\boldsymbol{\\theta}=\\left(p_{1},p_{2},\\dots ,p_{k}\\right)\\) y \\(\\sum_{k=1}^{K}p_{k}=1\\). Sea \\(N_i\\) el número de elementos en el i-ésiamo dominio y \\(N_{ik}\\) el número de elementos que tienen la k-ésima categoría, note que \\(\\sum_{k=1}^{K}N_{ik}=N_{i}\\) y \\(p_{ik}=\\frac{N_{ik}}{N_{i}}\\). Sea \\(\\hat{p}_{ik}\\) la estimación directa de \\(p_{ik}\\) y \\(v_{ik}=Var\\left(\\hat{p}_{ik}\\right)\\) y denote el estimador de la varianza por \\(\\hat{v}_{ik}=\\widehat{Var}\\left(\\hat{p}_{ik}\\right)\\) Note que el efecto diseño cambia entre categoría, por tanto, lo primero será definir el tamaño de muestra efectivo por categoría. Esto es: La estimación de \\(\\tilde{n}\\) esta dado por \\(\\tilde{n}_{ik} = \\frac{(\\tilde{p}_{ik}\\times(1-\\tilde{p}_{ik}))}{\\hat{v}_{ik}},\\) \\(\\tilde{y}_{ik}=\\tilde{n}_{ik}\\times\\hat{p}_{ik}\\) luego, \\(\\hat{n}_{i} = \\sum_{k=1}^{K}\\tilde{y}_{ik}\\) de donde se sigue que \\(\\hat{y}_{ik} = \\hat{n}_i\\times \\hat{p}_{ik}\\) Sea \\(\\boldsymbol{\\theta}=\\left(p_{1},p_{2}, p_{3}\\right)^{T}=\\left(\\frac{N_{i1}}{N_{i}},\\frac{N_{i2}}{N_{i}}\\frac{N_{i3}}{N_{i}}\\right)^{T}\\), entonces el modelo multinomial para el i-ésimo dominio estaría dado por: \\[ \\left(\\tilde{y}_{i1},\\tilde{y}_{i2},\\tilde{y}_{i3}\\right)\\mid\\hat{n}_{i},\\boldsymbol{\\theta}_{i}\\sim multinomial\\left(\\hat{n}_{i},\\boldsymbol{\\theta}_{i}\\right) \\] Ahora, puede escribir \\(p_{ik}\\) como : \\(\\ln\\left(\\frac{p_{i2}}{p_{i1}}\\right)=\\boldsymbol{X}_{i}^{T}\\beta_{2} + u_{i2}\\) y \\(\\ln\\left(\\frac{p_{i3}}{p_{i1}}\\right)=\\boldsymbol{X}_{i}^{T}\\beta_{3}+ u_{i3}\\) Dada la restricción \\(1 = p_{i1} + p_{i2} + p_{i3}\\) entonces \\[p_{i1} + p_{i1}(e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2})+p_{i1}(e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta}_{3}} + u_{i3})\\] de donde se sigue que \\[ p_{i1}=\\frac{1}{1+e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2}+e^{\\boldsymbol{X_{i}}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i3}} \\] Las expresiones para \\(p_{i2}\\) y \\(p_{i3}\\) estarían dadas por: \\[ p_{i2}=\\frac{e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta}_{2}} + u_{i2}}{1+e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2}+e^{\\boldsymbol{X_{i}}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i3}} \\] \\[ p_{i3}=\\frac{e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta}_{3}}+ u_{i3}}{1+e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2}+e^{\\boldsymbol{X_{i}}^{T}\\boldsymbol{\\beta_{3}}}+ u_{i3}} \\] "],["lectura-de-librerías..html", "14.2 Lectura de librerías.", " 14.2 Lectura de librerías. La librería survey es una herramienta de análisis estadístico en R que permite trabajar con datos de encuestas complejas, como las encuestas estratificadas, multietápicas o con pesos de muestreo. Ofrece funciones para estimación de parámetros, diseño de muestras, análisis de varianza y regresión, y cálculo de errores estándar. La librería tidyverse es un conjunto de paquetes de R que se utilizan para la manipulación y visualización de datos. Incluye las librerías dplyr, ggplot2, tidyr y otras, y se caracteriza por su enfoque en la programación tidy o ordenada, que facilita la exploración y análisis de datos. La librería srvyr es una extensión de la librería survey que permite integrar las funciones de survey con la sintaxis de dplyr, lo que facilita la manipulación de datos de encuestas complejas. Incluye funciones para agrupar, filtrar y resumir datos de encuestas utilizando la sintaxis tidy. La librería TeachingSampling es una herramienta de R que se utiliza para la enseñanza de métodos de muestreo estadístico. Incluye funciones para simular diferentes tipos de muestras, estimar parámetros, calcular errores estándar y construir intervalos de confianza, entre otras. La librería haven es una herramienta de R que permite importar y exportar datos en diferentes formatos, incluyendo SPSS, Stata y SAS. Permite trabajar con archivos de datos de encuestas, y ofrece funciones para etiquetar variables, codificar datos faltantes y convertir datos de diferentes formatos. La librería bayesplot es una herramienta de R que se utiliza para la visualización y diagnóstico de modelos Bayesianos. Incluye funciones para graficar distribuciones posteriores, diagnósticos de convergencia, gráficos de diagnóstico de residuos, y otros tipos de gráficos relacionados con el análisis Bayesianos. La librería patchwork es una herramienta de R que permite unir gráficos de manera sencilla y flexible. Esta librería facilita la creación de gráficos complejos al permitir la combinación de múltiples gráficos en una sola visualización, lo que resulta especialmente útil en análisis de datos y modelización. La librería stringr es una herramienta de R que se utiliza para la manipulación de cadenas de texto. Incluye funciones para la extracción, manipulación y modificación de cadenas de texto, lo que resulta especialmente útil en la limpieza y preparación de datos antes de su análisis. La librería rstan es una herramienta de R que se utiliza para la estimación de modelos Bayesianos mediante el método de cadenas de Markov Monte Carlo (MCMC). Esta librería permite la especificación y estimación de modelos complejos mediante un lenguaje sencillo y flexible, y ofrece diversas herramientas para el diagnóstico y visualización de resultados. library(survey) library(tidyverse) library(srvyr) library(TeachingSampling) library(haven) library(bayesplot) library(patchwork) library(stringr) library(rstan) "],["lectura-de-la-encuesta-y-estimaciones-directas.html", "14.3 Lectura de la encuesta y estimaciones directas", " 14.3 Lectura de la encuesta y estimaciones directas En la primera línea se carga la encuesta desde un archivo RDS y se guarda en un objeto llamado encuesta. La segunda línea utiliza la función transmute() de la librería dplyr para seleccionar las variables de interés en la encuesta y crear nuevas variables a partir de ellas. Luego, se utiliza la variable id_dominio para identificar el dominio de estudio. En conjunto, estos pasos son fundamentales para preparar los datos de la encuesta para su posterior estimación del parámetro. encuesta &lt;- readRDS(&#39;Recursos/Día5/Sesion1/Data/encuestaDOM21N1.rds&#39;) region &lt;- readRDS(file = &quot;Recursos/Día5/Sesion1/Data/total_personas_dam2.rds&quot;) %&gt;% ungroup() %&gt;% select(region,dam2) ## encuesta &lt;- encuesta %&gt;% transmute( dam = haven::as_factor(dam_ee,levels = &quot;values&quot;), dam = str_pad(dam,width = 2,pad = &quot;0&quot;), dam2, fep = `_fep`, upm = `_upm`, estrato = `_estrato`, empleo = condact3 ) %&gt;% inner_join(region) El código presentado define el diseño muestral para el análisis de la encuesta “encuesta” en R. La primera línea establece una opción para el tratamiento de las PSU (unidades primarias de muestreo) solitarias, lo que indica que se deben aplicar ajustes en el cálculo de los errores estándar. La segunda línea utiliza la función “as_survey_design” de la librería “survey” para definir el diseño muestral. La función toma como argumentos la variable “encuesta” y los siguientes parámetros: strata: la variable que define las estratas de muestreo en la encuesta, en este caso la variable “estrato”. ids: la variable que identifica las PSU en la encuesta, en este caso la variable “upm”. weights: la variable que indica los pesos muestrales de cada observación, en este caso la variable “fep”. nest: un parámetro lógico que indica si los datos de la encuesta están anidados o no. En este caso, se establece en “TRUE” porque los datos están anidados por dominio. En conjunto, estos pasos permiten definir un diseño muestral que tenga en cuenta las características del muestreo y los pesos asignados a cada observación en la encuesta, lo que es necesario para obtener estimaciones precisas y representativas de los parámetros de interés. options(survey.lonely.psu= &#39;adjust&#39; ) diseno &lt;- encuesta %&gt;% as_survey_design( strata = estrato, ids = upm, weights = fep, nest=T ) El código presentado es una operación que se realiza en el diseño muestral definido en el código anterior, con el objetivo de obtener un indicador del empleo por dominio. La primera línea define un objeto llamado “indicador_dam”. En la segunda línea, se agrupa el diseño muestral según el dominio especificado en la variable “id_dominio”. La tercera línea filtra los datos para quedarse con los individuos que tienen empleo (empleo igual a 1), están desempleados (empleo igual a 2) o son inactivos (empleo igual a 3). A partir de la cuarta línea, se utilizan las funciones “summarise” y “survey_mean” para calcular las estadísticas descriptivas de interés. En particular, se calculan el número de personas ocupadas, desocupadas e inactivas en cada dominio, y la proporción de personas en cada una de estas categorías. La función “survey_mean” se utiliza para calcular la proporción de personas en cada una de estas categorías con sus respectivos errores estándar y efecto de diseño. indicador_dam &lt;- diseno %&gt;% group_by(dam2) %&gt;% filter(empleo %in% c(1:3)) %&gt;% summarise( n_ocupado = unweighted(sum(empleo == 1)), n_desocupado = unweighted(sum(empleo == 2)), n_inactivo = unweighted(sum(empleo == 3)), Ocupado = survey_mean(empleo == 1, vartype = c(&quot;se&quot;, &quot;var&quot;), deff = T ), Desocupado = survey_mean(empleo == 2, vartype = c(&quot;se&quot;, &quot;var&quot;), deff = T ), Inactivo = survey_mean(empleo == 3, vartype = c(&quot;se&quot;, &quot;var&quot;), deff = T ) ) "],["selección-de-dominios.html", "14.4 Selección de dominios", " 14.4 Selección de dominios En la sección anterior, se llevó a cabo una estimación directa para cada categoría individualmente en cada municipio (dominio) presente en la muestra. Ahora, para evaluar la calidad de los resultados obtenidos, realizaremos un análisis descriptivo. Se emplean varias medidas de calidad, entre ellas, se cuenta el número de dominios que tienen dos o más unidades primarias de muestreo (UPM), así como el efecto de diseño mayor a 1 y las varianzas mayores a 0. Estas medidas nos permitirán determinar la fiabilidad de nuestros resultados y tomar decisiones informadas en función de ellos. Después de realizar las validaciones anteriores se establece como regla incluir en el estudio los dominios que posean Dos o más upm por dominio. Contar con un resultado en el Deff n_upm &lt;- encuesta %&gt;% distinct(dam2, upm) %&gt;% group_by(dam2) %&gt;% tally(name = &quot;n_upm&quot;, sort = TRUE) indicador_dam &lt;- inner_join(n_upm, indicador_dam) indicador_dam1 &lt;- indicador_dam %&gt;% filter(n_upm &gt;= 2, !is.na(Desocupado_deff)) %&gt;% mutate(id_orden = 1:n()) saveRDS(object = indicador_dam1, &quot;Recursos/Día5/Sesion1/Data/base_modelo.Rds&quot;) dam2 n_upm n_ocupado n_desocupado n_inactivo Ocupado Ocupado_se Ocupado_var Ocupado_deff Desocupado Desocupado_se Desocupado_var Desocupado_deff Inactivo Inactivo_se Inactivo_var Inactivo_deff id_orden 00101 127 2953 284 2439 0.5210 0.0117 1e-04 3.1326 0.0503 0.0050 0e+00 2.9903 0.4287 0.0119 0.0001 3.3118 1 03201 109 2841 240 2524 0.5018 0.0128 2e-04 3.6801 0.0481 0.0045 0e+00 2.5120 0.4501 0.0122 0.0001 3.3802 2 02501 87 3059 121 2133 0.5719 0.0111 1e-04 2.7180 0.0226 0.0034 0e+00 2.8494 0.4055 0.0115 0.0001 2.9408 3 03203 59 1953 96 1629 0.5301 0.0121 1e-04 2.1909 0.0263 0.0027 0e+00 1.0520 0.4436 0.0124 0.0002 2.3024 4 03202 42 1050 51 883 0.5290 0.0131 2e-04 1.3768 0.0229 0.0054 0e+00 2.5923 0.4481 0.0137 0.0002 1.5230 5 01101 38 1203 114 713 0.6092 0.0227 5e-04 4.4247 0.0575 0.0075 1e-04 2.1246 0.3333 0.0227 0.0005 4.7511 6 03206 32 837 51 728 0.5022 0.0177 3e-04 2.0370 0.0315 0.0080 1e-04 3.3819 0.4663 0.0170 0.0003 1.8859 7 00901 20 744 83 530 0.5492 0.0194 4e-04 2.0806 0.0595 0.0113 1e-04 3.1142 0.3913 0.0208 0.0004 2.4841 8 01301 20 738 45 552 0.5359 0.0244 6e-04 3.2173 0.0351 0.0049 0e+00 0.9599 0.4290 0.0262 0.0007 3.7629 9 02101 20 505 52 460 0.4965 0.0258 7e-04 2.7259 0.0514 0.0116 1e-04 2.8329 0.4521 0.0332 0.0011 4.5559 10 "],["modelo-programando-en-stan.html", "14.5 Modelo programando en STAN", " 14.5 Modelo programando en STAN El código presenta la implementación de un modelo multinomial logístico de área de respuesta utilizando el lenguaje de programación STAN. En este modelo, se asume que la variable de respuesta en cada dominio sigue una distribución multinomial. Se asume que los parámetros que rigen la relación entre las variables predictoras y la variable de respuesta son diferentes en cada dominio y se modelan como efectos aleatorios. La sección de functions define una función auxiliar llamada pred_theta(), que se utiliza para predecir los valores de la variable de respuesta en los dominios no observados. La sección de data contiene las variables de entrada del modelo, incluyendo el número de dominios, el número de categorías de la variable de respuesta, las estimaciones directas de la variable de respuesta en cada dominio, las covariables observadas en cada dominio y las covariables correspondientes a los dominios no observados. La sección de parameters define los parámetros desconocidos del modelo, incluyendo la matriz de parámetros beta, que contiene los coeficientes que relacionan las covariables con la variable de respuesta en cada categoría. También se incluyen los desviaciones estándar de los efectos aleatorios. En la sección de transformed parameters se define el vector de parámetros theta, que contiene las probabilidades de pertenencia a cada categoría de la variable de respuesta en cada dominio. Se utilizan los efectos aleatorios para ajustar los valores de theta en cada dominio. En la sección de model se define la estructura del modelo y se incluyen las distribuciones a priori para los parámetros desconocidos. En particular, se utiliza una distribución normal para los coeficientes de la matriz beta. Finalmente, se calcula la función de verosimilitud de la distribución multinomial para las estimaciones directas de la variable de respuesta en cada dominio. La sección de generated quantities se utiliza para calcular las predicciones de la variable de respuesta en los dominios no observados utilizando la función auxiliar definida previamente. functions { matrix pred_theta(matrix Xp, int p, matrix beta){ int D1 = rows(Xp); real num1[D1, p]; real den1[D1]; matrix[D1,p] theta_p; for(d in 1:D1){ num1[d, 1] = 1; num1[d, 2] = exp(Xp[d, ] * beta[1, ]&#39; ) ; num1[d, 3] = exp(Xp[d, ] * beta[2, ]&#39; ) ; den1[d] = sum(num1[d, ]); } for(d in 1:D1){ for(i in 2:p){ theta_p[d, i] = num1[d, i]/den1[d]; } theta_p[d, 1] = 1/den1[d]; } return theta_p ; } } data { int&lt;lower=1&gt; D; // número de dominios int&lt;lower=1&gt; P; // categorías int&lt;lower=1&gt; K; // cantidad de regresores int y_tilde[D, P]; // matriz de datos matrix[D, K] X_obs; // matriz de covariables int&lt;lower=1&gt; D1; // número de dominios matrix[D1, K] X_pred; // matriz de covariables } parameters { matrix[P-1, K] beta;// matriz de parámetros real&lt;lower=0&gt; sigma2_u1; // random effects standard deviations real&lt;lower=0&gt; sigma2_u2; // random effects standard deviations vector[D] u1; vector[D] u2; // declare L_u to be the Choleski factor of a 2x2 correlation matrix } transformed parameters { simplex[P] theta[D];// vector de parámetros; real num[D, P]; real den[D]; real&lt;lower=0&gt; sigma_u1; // random effects standard deviations real&lt;lower=0&gt; sigma_u2; // random effects standard deviations sigma_u1 = sqrt(sigma2_u1); sigma_u2 = sqrt(sigma2_u2); for(d in 1:D){ num[d, 1] = 1; num[d, 2] = exp(X_obs[d, ] * beta[1, ]&#39; + u1[d]) ; num[d, 3] = exp(X_obs[d, ] * beta[2, ]&#39; + u2[d]) ; den[d] = sum(num[d, ]); } for(d in 1:D){ for(p in 2:P){ theta[d, p] = num[d, p]/den[d]; } theta[d, 1] = 1/den[d]; } } model { u1 ~ normal(0, sigma_u1); u2 ~ normal(0, sigma_u2); sigma2_u1 ~ inv_gamma(0.0001, 0.0001); sigma2_u2 ~ inv_gamma(0.0001, 0.0001); for(p in 2:P){ for(k in 1:K){ beta[p-1, k] ~ normal(0, 10000); } } for(d in 1:D){ target += multinomial_lpmf(y_tilde[d, ] | theta[d, ]); } } generated quantities { matrix[D1,P] theta_pred; theta_pred = pred_theta(X_pred, P, beta); } "],["preparando-insumos-para-stan.html", "14.6 Preparando insumos para STAN", " 14.6 Preparando insumos para STAN Lectura y adecuación de covariables statelevel_predictors_df &lt;- readRDS(&#39;Recursos/Día5/Sesion1/Data/statelevel_predictors_df_dam2.rds&#39;) ## Estandarizando las variables para controlar el efecto de la escala. statelevel_predictors_df %&lt;&gt;% mutate_at(vars(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x)as.numeric(scale(x))) head(statelevel_predictors_df,10) %&gt;% tba() dam2 modificacion_humana accesibilidad_hospitales accesibilidad_hosp_caminado cubrimiento_cultivo cubrimiento_urbano luces_nocturnas area1 sexo2 edad2 edad3 edad4 edad5 anoest2 anoest3 anoest4 anoest99 tiene_sanitario tiene_acueducto tiene_gas eliminar_basura tiene_internet piso_tierra material_paredes material_techo rezago_escolar alfabeta hacinamiento tasa_desocupacion id_municipio 00101 3.6127 -1.1835 -1.5653 -1.1560 7.2782 4.9650 1.0000 0.5224 0.2781 0.2117 0.1808 0.0725 0.2000 0.3680 0.2286 0.0193 0.0119 0.7946 0.0673 0.0810 0.6678 0.0033 0.0109 0.0111 0.3694 0.9247 0.1962 0.0066 100101 00201 -0.0553 0.4449 0.2100 0.0684 -0.0682 -0.1511 0.8904 0.4933 0.2726 0.1849 0.1520 0.0614 0.3149 0.3022 0.0775 0.0082 0.1005 0.7220 0.2261 0.1300 0.9276 0.0664 0.0812 0.0249 0.1501 0.7975 0.3014 0.0007 050201 00202 -0.3758 0.0000 0.1482 -0.2345 -0.2855 -0.4234 0.6799 0.4697 0.2804 0.1895 0.1430 0.0515 0.3757 0.2405 0.0148 0.0014 0.1322 0.9230 0.2693 0.2884 0.9759 0.0625 0.0986 0.0673 0.0278 0.7140 0.3454 0.0001 050202 00203 -0.9259 0.5732 -0.1402 -0.5511 -0.3822 -0.5612 0.5814 0.4601 0.2665 0.1733 0.1586 0.0713 0.3778 0.2463 0.0219 0.0052 0.2579 0.7602 0.4824 0.2589 0.9919 0.1937 0.2342 0.1238 0.0485 0.7104 0.2755 0.0001 050203 00204 -1.3166 1.1111 0.4438 -0.5027 -0.3835 -0.6042 0.5708 0.4663 0.2647 0.1683 0.1673 0.0757 0.3306 0.2402 0.0440 0.0049 0.1672 0.6375 0.5040 0.3837 0.9759 0.1403 0.1354 0.0176 0.0873 0.6737 0.2671 0.0002 050204 00205 -0.7474 2.1155 1.2271 -0.5838 -0.3345 -0.5909 0.6937 0.4633 0.2849 0.2107 0.1473 0.0583 0.2794 0.2821 0.0562 0.0067 0.3800 0.6596 0.5014 0.2852 0.9894 0.2309 0.2498 0.0459 0.1016 0.6751 0.4973 0.0001 050205 00206 0.5157 -0.1468 -0.1811 1.1894 -0.1191 -0.4022 0.9563 0.4557 0.2910 0.1814 0.1495 0.0626 0.3793 0.2815 0.0427 0.0052 0.1301 0.8817 0.2565 0.1495 0.9659 0.0629 0.0472 0.0337 0.0835 0.8027 0.2200 0.0001 050206 00207 1.7368 -0.7648 -0.4861 0.7170 -0.0609 0.0042 0.5201 0.4783 0.2898 0.1675 0.1464 0.0531 0.3552 0.2901 0.0328 0.0061 0.2434 0.5775 0.2758 0.0950 0.9911 0.0717 0.2004 0.1304 0.0714 0.7778 0.3936 0.0001 050207 00208 -0.5942 0.3212 -0.1697 -0.3627 -0.3044 -0.4750 0.6625 0.4334 0.2943 0.1875 0.1523 0.0654 0.3557 0.2486 0.0250 0.0054 0.1908 0.8251 0.4152 0.1450 0.9907 0.1458 0.1517 0.0852 0.0509 0.6897 0.3051 0.0001 050208 00209 -1.5280 3.0192 1.9428 -0.8078 -0.4046 -0.6423 0.6798 0.4311 0.2858 0.1687 0.1628 0.0701 0.3648 0.2645 0.0752 0.0061 0.1893 0.5760 0.4096 0.3557 0.9978 0.1097 0.0941 0.0292 0.1357 0.7680 0.2189 0.0001 050209 Seleccionar las variables del modelo y crear matriz de covariables. names_cov &lt;- c( &quot;dam2&quot;, &quot;tasa_desocupacion&quot;, &quot;hacinamiento&quot;, &quot;piso_tierra&quot;, &quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;modificacion_humana&quot; ) X_pred &lt;- anti_join(statelevel_predictors_df %&gt;% select(all_of(names_cov)), indicador_dam1 %&gt;% select(dam2)) En el bloque de código se identifican que dominios serán los predichos. X_pred %&gt;% select(dam2) %&gt;% saveRDS(file = &quot;Recursos/Día5/Sesion1/Data/dam_pred.rds&quot;) Creando la matriz de covariables para los dominios no observados (X_pred) y los observados (X_obs) ## Obteniendo la matrix X_pred %&lt;&gt;% data.frame() %&gt;% select(-dam2) %&gt;% as.matrix() ## Identificando los dominios para realizar estimación del modelo X_obs &lt;- inner_join(indicador_dam1 %&gt;% select(dam2, id_orden), statelevel_predictors_df %&gt;% select(all_of(names_cov))) %&gt;% arrange(id_orden) %&gt;% data.frame() %&gt;% select(-dam2, -id_orden) %&gt;% as.matrix() Calculando el n_efectivo y el \\(\\tilde{y}\\) D &lt;- nrow(indicador_dam1) P &lt;- 3 # Ocupado, desocupado, inactivo. Y_tilde &lt;- matrix(NA, D, P) n_tilde &lt;- matrix(NA, D, P) Y_hat &lt;- matrix(NA, D, P) # n efectivos ocupado n_tilde[,1] &lt;- (indicador_dam1$Ocupado*(1 - indicador_dam1$Ocupado))/indicador_dam1$Ocupado_var Y_tilde[,1] &lt;- n_tilde[,1]* indicador_dam1$Ocupado # n efectivos desocupado n_tilde[,2] &lt;- (indicador_dam1$Desocupado*(1 - indicador_dam1$Desocupado))/indicador_dam1$Desocupado_var Y_tilde[,2] &lt;- n_tilde[,2]* indicador_dam1$Desocupado # n efectivos Inactivo n_tilde[,3] &lt;- (indicador_dam1$Inactivo*(1 - indicador_dam1$Inactivo))/indicador_dam1$Inactivo_var Y_tilde[,3] &lt;- n_tilde[,3]* indicador_dam1$Inactivo Ahora, validamos la coherencia de los cálculos realizados ni_hat = rowSums(Y_tilde) Y_hat[,1] &lt;- ni_hat* indicador_dam1$Ocupado Y_hat[,2] &lt;- ni_hat* indicador_dam1$Desocupado Y_hat[,3] &lt;- ni_hat* indicador_dam1$Inactivo Y_hat &lt;- ceiling(Y_hat) hat_p &lt;- Y_hat/rowSums(Y_hat) par(mfrow = c(1,3)) plot(hat_p[,1],indicador_dam1$Ocupado) abline(a = 0,b=1,col = &quot;red&quot;) plot(hat_p[,2],indicador_dam1$Desocupado) abline(a = 0,b=1,col = &quot;red&quot;) plot(hat_p[,3],indicador_dam1$Inactivo) abline(a = 0,b=1,col = &quot;red&quot;) Compilando el modelo X1_obs &lt;- cbind(matrix(1,nrow = D,ncol = 1),X_obs) K = ncol(X1_obs) D1 &lt;- nrow(X_pred) X1_pred &lt;- cbind(matrix(1,nrow = D1,ncol = 1),X_pred) sample_data &lt;- list(D = D, P = P, K = K, y_tilde = Y_hat, X_obs = X1_obs, X_pred = X1_pred, D1 = D1) library(rstan) fit_mcmc2 &lt;- stan( file = &quot;Recursos/Día5/Sesion1/Data/modelosStan/00 Multinomial_simple_no_cor.stan&quot;, # Stan program data = sample_data, # named list of data verbose = TRUE, warmup = 1000, # number of warmup iterations per chain iter = 2000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) saveRDS(fit_mcmc2, &quot;Recursos/Día5/Sesion1/Data/fit_multinomial_no_cor.Rds&quot;) "],["validación-del-modelo.html", "14.7 Validación del modelo", " 14.7 Validación del modelo La validación de un modelo es esencial para evaluar su capacidad para predecir de manera precisa y confiable los resultados futuros. En el caso de un modelo de área con respuesta multinomial, la validación se enfoca en medir la precisión del modelo para predecir las diferentes categorías de respuesta. El objetivo principal de la validación es determinar si el modelo es capaz de generalizar bien a datos no vistos y proporcionar predicciones precisas. Esto implica comparar las predicciones del modelo con los datos observados y utilizar métricas de evaluación para medir el rendimiento del modelo. La validación del modelo es esencial para garantizar la calidad de las predicciones y la confiabilidad del modelo para su uso en aplicaciones futuras. infile &lt;- paste0(&quot;Recursos/Día5/Sesion1/Data/fit_multinomial_no_cor.Rds&quot;) fit &lt;- readRDS(infile) theta_dir &lt;- indicador_dam1 %&gt;% transmute(dam2, n = n_desocupado + n_ocupado + n_inactivo, Ocupado, Desocupado, Inactivo) color_scheme_set(&quot;brightblue&quot;) theme_set(theme_bw(base_size = 15)) y_pred_B &lt;- as.array(fit, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) theta_1&lt;- grep(pattern = &quot;1]&quot;,x = colnames(y_pred_B),value = TRUE) theta_2&lt;- grep(pattern = &quot;2]&quot;,x = colnames(y_pred_B),value = TRUE) theta_3&lt;- grep(pattern = &quot;3]&quot;,x = colnames(y_pred_B),value = TRUE) y_pred1 &lt;- y_pred_B[rowsrandom,theta_1 ] y_pred2 &lt;- y_pred_B[rowsrandom,theta_2 ] y_pred3 &lt;- y_pred_B[rowsrandom,theta_3 ] ppc_dens_overlay(y = as.numeric(theta_dir$Ocupado), y_pred1)/ ppc_dens_overlay(y = as.numeric(theta_dir$Desocupado), y_pred2)/ ppc_dens_overlay(y = as.numeric(theta_dir$Inactivo), y_pred3) "],["estimación-de-los-parámetros..html", "14.8 Estimación de los parámetros.", " 14.8 Estimación de los parámetros. El código crea dos matrices, theta_obs_ordenado y theta_pred_ordenado, que contienen las estimaciones medias de los parámetros del modelo de respuesta multinomial con covariables para los datos de observación y predicción, respectivamente. La función matrix() se utiliza para dar formato a los datos con una matriz nrow x ncol, y se asignan nombres de columna apropiados a la matriz resultante utilizando colnames(). Luego se convierten las matrices en marcos de datos (as.data.frame()) y se unen mediante full_join() para crear una única tabla que contenga todas las estimaciones de los parámetros para los datos de observación y predicción, junto con la información del indicador de área (theta_dir). El resultado final es un marco de datos llamado estimaciones_obs. dam_pred &lt;- readRDS(&quot;Recursos/Día5/Sesion1/Data/dam_pred.rds&quot;) P &lt;- 3 D &lt;- nrow(indicador_dam1) D1 &lt;- nrow(dam_pred) ## Estimación del modelo. theta_obs &lt;- summary(fit, pars = &quot;theta&quot;)$summary[, &quot;mean&quot;] theta_pred &lt;- summary(fit, pars = &quot;theta_pred&quot;)$summary[, &quot;mean&quot;] ## Ordenando la matrix de theta theta_obs_ordenado &lt;- matrix(theta_obs, nrow = D, ncol = P,byrow = TRUE) colnames(theta_obs_ordenado) &lt;- c(&quot;Ocupado_mod&quot;, &quot;Desocupado_mod&quot;, &quot;Inactivo_mod&quot;) theta_obs_ordenado%&lt;&gt;% as.data.frame() theta_obs_ordenado &lt;- cbind(dam2 = indicador_dam1$dam2, theta_obs_ordenado) theta_pred_ordenado &lt;- matrix(theta_pred, nrow = D1, ncol = P,byrow = TRUE) colnames(theta_pred_ordenado) &lt;- c(&quot;Ocupado_mod&quot;, &quot;Desocupado_mod&quot;, &quot;Inactivo_mod&quot;) theta_pred_ordenado%&lt;&gt;% as.data.frame() theta_pred_ordenado &lt;- cbind(dam2 = dam_pred$dam2, theta_pred_ordenado) "],["estimación-de-la-desviación-estárdar-y-el-coeficiente-de-valiación.html", "14.9 Estimación de la desviación estárdar y el coeficiente de valiación", " 14.9 Estimación de la desviación estárdar y el coeficiente de valiación Este bloque de código corresponde al cálculo de las desviaciones estándar (sd) y coeficientes de variación (cv) de los parámetros theta para los datos observados y predichos. En primer lugar, se utiliza la función summary() del paquete rstan para extraer los valores de sd de los parámetros theta observados y predichos, respectivamente, a partir del modelo (fit) que contiene la información de la estimación de los parámetros de la distribución Bayesiana. Luego, se organizan los valores de sd en una matriz ordenada por dam2 y se les asignan los nombres correspondientes. Con esta matriz, se calcula otra matriz que contiene los coeficientes de variación para los parámetros theta observados (theta_obs_ordenado_cv). De manera similar, se construyen matrices ordenadas por dam2 para los valores de sd y cv de los parámetros theta predichos (theta_pred_ordenado_sd y theta_pred_ordenado_cv, respectivamente). theta_obs_sd &lt;- summary(fit, pars = &quot;theta&quot;)$summary[, &quot;sd&quot;] theta_pred_sd &lt;- summary(fit, pars = &quot;theta_pred&quot;)$summary[, &quot;sd&quot;] theta_obs_ordenado_sd &lt;- matrix(theta_obs_sd, nrow = D, ncol = P,byrow = TRUE) colnames(theta_obs_ordenado_sd) &lt;- c(&quot;Ocupado_mod_sd&quot;, &quot;Desocupado_mod_sd&quot;, &quot;Inactivo_mod_sd&quot;) theta_obs_ordenado_sd%&lt;&gt;% as.data.frame() theta_obs_ordenado_sd &lt;- cbind(dam2 = indicador_dam1$dam2, theta_obs_ordenado_sd) theta_obs_ordenado_cv &lt;- theta_obs_ordenado_sd[,-1]/theta_obs_ordenado[,-1] colnames(theta_obs_ordenado_cv) &lt;- c(&quot;Ocupado_mod_cv&quot;, &quot;Desocupado_mod_cv&quot;, &quot;Inactivo_mod_cv&quot;) theta_obs_ordenado_cv &lt;- cbind(dam2 = indicador_dam1$dam2, theta_obs_ordenado_cv) theta_pred_ordenado_sd &lt;- matrix(theta_pred_sd, nrow = D1, ncol = P,byrow = TRUE) colnames(theta_pred_ordenado_sd) &lt;- c(&quot;Ocupado_mod_sd&quot;, &quot;Desocupado_mod_sd&quot;, &quot;Inactivo_mod_sd&quot;) theta_pred_ordenado_sd%&lt;&gt;% as.data.frame() theta_pred_ordenado_sd &lt;- cbind(dam2 = dam_pred$dam2, theta_pred_ordenado_sd) theta_pred_ordenado_cv &lt;- theta_pred_ordenado_sd[,-1]/theta_pred_ordenado[,-1] colnames(theta_pred_ordenado_cv) &lt;- c(&quot;Ocupado_mod_cv&quot;, &quot;Desocupado_mod_cv&quot;, &quot;Inactivo_mod_cv&quot;) theta_pred_ordenado_cv &lt;- cbind(dam2 = dam_pred$dam2, theta_pred_ordenado_cv) El último paso es realizar la consolidación de la bases obtenidas para la estimación puntual, desviación estándar y coeficiente de variación. theta_obs_ordenado &lt;- full_join(theta_obs_ordenado,theta_obs_ordenado_sd) %&gt;% full_join(theta_obs_ordenado_cv) theta_pred_ordenado &lt;- full_join(theta_pred_ordenado,theta_pred_ordenado_sd) %&gt;% full_join(theta_pred_ordenado_cv) estimaciones &lt;- full_join(indicador_dam1, bind_rows(theta_obs_ordenado, theta_pred_ordenado)) saveRDS(object = estimaciones, file = &quot;Recursos/Día5/Sesion1/Data/estimaciones.rds&quot;) tba(head(estimaciones,10)) dam2 n_upm n_ocupado n_desocupado n_inactivo Ocupado Ocupado_se Ocupado_var Ocupado_deff Desocupado Desocupado_se Desocupado_var Desocupado_deff Inactivo Inactivo_se Inactivo_var Inactivo_deff id_orden Ocupado_mod Desocupado_mod Inactivo_mod Ocupado_mod_sd Desocupado_mod_sd Inactivo_mod_sd Ocupado_mod_cv Desocupado_mod_cv Inactivo_mod_cv 00101 127 2953 284 2439 0.5210 0.0117 1e-04 3.1326 0.0503 0.0050 0e+00 2.9903 0.4287 0.0119 0.0001 3.3118 1 0.5217 0.0496 0.4287 0.0115 0.0051 0.0114 0.0221 0.1019 0.0266 03201 109 2841 240 2524 0.5018 0.0128 2e-04 3.6801 0.0481 0.0045 0e+00 2.5120 0.4501 0.0122 0.0001 3.3802 2 0.5035 0.0477 0.4488 0.0122 0.0052 0.0121 0.0243 0.1095 0.0269 02501 87 3059 121 2133 0.5719 0.0111 1e-04 2.7180 0.0226 0.0034 0e+00 2.8494 0.4055 0.0115 0.0001 2.9408 3 0.5703 0.0240 0.4057 0.0108 0.0034 0.0106 0.0190 0.1413 0.0262 03203 59 1953 96 1629 0.5301 0.0121 1e-04 2.1909 0.0263 0.0027 0e+00 1.0520 0.4436 0.0124 0.0002 2.3024 4 0.5300 0.0271 0.4428 0.0118 0.0038 0.0118 0.0222 0.1401 0.0266 03202 42 1050 51 883 0.5290 0.0131 2e-04 1.3768 0.0229 0.0054 0e+00 2.5923 0.4481 0.0137 0.0002 1.5230 5 0.5267 0.0241 0.4493 0.0133 0.0041 0.0132 0.0252 0.1693 0.0294 01101 38 1203 114 713 0.6092 0.0227 5e-04 4.4247 0.0575 0.0075 1e-04 2.1246 0.3333 0.0227 0.0005 4.7511 6 0.5973 0.0605 0.3422 0.0209 0.0102 0.0203 0.0349 0.1681 0.0594 03206 32 837 51 728 0.5022 0.0177 3e-04 2.0370 0.0315 0.0080 1e-04 3.3819 0.4663 0.0170 0.0003 1.8859 7 0.5007 0.0319 0.4674 0.0170 0.0060 0.0169 0.0339 0.1879 0.0361 00901 20 744 83 530 0.5492 0.0194 4e-04 2.0806 0.0595 0.0113 1e-04 3.1142 0.3913 0.0208 0.0004 2.4841 8 0.5487 0.0578 0.3935 0.0192 0.0090 0.0192 0.0349 0.1552 0.0487 01301 20 738 45 552 0.5359 0.0244 6e-04 3.2173 0.0351 0.0049 0e+00 0.9599 0.4290 0.0262 0.0007 3.7629 9 0.5356 0.0363 0.4281 0.0226 0.0082 0.0228 0.0423 0.2257 0.0532 02101 20 505 52 460 0.4965 0.0258 7e-04 2.7259 0.0514 0.0116 1e-04 2.8329 0.4521 0.0332 0.0011 4.5559 10 0.4993 0.0491 0.4516 0.0261 0.0114 0.0263 0.0523 0.2313 0.0582 "],["metodología-de-benchmarking.html", "14.10 Metodología de Benchmarking", " 14.10 Metodología de Benchmarking Conteos de personas agregados por dam2, personas mayores de 15 años de edad. conteo_pp_dam &lt;- readRDS(&quot;Recursos/Día5/Sesion1/Data/censo_mrp_dam2.rds&quot;) %&gt;% filter(edad &gt; 1) %&gt;% group_by(dam , dam2) %&gt;% summarise(pp_dam2 = sum(n),.groups = &quot;drop&quot;) conteo_pp_dam &lt;- inner_join(conteo_pp_dam,region) %&gt;% group_by(region) %&gt;% mutate(pp_region = sum(pp_dam2)) head(conteo_pp_dam) %&gt;% tba() dam dam2 pp_dam2 region pp_region 01 00101 717099 10 2366172 02 00201 61287 05 697131 02 00202 7470 05 697131 02 00203 11799 05 697131 02 00204 13547 05 697131 02 00205 10697 05 697131 Estimación del parámetro theta al nivel que la encuesta sea representativa. indicador_agregado &lt;- diseno %&gt;% group_by(region) %&gt;% filter(empleo %in% c(1:3)) %&gt;% summarise( Ocupado = survey_ratio(numerator = (empleo == 1), denominator = 1 ), Desocupado = survey_ratio(numerator =( empleo == 2),denominator = 1 ), Inactivo = survey_ratio(numerator = (empleo == 3), denominator = 1 ) ) %&gt;% select(region,Ocupado,Desocupado, Inactivo) tba(indicador_agregado) region Ocupado Desocupado Inactivo 01 0.5537 0.0236 0.4227 02 0.5492 0.0349 0.4159 03 0.5236 0.0855 0.3909 04 0.5136 0.0337 0.4526 05 0.4623 0.0423 0.4954 06 0.4999 0.0298 0.4703 07 0.5295 0.0174 0.4532 08 0.5639 0.0678 0.3683 09 0.5257 0.0505 0.4238 10 0.5144 0.0402 0.4453 Organizando la salida como un vector. temp &lt;- gather(indicador_agregado, key = &quot;agregado&quot;, value = &quot;estimacion&quot;, -region) %&gt;% mutate(nombre = paste0(&quot;region_&quot;, region,&quot;_&quot;, agregado)) Razon_empleo &lt;- setNames(temp$estimacion, temp$nombre) Definir los pesos por dominios. names_cov &lt;- &quot;region&quot; estimaciones_mod &lt;- estimaciones %&gt;% transmute( region, dam2,Ocupado_mod,Desocupado_mod,Inactivo_mod) %&gt;% inner_join(conteo_pp_dam ) %&gt;% mutate(wi = pp_dam2/pp_region) Crear variables dummys estimaciones_mod %&lt;&gt;% fastDummies::dummy_cols(select_columns = names_cov, remove_selected_columns = FALSE) Xdummy &lt;- estimaciones_mod %&gt;% select(matches(&quot;region_&quot;)) %&gt;% mutate_at(vars(matches(&quot;_\\\\d&quot;)) , list(Ocupado = function(x) x*estimaciones_mod$Ocupado_mod, Desocupado = function(x) x*estimaciones_mod$Desocupado_mod, Inactivo = function(x) x*estimaciones_mod$Inactivo_mod)) %&gt;% select((matches(&quot;Ocupado|Desocupado|Inactivo&quot;))) head(Xdummy) %&gt;% tba() region_01_Ocupado region_02_Ocupado region_03_Ocupado region_04_Ocupado region_05_Ocupado region_06_Ocupado region_07_Ocupado region_08_Ocupado region_09_Ocupado region_10_Ocupado region_01_Desocupado region_02_Desocupado region_03_Desocupado region_04_Desocupado region_05_Desocupado region_06_Desocupado region_07_Desocupado region_08_Desocupado region_09_Desocupado region_10_Desocupado region_01_Inactivo region_02_Inactivo region_03_Inactivo region_04_Inactivo region_05_Inactivo region_06_Inactivo region_07_Inactivo region_08_Inactivo region_09_Inactivo region_10_Inactivo 0.5217 0 0 0 0 0 0 0 0 0 0.0496 0 0 0 0 0 0 0 0 0 0.4287 0 0 0 0 0 0 0 0 0 0.5035 0 0 0 0 0 0 0 0 0 0.0477 0 0 0 0 0 0 0 0 0 0.4488 0 0 0 0 0 0 0 0 0 0.5703 0 0 0 0 0 0 0 0 0 0.0240 0 0 0 0 0 0 0 0 0 0.4057 0 0 0 0 0 0 0 0 0 0.5300 0 0 0 0 0 0 0 0 0 0.0271 0 0 0 0 0 0 0 0 0 0.4428 0 0 0 0 0 0 0 0 0 0.5267 0 0 0 0 0 0 0 0 0 0.0241 0 0 0 0 0 0 0 0 0 0.4493 0 0 0 0 0 0 0 0 0 0.5973 0 0 0 0 0 0 0 0 0 0.0605 0 0 0 0 0 0 0 0 0 0.3422 0 0 0 0 0 0 0 0 0 Calcular el ponderador para cada nivel de la variable. Ocupado library(sampling) names_ocupado &lt;- grep(pattern = &quot;_O&quot;, x = colnames(Xdummy),value = TRUE) gk_ocupado &lt;- calib(Xs = Xdummy[,names_ocupado] %&gt;% as.matrix(), d = estimaciones_mod$wi, total = Razon_empleo[names_ocupado] %&gt;% as.matrix(), method=&quot;linear&quot;,max_iter = 5000) checkcalibration(Xs = Xdummy[,names_ocupado] %&gt;% as.matrix(), d =estimaciones_mod$wi, total = Razon_empleo[names_ocupado] %&gt;% as.matrix(), g = gk_ocupado,) Desocupado names_descupados &lt;- grep(pattern = &quot;_D&quot;, x = colnames(Xdummy),value = TRUE) gk_desocupado &lt;- calib(Xs = Xdummy[,names_descupados]%&gt;% as.matrix(), d = estimaciones_mod$wi, total = Razon_empleo[names_descupados]%&gt;% as.matrix(), method=&quot;linear&quot;,max_iter = 5000) checkcalibration(Xs = Xdummy[,names_descupados]%&gt;% as.matrix(), d =estimaciones_mod$wi, total = Razon_empleo[names_descupados]%&gt;% as.matrix(), g = gk_desocupado,) Inactivo names_inactivo &lt;- grep(pattern = &quot;_I&quot;, x = colnames(Xdummy),value = TRUE) gk_Inactivo &lt;- calib(Xs = Xdummy[,names_inactivo]%&gt;% as.matrix(), d = estimaciones_mod$wi, total = Razon_empleo[names_inactivo]%&gt;% as.matrix(), method=&quot;linear&quot;,max_iter = 5000) checkcalibration(Xs = Xdummy[,names_inactivo]%&gt;% as.matrix(), d =estimaciones_mod$wi, total = Razon_empleo[names_inactivo]%&gt;% as.matrix(), g = gk_Inactivo,) Validar los resultados obtenidos. par(mfrow = c(1,3)) hist(gk_ocupado) hist(gk_desocupado) hist(gk_Inactivo) Estimaciones ajustadas por el ponderador estimacionesBench &lt;- estimaciones_mod %&gt;% mutate(gk_ocupado, gk_desocupado, gk_Inactivo) %&gt;% transmute( region, dam, dam2, wi,gk_ocupado, gk_desocupado, gk_Inactivo, Ocupado_Bench = Ocupado_mod*gk_ocupado, Desocupado_Bench = Desocupado_mod*gk_desocupado, Inactivo_Bench = Inactivo_mod*gk_Inactivo ) Validación de resultados. estimacionesBench %&gt;% group_by(region) %&gt;% summarise(Ocupado_Bench = sum(wi*Ocupado_Bench), Desocupado_Bench = sum(wi*Desocupado_Bench), Inactivo_Bench = sum(wi*Inactivo_Bench)) %&gt;% inner_join(indicador_agregado) %&gt;% tba() region Ocupado_Bench Desocupado_Bench Inactivo_Bench Ocupado Desocupado Inactivo 01 0.5537 0.0236 0.4227 0.5537 0.0236 0.4227 02 0.5492 0.0349 0.4159 0.5492 0.0349 0.4159 03 0.5236 0.0855 0.3909 0.5236 0.0855 0.3909 04 0.5136 0.0337 0.4526 0.5136 0.0337 0.4526 05 0.4623 0.0423 0.4954 0.4623 0.0423 0.4954 06 0.4999 0.0298 0.4703 0.4999 0.0298 0.4703 07 0.5295 0.0174 0.4532 0.5295 0.0174 0.4532 08 0.5639 0.0678 0.3683 0.5639 0.0678 0.3683 09 0.5257 0.0505 0.4238 0.5257 0.0505 0.4238 10 0.5144 0.0402 0.4453 0.5144 0.0402 0.4453 Guardar resultados estimaciones &lt;- inner_join(estimaciones,estimacionesBench) saveRDS(object = estimaciones, file = &quot;Recursos/Día5/Sesion1/Data/estimaciones_Bench.rds&quot;) "],["mapas-del-mercado-de-trabajo..html", "14.11 Mapas del mercado de trabajo.", " 14.11 Mapas del mercado de trabajo. El código carga las librerías sp, sf y tmap. Luego, se lee un archivo shapefile con información geográfica y se utiliza la función ‘inner_join’ para unirlo con las estimaciones de la encuesta previamente calculadas. Posteriormente, se definen los puntos de corte para la generación de los intervalos de clase en los mapas de cada variable de interés (ocupados, desocupados e inactivos) y se asignan a las variables ‘brks_ocupado’, ‘brks_desocupado’ y ‘brks_inactivo’, respectivamente. library(sp) library(sf) library(tmap) ShapeSAE &lt;- read_sf(&quot;Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) P1_empleo &lt;- tm_shape(ShapeSAE %&gt;% inner_join(estimaciones)) brks_ocupado &lt;- seq(0.2,0.8,0.1) brks_desocupado &lt;- seq(0,0.3,0.05) brks_inactivo &lt;- seq(0.15,0.65, 0.1) Ocupado Este código está creando un mapa de la variable “Ocupado” utilizando la función tm_fill() de la librería tmap. Los valores de la variable se clasifican en diferentes categorías utilizando la función breaks, y se establece un título para la leyenda del mapa con el argumento title. Se utiliza una paleta de colores llamada “-Blues” para representar las diferentes categorías de la variable en el mapa. La función tm_layout se utiliza para establecer algunas características del diseño del mapa, como el tamaño de la leyenda, el tamaño de la fuente, y la relación de aspecto del mapa. Finalmente, el mapa se guarda en la variable Mapa_ocupado. Mapa_ocupado &lt;- P1_empleo + tm_fill(&quot;Ocupado_Bench&quot;, breaks = brks_ocupado, title = &quot;Ocupado&quot;, palette = &quot;-Blues&quot;) + tm_layout( legend.only = FALSE, legend.height = -0.95, legend.width = -0.95, asp = 2.1, legend.text.size = 3, legend.title.size = 3 ) Mapa_ocupado Desocupado Este código utiliza la función tm_fill() de la librería tmap para crear un mapa temático del indicador de “desocupado” a nivel de las áreas geográficas definidas en el archivo de polígonos ShapeSAE. La paleta de colores utilizada para representar los valores del indicador es la “YlOrRd”. Se especifican los mismos parámetros de tm_layout() que en el mapa anterior para definir el diseño general del mapa. Mapa_desocupado &lt;- P1_empleo + tm_fill( &quot;Desocupado_Bench&quot;, breaks = brks_desocupado, title = &quot;Desocupado&quot;, palette = &quot;YlOrRd&quot; ) + tm_layout( legend.only = FALSE, legend.height = -0.95, legend.width = -0.95, asp = 2.1, legend.text.size = 3, legend.title.size = 3 ) Mapa_desocupado Inactivo Este código genera un mapa temático de la variable “Inactivo” utilizando la librería tmap. Primero se carga el archivo de shapefile y se hace una unión con las estimaciones previamente calculadas. Luego se utiliza la función tm_fill() para especificar que se desea utilizar el valor de la variable “Inactivo” para el relleno del mapa. Se definen los intervalos de la paleta de colores con la variable “brks_inactivo” y se especifica el título del mapa con la opción “title”. Finalmente, se configura el diseño del mapa con la función tm_layout(), donde se ajustan parámetros como el tamaño del texto y de la leyenda, y se establece el aspecto del mapa en 1.5 para una mejor visualización. Mapa_Inactivo &lt;- P1_empleo + tm_fill( &quot;Inactivo_Bench&quot;, title = &quot;Inactivo&quot;, breaks = brks_inactivo, palette = &quot;YlGn&quot; ) + tm_layout( legend.only = FALSE, legend.height = -0.95, legend.width = -0.95, asp = 2.1, legend.text.size = 3, legend.title.size = 3 ) Mapa_Inactivo "],["día-5---sesión-2---definición-del-modelo-multinomial-de-efectos-aleatorios-correlacionados..html", "Capítulo 15 Día 5 - Sesión 2 - Definición del modelo multinomial de efectos aleatorios correlacionados.", " Capítulo 15 Día 5 - Sesión 2 - Definición del modelo multinomial de efectos aleatorios correlacionados. La Estimación del modelo de área de respuesta multinomial es una técnica estadística utilizada para analizar datos provenientes de encuestas que involucran múltiples categorías de respuesta y están diseñadas a nivel de áreas geográficas. Esta técnica es una extensión del modelo de área de respuesta binomial, el cual se utiliza para analizar encuestas con dos posibles respuestas. El Modelo multinomial logístico es un tipo de modelo de regresión utilizado para analizar datos de respuesta categóricos que tienen más de dos categorías. Este modelo es una extensión del modelo de regresión logística binaria, el cual se utiliza para analizar datos de respuesta binaria. Recordemos las expresiones del modelo múltinomial. Sea \\(\\boldsymbol{\\theta}=\\left(p_{1},p_{2}, p_{3}\\right)^{T}=\\left(\\frac{N_{i1}}{N_{i}},\\frac{N_{i2}}{N_{i}}\\frac{N_{i3}}{N_{i}}\\right)^{T}\\), entonces el modelo multinomial para el i-ésimo dominio estaría dado por: \\[ \\left(\\tilde{y}_{i1},\\tilde{y}_{i2},\\tilde{y}_{i3}\\right)\\mid\\hat{n}_{i},\\boldsymbol{\\theta}_{i}\\sim multinomial\\left(\\hat{n}_{i},\\boldsymbol{\\theta}_{i}\\right) \\] Ahora, puede escribir \\(p_{ik}\\) como : \\(\\ln\\left(\\frac{p_{i2}}{p_{i1}}\\right)=\\boldsymbol{X}_{i}^{T}\\beta_{2} + u_{i2}\\) y \\(\\ln\\left(\\frac{p_{i3}}{p_{i1}}\\right)=\\boldsymbol{X}_{i}^{T}\\beta_{3}+ u_{i3}\\) Dada la restricción \\(1 = p_{i1} + p_{i2} + p_{i3}\\) entonces \\[p_{i1} + p_{i1}(e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2})+p_{i1}(e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta}_{3}} + u_{i3})\\] de donde se sigue que \\[ p_{i1}=\\frac{1}{1+e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2}+e^{\\boldsymbol{X_{i}}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i3}} \\] Las expresiones para \\(p_{i2}\\) y \\(p_{i3}\\) estarían dadas por: \\[ p_{i2}=\\frac{e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta}_{2}} + u_{i2}}{1+e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2}+e^{\\boldsymbol{X_{i}}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i3}} \\] \\[ p_{i3}=\\frac{e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta}_{3}}+ u_{i3}}{1+e^{\\boldsymbol{X}_{i}^{T}\\boldsymbol{\\beta_{2}}}+ u_{i2}+e^{\\boldsymbol{X_{i}}^{T}\\boldsymbol{\\beta_{3}}}+ u_{i3}} \\] dado la naturaleza de la variable, se puede suponer que \\(cor(u_{i2},u_{i3})\\ne 0\\) "],["lectura-de-las-estimaciones-directas.html", "15.1 Lectura de las estimaciones directas", " 15.1 Lectura de las estimaciones directas En la sección anterior se realizó el cálculo de estimaciones directas para los distintos dominio y se aplicaron criterios de selección para conservar aquellos dominios que contaran con suficientes observaciones y una varianza estimada adecuada. Tras este proceso de selección, se obtuvieron un total de 413 dominios. Es importante destacar que la elección de estos criterios es fundamental para asegurar la calidad de las estimaciones obtenidas. A continuación, presentamos una lista con los 10 primeros dominios seleccionados. indicador_dam1 &lt;- readRDS(&quot;Recursos/Día5/Sesion2/Data/base_modelo.Rds&quot;) tba(head(indicador_dam1,10)) dam2 n_upm n_ocupado n_desocupado n_inactivo Ocupado Ocupado_se Ocupado_var Ocupado_deff Desocupado Desocupado_se Desocupado_var Desocupado_deff Inactivo Inactivo_se Inactivo_var Inactivo_deff id_orden 00101 127 2953 284 2439 0.5210 0.0117 1e-04 3.1326 0.0503 0.0050 0e+00 2.9903 0.4287 0.0119 0.0001 3.3118 1 03201 109 2841 240 2524 0.5018 0.0128 2e-04 3.6801 0.0481 0.0045 0e+00 2.5120 0.4501 0.0122 0.0001 3.3802 2 02501 87 3059 121 2133 0.5719 0.0111 1e-04 2.7180 0.0226 0.0034 0e+00 2.8494 0.4055 0.0115 0.0001 2.9408 3 03203 59 1953 96 1629 0.5301 0.0121 1e-04 2.1909 0.0263 0.0027 0e+00 1.0520 0.4436 0.0124 0.0002 2.3024 4 03202 42 1050 51 883 0.5290 0.0131 2e-04 1.3768 0.0229 0.0054 0e+00 2.5923 0.4481 0.0137 0.0002 1.5230 5 01101 38 1203 114 713 0.6092 0.0227 5e-04 4.4247 0.0575 0.0075 1e-04 2.1246 0.3333 0.0227 0.0005 4.7511 6 03206 32 837 51 728 0.5022 0.0177 3e-04 2.0370 0.0315 0.0080 1e-04 3.3819 0.4663 0.0170 0.0003 1.8859 7 00901 20 744 83 530 0.5492 0.0194 4e-04 2.0806 0.0595 0.0113 1e-04 3.1142 0.3913 0.0208 0.0004 2.4841 8 01301 20 738 45 552 0.5359 0.0244 6e-04 3.2173 0.0351 0.0049 0e+00 0.9599 0.4290 0.0262 0.0007 3.7629 9 02101 20 505 52 460 0.4965 0.0258 7e-04 2.7259 0.0514 0.0116 1e-04 2.8329 0.4521 0.0332 0.0011 4.5559 10 "],["modelo-programando-en-stan-1.html", "15.2 Modelo programando en STAN", " 15.2 Modelo programando en STAN El código se divide en varios bloques: El primer bloque especifica las funciones que se utilizarán en el modelo. En este caso, solo hay una función llamada pred_theta, que toma una matriz de covariables, un número de categorías y una matriz de parámetros beta y devuelve una matriz de parámetros theta. El segundo bloque define los datos de entrada que se utilizarán en el modelo. Se especifica el número de dominios, categorías y regresores, y se proporcionan las matrices de datos observados y covariables observadas. El tercer bloque especifica los parámetros del modelo. En este caso, se incluyen la matriz de parámetros beta, las desviaciones estándar de los efectos aleatorios, la matriz de correlación de los efectos aleatorios y la matriz de efectos aleatorios. El cuarto bloque transforma los parámetros para asegurar que los efectos aleatorios tengan la matriz de correlación deseada y calcula los parámetros theta. El quinto bloque define el modelo. En este caso, se incluye una distribución previa para los parámetros beta, las desviaciones estándar y la matriz de correlación, así como la verosimilitud de la distribución multinomial para los datos observados. El sexto bloque genera las cantidades posteriores a partir de los parámetros estimados. En este caso, se incluye la matriz de parámetros theta para los datos de predicción y la matriz de correlación de los efectos aleatorios. functions { matrix pred_theta(matrix Xp, int p, matrix beta){ int D1 = rows(Xp); real num1[D1, p]; real den1[D1]; matrix[D1,p] theta_p; for(d in 1:D1){ num1[d, 1] = 1; num1[d, 2] = exp(Xp[d, ] * beta[1, ]&#39; ) ; num1[d, 3] = exp(Xp[d, ] * beta[2, ]&#39; ) ; den1[d] = sum(num1[d, ]); } for(d in 1:D1){ for(i in 2:p){ theta_p[d, i] = num1[d, i]/den1[d]; } theta_p[d, 1] = 1/den1[d]; } return theta_p ; } } data { int&lt;lower=1&gt; D; // número de dominios int&lt;lower=1&gt; P; // categorías int&lt;lower=1&gt; K; // cantidad de regresores int hat_y[D, P]; // matriz de datos matrix[D, K] X_obs; // matriz de covariables int&lt;lower=1&gt; D1; // número de dominios matrix[D1, K] X_pred; // matriz de covariables } parameters { matrix[P-1, K] beta;// matriz de parámetros vector&lt;lower=0&gt;[P-1] sigma_u; // random effects standard deviations // declare L_u to be the Choleski factor of a 2x2 correlation matrix cholesky_factor_corr[P-1] L_u; matrix[P-1, D] z_u; } transformed parameters { simplex[P] theta[D];// vector de parámetros; real num[D, P]; real den[D]; // this transform random effects so that they have the correlation // matrix specified by the correlation matrix above matrix[P-1, D] u; // random effect matrix u = diag_pre_multiply(sigma_u, L_u) * z_u; for(d in 1:D){ num[d, 1] = 1; num[d, 2] = exp(X_obs[d, ] * beta[1, ]&#39; + u[1, d]) ; num[d, 3] = exp(X_obs[d, ] * beta[2, ]&#39; + u[2, d]) ; den[d] = sum(num[d, ]); } for(d in 1:D){ for(p in 2:P){ theta[d, p] = num[d, p]/den[d]; } theta[d, 1] = 1/den[d]; } } model { L_u ~ lkj_corr_cholesky(1); // LKJ prior for the correlation matrix to_vector(z_u) ~ normal(0, 10000); sigma_u ~ inv_gamma(0.0001, 0.0001); for(p in 2:P){ for(k in 1:K){ beta[p-1, k] ~ normal(0, 10000); } } for(d in 1:D){ target += multinomial_lpmf(hat_y[d, ] | theta[d, ]); } } generated quantities { matrix[D1,P] theta_pred; matrix[2, 2] Omega; Omega = L_u * L_u&#39;; // so that it return the correlation matrix theta_pred = pred_theta(X_pred, P, beta); } "],["preparando-insumos-para-stan-1.html", "15.3 Preparando insumos para STAN", " 15.3 Preparando insumos para STAN Lectura y adecuación de covariables statelevel_predictors_df &lt;- readRDS(&#39;Recursos/Día5/Sesion2/Data/statelevel_predictors_df_dam2.rds&#39;) ## Estandarizando las variables para controlar el efecto de la escala. statelevel_predictors_df %&lt;&gt;% mutate_at(vars(&quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;cubrimiento_urbano&quot;, &quot;modificacion_humana&quot;, &quot;accesibilidad_hospitales&quot;, &quot;accesibilidad_hosp_caminado&quot;), function(x)as.numeric(scale(x))) Seleccionar las variables del modelo y crear matriz de covariables. names_cov &lt;- c( &quot;dam2&quot;, &quot;tasa_desocupacion&quot;, &quot;hacinamiento&quot;, &quot;piso_tierra&quot;, &quot;luces_nocturnas&quot;, &quot;cubrimiento_cultivo&quot;, &quot;modificacion_humana&quot; ) X_pred &lt;- anti_join(statelevel_predictors_df %&gt;% select(all_of(names_cov)), indicador_dam1 %&gt;% select(dam2)) En el bloque de código se identifican que dominios serán los predichos. X_pred %&gt;% select(dam2) %&gt;% saveRDS(file = &quot;Recursos/Día5/Sesion2/Data/dam_pred.rds&quot;) Creando la matriz de covariables para los dominios no observados (X_pred) y los observados (X_obs) ## Obteniendo la matrix X_pred %&lt;&gt;% data.frame() %&gt;% select(-dam2) %&gt;% as.matrix() ## Identificando los dominios para realizar estimación del modelo X_obs &lt;- inner_join(indicador_dam1 %&gt;% select(dam2, id_orden), statelevel_predictors_df %&gt;% select(all_of(names_cov))) %&gt;% arrange(id_orden) %&gt;% data.frame() %&gt;% select(-dam2, -id_orden) %&gt;% as.matrix() Calculando el n_efectivo y el \\(\\tilde{y}\\) D &lt;- nrow(indicador_dam1) P &lt;- 3 # Ocupado, desocupado, inactivo. Y_tilde &lt;- matrix(NA, D, P) n_tilde &lt;- matrix(NA, D, P) Y_hat &lt;- matrix(NA, D, P) # n efectivos ocupado n_tilde[,1] &lt;- (indicador_dam1$Ocupado*(1 - indicador_dam1$Ocupado))/indicador_dam1$Ocupado_var Y_tilde[,1] &lt;- n_tilde[,1]* indicador_dam1$Ocupado # n efectivos desocupado n_tilde[,2] &lt;- (indicador_dam1$Desocupado*(1 - indicador_dam1$Desocupado))/indicador_dam1$Desocupado_var Y_tilde[,2] &lt;- n_tilde[,2]* indicador_dam1$Desocupado # n efectivos Inactivo n_tilde[,3] &lt;- (indicador_dam1$Inactivo*(1 - indicador_dam1$Inactivo))/indicador_dam1$Inactivo_var Y_tilde[,3] &lt;- n_tilde[,3]* indicador_dam1$Inactivo Compilando el modelo ni_hat = rowSums(Y_tilde) Y_hat[,1] &lt;- ni_hat* indicador_dam1$Ocupado Y_hat[,2] &lt;- ni_hat* indicador_dam1$Desocupado Y_hat[,3] &lt;- ni_hat* indicador_dam1$Inactivo Y_hat &lt;- ceiling(Y_hat) X1_obs &lt;- cbind(matrix(1,nrow = D,ncol = 1),X_obs) K = ncol(X1_obs) D1 &lt;- nrow(X_pred) X1_pred &lt;- cbind(matrix(1,nrow = D1,ncol = 1),X_pred) sample_data &lt;- list(D = D, P = P, K = K, hat_y = Y_hat, X_obs = X1_obs, X_pred = X1_pred, D1 = D1) library(rstan) fit_mcmc2 &lt;- stan( file = &quot;Recursos/Día5/Sesion2/Data/modelosStan/01 Multinomial_simple_pred.stan&quot;, # Stan program data = sample_data, # named list of data verbose = TRUE, warmup = 1000, # number of warmup iterations per chain iter = 2000, # total number of iterations per chain cores = 4, # number of cores (could use one per chain) ) saveRDS(fit_mcmc2, &quot;Recursos/Día5/Sesion2/Data/fit_multinomial_cor.Rds&quot;) "],["validación-del-modelo-1.html", "15.4 Validación del modelo", " 15.4 Validación del modelo La validación de un modelo es esencial para evaluar su capacidad para predecir de manera precisa y confiable los resultados futuros. En el caso de un modelo de área con respuesta multinomial, la validación se enfoca en medir la precisión del modelo para predecir las diferentes categorías de respuesta. El objetivo principal de la validación es determinar si el modelo es capaz de generalizar bien a datos no vistos y proporcionar predicciones precisas. Esto implica comparar las predicciones del modelo con los datos observados y utilizar métricas de evaluación para medir el rendimiento del modelo. La validación del modelo es esencial para garantizar la calidad de las predicciones y la confiabilidad del modelo para su uso en aplicaciones futuras. library(bayesplot) library(posterior) infile &lt;- paste0(&quot;Recursos/Día5/Sesion2/Data/fit_multinomial_cor.Rds&quot;) fit &lt;- readRDS(infile) theta_dir &lt;- indicador_dam1 %&gt;% transmute(dam2, n = n_desocupado + n_ocupado + n_inactivo, Ocupado, Desocupado, Inactivo) color_scheme_set(&quot;brightblue&quot;) theme_set(theme_bw(base_size = 15)) y_pred_B &lt;- as.array(fit, pars = &quot;theta&quot;) %&gt;% as_draws_matrix() rowsrandom &lt;- sample(nrow(y_pred_B), 100) theta_1&lt;- grep(pattern = &quot;1]&quot;,x = colnames(y_pred_B),value = TRUE) theta_2&lt;- grep(pattern = &quot;2]&quot;,x = colnames(y_pred_B),value = TRUE) theta_3&lt;- grep(pattern = &quot;3]&quot;,x = colnames(y_pred_B),value = TRUE) y_pred1 &lt;- y_pred_B[rowsrandom,theta_1 ] y_pred2 &lt;- y_pred_B[rowsrandom,theta_2 ] y_pred3 &lt;- y_pred_B[rowsrandom,theta_3 ] ppc_dens_overlay(y = as.numeric(theta_dir$Ocupado), y_pred1)/ ppc_dens_overlay(y = as.numeric(theta_dir$Desocupado), y_pred2)/ ppc_dens_overlay(y = as.numeric(theta_dir$Inactivo), y_pred3) La matriz de correlación de los efectos aleatorios. omega &lt;- summary(fit,&quot;Omega&quot;)$summary tba(omega) mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat Omega[1,1] 1.0000 NaN 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 NaN NaN Omega[1,2] -0.0719 0.0043 0.1199 -0.3059 -0.1532 -0.0715 0.0074 0.1627 767.8159 1.005 Omega[2,1] -0.0719 0.0043 0.1199 -0.3059 -0.1532 -0.0715 0.0074 0.1627 767.8159 1.005 Omega[2,2] 1.0000 0.0000 0.0000 1.0000 1.0000 1.0000 1.0000 1.0000 3883.6753 0.999 "],["estimación-de-los-parámetros.-1.html", "15.5 Estimación de los parámetros.", " 15.5 Estimación de los parámetros. El código crea dos matrices, theta_obs_ordenado y theta_pred_ordenado, que contienen las estimaciones medias de los parámetros del modelo de respuesta multinomial con covariables para los datos de observación y predicción, respectivamente. La función matrix() se utiliza para dar formato a los datos con una matriz nrow x ncol, y se asignan nombres de columna apropiados a la matriz resultante utilizando colnames(). Luego se convierten las matrices en marcos de datos (as.data.frame()) y se unen mediante full_join() para crear una única tabla que contenga todas las estimaciones de los parámetros para los datos de observación y predicción, junto con la información del indicador de área (theta_dir). El resultado final es un marco de datos llamado estimaciones_obs. dam_pred &lt;- readRDS(&quot;Recursos/Día5/Sesion2/Data/dam_pred.rds&quot;) P &lt;- 3 D &lt;- nrow(indicador_dam1) D1 &lt;- nrow(dam_pred) ## Estimación del modelo. theta_obs &lt;- summary(fit, pars = &quot;theta&quot;)$summary[, &quot;mean&quot;] theta_pred &lt;- summary(fit, pars = &quot;theta_pred&quot;)$summary[, &quot;mean&quot;] ## Ordenando la matrix de theta theta_obs_ordenado &lt;- matrix(theta_obs, nrow = D, ncol = P,byrow = TRUE) colnames(theta_obs_ordenado) &lt;- c(&quot;Ocupado_mod&quot;, &quot;Desocupado_mod&quot;, &quot;Inactivo_mod&quot;) theta_obs_ordenado%&lt;&gt;% as.data.frame() theta_obs_ordenado &lt;- cbind(dam2 = indicador_dam1$dam2, theta_obs_ordenado) theta_pred_ordenado &lt;- matrix(theta_pred, nrow = D1, ncol = P,byrow = TRUE) colnames(theta_pred_ordenado) &lt;- c(&quot;Ocupado_mod&quot;, &quot;Desocupado_mod&quot;, &quot;Inactivo_mod&quot;) theta_pred_ordenado%&lt;&gt;% as.data.frame() theta_pred_ordenado &lt;- cbind(dam2 = dam_pred$dam2, theta_pred_ordenado) "],["estimación-del-desviación-estárdar-y-el-coeficiente-de-valiación.html", "15.6 Estimación del desviación estárdar y el coeficiente de valiación", " 15.6 Estimación del desviación estárdar y el coeficiente de valiación Este bloque de código corresponde al cálculo de las desviaciones estándar (sd) y coeficientes de variación (cv) de los parámetros theta para los datos observados y predichos. En primer lugar, se utiliza la función summary() del paquete rstan para extraer los valores de sd de los parámetros theta observados y predichos, respectivamente, a partir del modelo (fit) que contiene la información de la estimación de los parámetros de la distribución Bayesiana. Luego, se organizan los valores de sd en una matriz ordenada por dam2 y se les asignan los nombres correspondientes. Con esta matriz, se calcula otra matriz que contiene los coeficientes de variación para los parámetros theta observados (theta_obs_ordenado_cv). De manera similar, se construyen matrices ordenadas por dam2 para los valores de sd y cv de los parámetros theta predichos (theta_pred_ordenado_sd y theta_pred_ordenado_cv, respectivamente). theta_obs_sd &lt;- summary(fit, pars = &quot;theta&quot;)$summary[, &quot;sd&quot;] theta_pred_sd &lt;- summary(fit, pars = &quot;theta_pred&quot;)$summary[, &quot;sd&quot;] theta_obs_ordenado_sd &lt;- matrix(theta_obs_sd, nrow = D, ncol = P,byrow = TRUE) colnames(theta_obs_ordenado_sd) &lt;- c(&quot;Ocupado_mod_sd&quot;, &quot;Desocupado_mod_sd&quot;, &quot;Inactivo_mod_sd&quot;) theta_obs_ordenado_sd%&lt;&gt;% as.data.frame() theta_obs_ordenado_sd &lt;- cbind(dam2 = indicador_dam1$dam2, theta_obs_ordenado_sd) theta_obs_ordenado_cv &lt;- theta_obs_ordenado_sd[,-1]/theta_obs_ordenado[,-1] colnames(theta_obs_ordenado_cv) &lt;- c(&quot;Ocupado_mod_cv&quot;, &quot;Desocupado_mod_cv&quot;, &quot;Inactivo_mod_cv&quot;) theta_obs_ordenado_cv &lt;- cbind(dam2 = indicador_dam1$dam2, theta_obs_ordenado_cv) theta_pred_ordenado_sd &lt;- matrix(theta_pred_sd, nrow = D1, ncol = P,byrow = TRUE) colnames(theta_pred_ordenado_sd) &lt;- c(&quot;Ocupado_mod_sd&quot;, &quot;Desocupado_mod_sd&quot;, &quot;Inactivo_mod_sd&quot;) theta_pred_ordenado_sd%&lt;&gt;% as.data.frame() theta_pred_ordenado_sd &lt;- cbind(dam2 = dam_pred$dam2, theta_pred_ordenado_sd) theta_pred_ordenado_cv &lt;- theta_pred_ordenado_sd[,-1]/theta_pred_ordenado[,-1] colnames(theta_pred_ordenado_cv) &lt;- c(&quot;Ocupado_mod_cv&quot;, &quot;Desocupado_mod_cv&quot;, &quot;Inactivo_mod_cv&quot;) theta_pred_ordenado_cv &lt;- cbind(dam2 = dam_pred$dam2, theta_pred_ordenado_cv) El último paso es realizar la consolidación de la bases obtenidas para la estimación puntual, desviación estándar y coeficiente de variación. theta_obs_ordenado &lt;- full_join(theta_obs_ordenado,theta_obs_ordenado_sd) %&gt;% full_join(theta_obs_ordenado_cv) theta_pred_ordenado &lt;- full_join(theta_pred_ordenado,theta_pred_ordenado_sd) %&gt;% full_join(theta_pred_ordenado_cv) estimaciones &lt;- full_join(indicador_dam1, bind_rows(theta_obs_ordenado, theta_pred_ordenado)) saveRDS(object = estimaciones, file = &quot;Recursos/Día5/Sesion2/Data/estimaciones.rds&quot;) tba(head(estimaciones,10)) dam2 n_upm n_ocupado n_desocupado n_inactivo Ocupado Ocupado_se Ocupado_var Ocupado_deff Desocupado Desocupado_se Desocupado_var Desocupado_deff Inactivo Inactivo_se Inactivo_var Inactivo_deff id_orden Ocupado_mod Desocupado_mod Inactivo_mod Ocupado_mod_sd Desocupado_mod_sd Inactivo_mod_sd Ocupado_mod_cv Desocupado_mod_cv Inactivo_mod_cv 00101 127 2953 284 2439 0.5210 0.0117 1e-04 3.1326 0.0503 0.0050 0e+00 2.9903 0.4287 0.0119 0.0001 3.3118 1 0.5219 0.0495 0.4286 0.0116 0.0050 0.0115 0.0222 0.1018 0.0268 03201 109 2841 240 2524 0.5018 0.0128 2e-04 3.6801 0.0481 0.0045 0e+00 2.5120 0.4501 0.0122 0.0001 3.3802 2 0.5039 0.0476 0.4485 0.0123 0.0053 0.0123 0.0244 0.1111 0.0275 02501 87 3059 121 2133 0.5719 0.0111 1e-04 2.7180 0.0226 0.0034 0e+00 2.8494 0.4055 0.0115 0.0001 2.9408 3 0.5707 0.0239 0.4055 0.0110 0.0035 0.0110 0.0192 0.1457 0.0271 03203 59 1953 96 1629 0.5301 0.0121 1e-04 2.1909 0.0263 0.0027 0e+00 1.0520 0.4436 0.0124 0.0002 2.3024 4 0.5298 0.0270 0.4433 0.0123 0.0037 0.0124 0.0232 0.1386 0.0279 03202 42 1050 51 883 0.5290 0.0131 2e-04 1.3768 0.0229 0.0054 0e+00 2.5923 0.4481 0.0137 0.0002 1.5230 5 0.5263 0.0241 0.4497 0.0135 0.0041 0.0136 0.0257 0.1690 0.0301 01101 38 1203 114 713 0.6092 0.0227 5e-04 4.4247 0.0575 0.0075 1e-04 2.1246 0.3333 0.0227 0.0005 4.7511 6 0.5970 0.0608 0.3422 0.0208 0.0106 0.0203 0.0348 0.1737 0.0593 03206 32 837 51 728 0.5022 0.0177 3e-04 2.0370 0.0315 0.0080 1e-04 3.3819 0.4663 0.0170 0.0003 1.8859 7 0.5006 0.0319 0.4676 0.0169 0.0060 0.0171 0.0337 0.1891 0.0366 00901 20 744 83 530 0.5492 0.0194 4e-04 2.0806 0.0595 0.0113 1e-04 3.1142 0.3913 0.0208 0.0004 2.4841 8 0.5485 0.0581 0.3934 0.0196 0.0096 0.0197 0.0357 0.1649 0.0501 01301 20 738 45 552 0.5359 0.0244 6e-04 3.2173 0.0351 0.0049 0e+00 0.9599 0.4290 0.0262 0.0007 3.7629 9 0.5353 0.0363 0.4284 0.0224 0.0081 0.0224 0.0418 0.2220 0.0524 02101 20 505 52 460 0.4965 0.0258 7e-04 2.7259 0.0514 0.0116 1e-04 2.8329 0.4521 0.0332 0.0011 4.5559 10 0.4994 0.0497 0.4509 0.0261 0.0117 0.0267 0.0522 0.2346 0.0593 "],["metodología-de-benchmarking-1.html", "15.7 Metodología de Benchmarking", " 15.7 Metodología de Benchmarking Conteos de personas agregados por dam2, personas mayores de 15 años de edad. region &lt;- readRDS(file = &quot;Recursos/Día5/Sesion2/Data/total_personas_dam2.rds&quot;) %&gt;% ungroup() %&gt;% select(region,dam2) conteo_pp_dam &lt;- readRDS(&quot;Recursos/Día5/Sesion2/Data/censo_mrp_dam2.rds&quot;) %&gt;% filter(edad &gt; 1) %&gt;% group_by(dam , dam2) %&gt;% summarise(pp_dam2 = sum(n),.groups = &quot;drop&quot;) conteo_pp_dam &lt;- inner_join(conteo_pp_dam,region) %&gt;% group_by(region) %&gt;% mutate(pp_region = sum(pp_dam2)) head(conteo_pp_dam) %&gt;% tba() Estimación del parámetro theta al nivel que la encuesta sea representativa. indicador_agregado &lt;- readRDS(&quot;Recursos/Día5/Sesion2/0Recursos/tablas.rds&quot;) %&gt;% select(region,Ocupado,Desocupado,Inactivo) temp &lt;- gather(indicador_agregado, key = &quot;agregado&quot;, value = &quot;estimacion&quot;,-region) %&gt;% mutate(nombre = paste0(&quot;region_&quot;, region, &quot;_&quot;, agregado)) Razon_empleo &lt;- setNames(temp$estimacion, temp$nombre) tba(indicador_agregado) region Ocupado Desocupado Inactivo 01 0.5537 0.0236 0.4227 02 0.5492 0.0349 0.4159 03 0.5236 0.0855 0.3909 04 0.5136 0.0337 0.4526 05 0.4623 0.0423 0.4954 06 0.4999 0.0298 0.4703 07 0.5295 0.0174 0.4532 08 0.5639 0.0678 0.3683 09 0.5257 0.0505 0.4238 10 0.5144 0.0402 0.4453 Definir los pesos por dominios. names_cov &lt;- &quot;region&quot; estimaciones_mod &lt;- estimaciones %&gt;% transmute( region, dam2,Ocupado_mod,Desocupado_mod,Inactivo_mod) %&gt;% inner_join(conteo_pp_dam ) %&gt;% mutate(wi = pp_dam2/pp_region) Crear variables dummys estimaciones_mod %&lt;&gt;% fastDummies::dummy_cols(select_columns = names_cov, remove_selected_columns = FALSE) Xdummy &lt;- estimaciones_mod %&gt;% select(matches(&quot;region_&quot;)) %&gt;% mutate_at(vars(matches(&quot;_\\\\d&quot;)) , list(Ocupado = function(x) x*estimaciones_mod$Ocupado_mod, Desocupado = function(x) x*estimaciones_mod$Desocupado_mod, Inactivo = function(x) x*estimaciones_mod$Inactivo_mod)) %&gt;% select((matches(&quot;Ocupado|Desocupado|Inactivo&quot;))) Calcular el ponderador para cada nivel de la variable. Ocupado library(sampling) names_ocupado &lt;- grep(pattern = &quot;_O&quot;, x = colnames(Xdummy),value = TRUE) gk_ocupado &lt;- calib(Xs = Xdummy[,names_ocupado] %&gt;% as.matrix(), d = estimaciones_mod$wi, total = Razon_empleo[names_ocupado] %&gt;% as.matrix(), method=&quot;linear&quot;,max_iter = 5000) checkcalibration(Xs = Xdummy[,names_ocupado] %&gt;% as.matrix(), d =estimaciones_mod$wi, total = Razon_empleo[names_ocupado] %&gt;% as.matrix(), g = gk_ocupado,) Desocupado names_descupados &lt;- grep(pattern = &quot;_D&quot;, x = colnames(Xdummy),value = TRUE) gk_desocupado &lt;- calib(Xs = Xdummy[,names_descupados]%&gt;% as.matrix(), d = estimaciones_mod$wi, total = Razon_empleo[names_descupados]%&gt;% as.matrix(), method=&quot;linear&quot;,max_iter = 5000,) checkcalibration(Xs = Xdummy[,names_descupados]%&gt;% as.matrix(), d =estimaciones_mod$wi, total = Razon_empleo[names_descupados]%&gt;% as.matrix(), g = gk_desocupado,) Inactivo names_inactivo &lt;- grep(pattern = &quot;_I&quot;, x = colnames(Xdummy),value = TRUE) gk_Inactivo &lt;- calib(Xs = Xdummy[,names_inactivo]%&gt;% as.matrix(), d = estimaciones_mod$wi, total = Razon_empleo[names_inactivo]%&gt;% as.matrix(), method=&quot;linear&quot;,max_iter = 5000,) checkcalibration(Xs = Xdummy[,names_inactivo]%&gt;% as.matrix(), d =estimaciones_mod$wi, total = Razon_empleo[names_inactivo]%&gt;% as.matrix(), g = gk_Inactivo,) Validar los resultados obtenidos. par(mfrow = c(1,3)) hist(gk_ocupado) hist(gk_desocupado) hist(gk_Inactivo) Estimaciones ajustadas por el ponderador estimacionesBench &lt;- estimaciones_mod %&gt;% mutate(gk_ocupado, gk_desocupado, gk_Inactivo) %&gt;% transmute( region, dam, dam2, wi,gk_ocupado, gk_desocupado, gk_Inactivo, Ocupado_Bench = Ocupado_mod*gk_ocupado, Desocupado_Bench = Desocupado_mod*gk_desocupado, Inactivo_Bench = Inactivo_mod*gk_Inactivo ) Validación de resultados. estimacionesBench %&gt;% group_by(region) %&gt;% summarise(Ocupado_Bench = sum(wi*Ocupado_Bench), Desocupado_Bench = sum(wi*Desocupado_Bench), Inactivo_Bench = sum(wi*Inactivo_Bench)) %&gt;% inner_join(indicador_agregado) %&gt;% tba() region Ocupado_Bench Desocupado_Bench Inactivo_Bench Ocupado Desocupado Inactivo 01 0.5537 0.0236 0.4227 0.5537 0.0236 0.4227 02 0.5492 0.0349 0.4159 0.5492 0.0349 0.4159 03 0.5236 0.0855 0.3909 0.5236 0.0855 0.3909 04 0.5136 0.0337 0.4526 0.5136 0.0337 0.4526 05 0.4623 0.0423 0.4954 0.4623 0.0423 0.4954 06 0.4999 0.0298 0.4703 0.4999 0.0298 0.4703 07 0.5295 0.0174 0.4532 0.5295 0.0174 0.4532 08 0.5639 0.0678 0.3683 0.5639 0.0678 0.3683 09 0.5257 0.0505 0.4238 0.5257 0.0505 0.4238 10 0.5144 0.0402 0.4453 0.5144 0.0402 0.4453 Guardar resultados estimaciones &lt;- inner_join(estimaciones,estimacionesBench) saveRDS(object = estimaciones, file = &quot;Recursos/Día5/Sesion2/Data/estimaciones_Bench.rds&quot;) "],["mapas-del-mercado-de-trabajo.-1.html", "15.8 Mapas del mercado de trabajo.", " 15.8 Mapas del mercado de trabajo. library(sp) library(sf) library(tmap) ShapeSAE &lt;- read_sf(&quot;Shape/DOM_dam2.shp&quot;) %&gt;% rename(dam2 = id_dominio) %&gt;% mutate(dam2 = str_pad( string = dam2, width = 5, pad = &quot;0&quot; )) P1_empleo &lt;- tm_shape(ShapeSAE %&gt;% inner_join(estimaciones)) brks_ocupado &lt;- seq(0.2,0.8,0.1) brks_desocupado &lt;- seq(0,0.2,0.05) brks_inactivo &lt;- seq(0.17,0.62, 0.09) Ocupado Mapa_ocupado &lt;- P1_empleo + tm_fill(&quot;Ocupado_Bench&quot;, breaks = brks_ocupado, title = &quot;Ocupado&quot;, palette = &quot;-Blues&quot;) + tm_layout( legend.only = FALSE, legend.height = -0.95, legend.width = -0.95, asp = 2.1, legend.text.size = 3, legend.title.size = 3 ) Mapa_ocupado Desocupado Mapa_desocupado &lt;- P1_empleo + tm_fill( &quot;Desocupado_Bench&quot;, breaks = brks_desocupado, title = &quot;Desocupado&quot;, palette = &quot;YlOrRd&quot; ) + tm_layout( legend.only = FALSE, legend.height = -0.95, legend.width = -0.95, asp = 2.1, legend.text.size = 3, legend.title.size = 3 ) Mapa_desocupado Inactivo Mapa_Inactivo &lt;- P1_empleo + tm_fill( &quot;Inactivo_Bench&quot;, title = &quot;Inactivo&quot;, breaks = brks_inactivo, palette = &quot;YlGn&quot; ) + tm_layout( legend.only = FALSE, legend.height = -0.95, legend.width = -0.95, asp = 2.1, legend.text.size = 3, legend.title.size = 3 ) Mapa_Inactivo "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]

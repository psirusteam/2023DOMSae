
```{r setup, include=FALSE, message=FALSE, error=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE)

library(printr)
library(kableExtra)
library(tidyverse)
tba <- function(dat, cap = NA){
  kable(dat,
      format = "html", digits =  4,
      caption = cap) %>% 
     kable_styling(bootstrap_options = "striped", full_width = F)%>%
         kable_classic(full_width = F, html_font = "Arial Narrow")
}

```

# Día 3 - Sesión 3- Modelos de área - Estimación de la informalidad laboral.


La informalidad laboral es un fenómeno que ha sido objeto de estudio en la República Dominicana y en Latinoamérica debido a su impacto en el mercado laboral y en el desarrollo social. Según "La informalidad en el mercado laboral urbano de la República Dominicana", la informalidad laboral se refiere a la falta de registro y protección social de los trabajadores, así como a la ausencia de derechos laborales y condiciones de trabajo dignas. A pesar de que existe una definición común, la medición de la informalidad varía según el enfoque y la metodología utilizada, lo cual puede generar diferencias en los resultados obtenidos.

En la República Dominicana, la informalidad laboral es un fenómeno que afecta principalmente a los trabajadores del sector informal, que representan más de la mitad de la fuerza laboral del país. Este sector se caracteriza por la falta de protección social, la inestabilidad laboral y la baja remuneración, lo que limita las oportunidades de desarrollo de los trabajadores y sus familias. Además, la informalidad laboral tiene un impacto negativo en la economía del país, ya que reduce la recaudación fiscal y limita la inversión en programas sociales y de desarrollo.

Es importante conocer estas estimaciones de la informalidad laboral para comprender las desigualdades económicas y laborales en el país y desarrollar medidas para proteger los derechos laborales de los trabajadores informales y mejorar la economía del país en general.

## Estimaciones directas.

En este apartado realizaremos las estimaciones directas para los dominios que fueron seleccionados en la muestra, dado que estos fueron no planeados. Las estimaciones directas son una herramienta comúnmente utilizada en la estadística inferencial para obtener información sobre una población a partir de una muestra. Sin embargo, estas estimaciones pueden presentar problemas cuando la muestra es pequeña, lo que puede conducir a una falta de precisión en las estimaciones y a una mayor incertidumbre en las conclusiones que se puedan extraer.


```{r, eval=FALSE}
encuestaDOM <-  readRDS("Data/encuestaDOM.Rds")

encuestaDOM <-
  encuestaDOM %>%
  transmute(
    dam2 = id_dominio,
    upm = str_pad(string = upm,width = 9,pad = "0"),
    estrato = str_pad(string = estrato,width = 5,pad = "0"),
    factor_anual = factor_expansion / 4, 
    pet, ocupado,orden_sector
) %>% 
    filter(ocupado == 1 & pet == 1)
```

Para la definición del diseño se hace uso de la librería `survey` como se muestra en el siguiente código

```{r, eval=FALSE}
options(survey.lonely.psu= 'adjust' )
disenoDOM <- encuestaDOM %>%
  as_survey_design(
    strata = estrato,
    ids = upm,
    weights = factor_anual,
    nest=T
  )
```

###  Calculo del indicador

La informalidad laboral en República Dominicana se define como el trabajo que se realiza al margen de las leyes tributarias y laborales, así como aquel que busca evadir sus obligaciones fiscales ante las agencias del gobierno. Para definir el indicador de la informalidad laboral en República Dominicana, se utiliza la siguiente fórmula:

$$
Tas\ de\ informalidad\ laboral = \frac{Número\ de\ trabajadores\ informales}{ Población\ económicamente\ activa} \times 100.
$$

Este bloque de código realiza lo siguiente:

  -   Se agrupa la encuesta por dam2
  -   Se calcula el tamaño muestral no ponderado (`n()`).
  -   Se calcula la razón de la variable `orden_sector` igual a 2 sobre la variable constante igual a 1 mediante el uso de `survey_ratio()`, que utiliza los pesos de muestreo para producir estimaciones de varianza y errores estándar apropiados para el muestreo complejo.
  -   La función `survey_ratio()` también permite calcular intervalos de confianza y coeficientes de variación.


```{r, eval=FALSE}
indicador_dom <-
  disenoDOM %>% group_by(dam2) %>% 
  summarise(
    n = unweighted(n()),
    Rd = survey_ratio(
      numerator = orden_sector == 2 ,
      denominator = 1,
      vartype = c("se", "ci", "var", "cv"),
      deff = T
    )
  )
```

Ahora, como parte del proceso es necesario incorporar la información del número de
upm por dam2, para lo cual se hace 

```{r, eval=FALSE}
n_upm <- encuestaDOM %>% distinct(dam2, upm) %>% 
  group_by(dam2) %>% tally(name = "n_upm",sort = TRUE)
indicador_dom <- inner_join(n_upm,indicador_dom)
saveRDS(object = indicador_dom, file = "Data/indicador_dom.rds")
```



```{r, echo=FALSE}
indicador_dom <- readRDS( "Data/indicador_dom.rds")
tba(indicador_dom %>% head(10))
```


## Función Generalizada de Varianza

La Función Generalizada de Varianza (GVF) es una técnica estadística utilizada para suavizar las estimaciones de las varianzas directas de los estimadores. Esta técnica busca estimar la varianza suavizada del estimador directo a través de un modelo log-lineal que involucra un vector de covariables auxiliares. La GVF es particularmente útil para modelar las varianzas de los estimadores directos, ya que permite lidiar con la naturaleza positiva de este parámetro. Además, esta técnica ha sido ampliamente utilizada en la literatura para estimar la varianza de los estimadores directos en diferentes contextos, incluyendo la estimación de ingreso per cápita en los Estados Unidos, cifras oficiales del mercado de trabajo en Canadá y las tasas de pobreza comunal en la región. En este sentido, la GVF se plantea en términos de una relación log-lineal con un vector de covariables auxiliares que puede variar dependiendo del contexto en que se aplique.

El proceso continua con la selección de las dam que posean una varianza estimada mayor que cero, un deff mayor que 1 y 2 o más UPMs. Para los dominios que superan estas condiciones se realiza la transformación $\log(\hat{\sigma}^2_d)$, además se realiza la selección de las columnas identificador del municipio (`id_dominio`), la estimación directa del indicador (`Rd`), El número de personas en el dominio (`n`) y la varianza estimada del para la estimación directa `Rd_var`,siendo esta la que transforma mediante la función `log()`. 


```{r}
indicador_dom1 <- indicador_dom %>% 
  filter(Rd_var>0 & Rd_deff>=1 & n_upm >= 2) 

baseFGV <-  indicador_dom1 %>%  
  dplyr::select(dam2 , Rd, n, Rd_var) %>%
  mutate(ln_sigma2 = log(Rd_var))
```


### Gráficas exploratorias

El código muestra la creación de cuatro gráficos usando la librería `ggplot2` y el uso de los datos `baseFGV`.  Estos gráficos tienen como objetivo explorar la relación entre el logaritmo de la varianza y diferentes transformaciones de la `n` y `Rd`.

El primer gráfico (`p1`) representa la relación entre la estimación directa y el logaritmo de la varianza. El segundo gráfico (`p2`) representa la relación entre el tamaño de muestra y el logaritmo de la varianza. El tercer gráfico (`p3`) representa la relación entre $n_d \times Rd$  y el logaritmo de la varianza. Finalmente, el cuarto gráfico (`p4`) representa la relación entre la raíz cuadrada de la estimación directa y el logaritmo de la varianza.

```{r}
p1 <- ggplot(baseFGV, aes(x = Rd, y = ln_sigma2)) +
  geom_point() +
  geom_smooth(method = "loess") +
  xlab("Formal")

p2 <- ggplot(baseFGV, aes(x = n, y = ln_sigma2)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  xlab("Tamaño de muestra")

p3 <- ggplot(baseFGV, 
             aes(x = Rd * n, y = ln_sigma2)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  xlab("Número de Formales")

p4 <- ggplot(baseFGV, 
             aes(x = sqrt(Rd), y = ln_sigma2)) + 
  geom_point() +
  geom_smooth(method = "loess") + 
  xlab("Raiz cuadrada de tasa de formalidad")


(p1 | p2) / (p3 | p4)
rm('p1','p2','p3','p4')

```

### Ajustando el modelo log-lineal de la varianza 

El código ajusta un modelo de regresión lineal múltiple (utilizando la función `lm()`), donde `ln_sigma2` es la variable respuesta y las variables predictoras son `Rd`, `n`, y varias transformaciones de éstas. El objetivo de este modelo es estimar la función generalizada de varianza (FGV) para los dominios observados.

```{r}
library(gtsummary)
FGV1 <- lm(ln_sigma2 ~ 1 + Rd + 
             n + I(n ^ 2) + I(Rd * n) +
             I(sqrt(Rd)) + I(sqrt(n)) + 
             I(sqrt(Rd * n)) ,
           data = baseFGV)

tbl_regression(FGV1) %>% 
  add_glance_table(include = c(r.squared, adj.r.squared))
```

Después de tener la estimación del modelo se debe obtener el  valor de la constante $\Delta$ para lo cual se usa el siguiente código.  


```{r}
delta.hat = sum(baseFGV$Rd_var) / sum(exp(fitted.values(FGV1)))

```
De donde se obtiene que $\Delta = `r delta.hat`$. Final es posible obtener la varianza suavizada  ejecutando el siguiente comando. 

```{r}
baseFGV <-
  baseFGV %>% mutate(hat_var = delta.hat * exp(fitted.values(FGV1)))
```

### Validaciones sobre el modelo 


```{r}
par(mfrow = c(2, 2))
plot(FGV1)
```
varianza suavizada Vs varianza estimada 

```{r}
ggplot(baseFGV, 
       aes(x = Rd_var, y = hat_var)) + 
  geom_point() +
  geom_smooth(method = "loess")
```

Este código está realizando una Consolidación de los dominios observados y no observados para lo cual hace una unión izquierda (`left_join()`) entre: `indicador_dom` y `baseFGV` de la cual selecciona las columnas de `id_dominio` y `hat_var`. El argumento `by = id_dominio` especifica que la unión debe realizarse mediante la columna `id_dominio`.

Luego, se utiliza la función `mutate()` para crear dos nuevas variables. La primera variable `Rd_var` se asigna el valor de `Rd_var` de `baseFGV` si `hat_var` no es un valor nulo (`NA`), de lo contrario se le asigna un valor `NA_real_` (NA pero de tipo numérico). De manera similar, se crea la variable `Rd_deff` con el valor de `Rd_deff` de `baseFGV` si `hat_var` no es nulo, de lo contrario se le asigna un valor `NA_real_`. 

```{r}

base_sae <- left_join(indicador_dom,
                      baseFGV %>% select(dam2, hat_var), 
                      by = "dam2") %>%
  mutate(
    Rd_var = ifelse(is.na(hat_var), NA_real_, Rd_var),
    Rd_deff = ifelse(is.na(hat_var), NA_real_, Rd_deff)
  )

```

Ahora, se debe estimar **deff_FGV** y **n_eff_FGV** a parir de la varianza suvizada (`hat_var`). 


```{r}
base_FH <- base_sae %>%
  mutate(
    Rd_deff = ifelse(is.nan(Rd_deff), 1, Rd_deff),
    deff_FGV = ifelse(Rd_var == 0 ,
      1,
      hat_var / (Rd_var / Rd_deff) #Fórmula del nuevo DEFF
    ),
   # Criterio MDS para regularizar el DeffFGV
    deff_FGV = ifelse(deff_FGV <= 1, NA_real_, deff_FGV), #Deff estimado
    n_eff_FGV = n / deff_FGV, #Número efectivo de personas encuestadas
   # Si no se estimó varianza para ese municipio, también excluir
   # la estimación directa de este municipio, esto es relevante para el modelo FH  
    hat_var = ifelse(deff_FGV <= 1, NA_real_, hat_var), 
    Rd = ifelse(is.na(hat_var), NA_real_, Rd) 
  )
tba(head(base_FH %>% select(dam2,n,n_upm,Rd, Rd_var,hat_var:n_eff_FGV), 10))
```

### Otras validaciones sobre el resultado del modelo. 

Continuando con el proceso de validación se construye el siguiente gráfico de dispersión con la variable de la varianza del estimador directo en el eje _y_ y la varianza FGV  en el eje _x_, para los municipios que tienen valores válidos para ambas variables. La línea de regresión lineal se ajusta a los puntos usando el método de mínimos cuadrados.

La visualización del gráfico permite evaluar si la FGV está capturando adecuadamente la variabilidad de la variable de interés (en este caso, la variable de varianza del estimador directo). Si la FGV captura la variabilidad, se espera que los puntos estén relativamente cerca de la línea de regresión, lo que indicaría que la FGV explica una gran parte de la variabilidad de la varianza del estimador directo. Por otro lado, si la FGV no captura la variabilidad, los puntos estarán más dispersos y alejados de la línea de regresión. 


```{r}
nDom <- sum(!is.na(base_FH$hat_var))
temp_FH <- base_FH %>% filter(!is.na(hat_var))

ggplot(temp_FH %>% arrange(n), aes(x = hat_var, y = Rd_var)) + 
  geom_point() + 
  geom_smooth(method = "lm", col = 2) + 
  labs(x = "FGV", y = "VaRdirEst") +
  ylab("Varianza del Estimador Directo")
```


Ahora, se realiza la comparación de la variabilidad de la varianza del estimador directo frente a la varianza suavizada a medida que el tamaño de muestra aumenta. El eje _x_ representa el tamaño de la muestra y el eje _y_ representa las varianzas. La línea azul representa la varianza FGV, mientras que la línea roja representa la varianza del estimador directo. En el gráfica es posible notar que la varianza FGV tiene una menos volatilidad que la varianza directa. 


```{r}
ggplot(temp_FH %>% 
         arrange(n), aes(x = 1:nDom)) +
  geom_line(aes(y = Rd_var, color = "VarDirEst")) +
  geom_line(aes(y = hat_var, color = "FGV")) +
  labs(y = "Varianzas", x = "Tamaño muestral", color = " ") +
  scale_x_continuous(breaks = seq(1, nDom, by = 10),
                     labels = temp_FH$n[order(temp_FH$n)][seq(1, nDom, by = 10)]) +
  scale_color_manual(values = c("FGV" = "Blue", "VarDirEst" = "Red"))
```


Siguiendo en la misma línea, se realiza la comparación del efectivo directo (n_eff_DIR) y el efectivo FGV (n_eff_DIR). El código que se muestra a continuación produce un gráfico que compara el tamaño de muestra efectivo obtenido a través de la estimación del DEFF con el tamaño de muestra directo. En el eje x se muestra el tamaño de muestra directo (n) y en el eje y se muestra el tamaño de muestra efectivo, calculado a través de la fórmula n/DEFF para la estimación directa (en rojo) y para la FGV (en azul).

Se puede observar que, en general, el tamaño de muestra efectivo estimado a través de la FGV es menos variable que el estimado a través de la estimación directa, lo que indica que la FGV reduce la varianza de la estimación. Además, se puede observar que para algunos dominios, el tamaño de muestra efectivo estimado a través de la FGV es menor que el tamaño de muestra directo, lo que podría deberse a la estimación de la varianza a través de la FGV. En general, este gráfico es útil para comparar la eficiencia de la estimación a través de la FGV y la estimación directa para cada dominio.


```{r}
ggplot(temp_FH %>%
         arrange(n), aes(x = 1:nDom)) +
  geom_line(aes(y =  n / Rd_deff, color = "n_eff_DIR")) +
  geom_line(aes(y = n_eff_FGV, color = "n_eff_FGV")) +
  labs(y = "Tamaño de muestra efectivo",
       x = "Tamaño muestral", color = " ") +
  scale_x_continuous(breaks = seq(1, nDom, by = 10),
                     labels = temp_FH$n[order(temp_FH$n)][seq(1, nDom, by = 10)]) +
  scale_color_manual(values = c("n_eff_FGV" = "Blue", "n_eff_DIR" = "red"))


```

Por último, guardamos la base resultante. 
```{r,eval=FALSE}
saveRDS(object = base_FH, "Data/base_FH.Rds")
```


## Estimación de la informalidad laboral con un modelo de área con tranformación arcoseno.


El Modelo de Fay-Herriot con transformación arcoseno es una técnica estadística ampliamente utilizada en la estimación de la media y la varianza de una población a partir de una muestra. Esta herramienta es particularmente útil cuando se trabaja con datos que no cumplen con los supuestos de normalidad, como es el caso de las proporciones o porcentajes limitados entre 0 y 1.

La transformación arcoseno es una técnica matemática que se aplica a los datos para mejorar su distribución. Esta transformación se utiliza comúnmente en estadística para trabajar con datos que tienen una distribución asimétrica o no cumplen con la normalidad. La transformación arcoseno es especialmente útil para trabajar con variables como la informalidad laboral, que se define como la proporción de trabajadores informales en una población.

En este contexto, el modelo de Fay-Herriot con transformación arcoseno se convierte en una herramienta valiosa para la estimación de la informalidad laboral en pequeñas áreas geográficas. Esta técnica permite la inclusión de información auxiliar, como las características socioeconómicas de las áreas geográficas, para mejorar la precisión y la confiabilidad de las estimaciones.

Además, el modelo de Fay-Herriot con transformación arcoseno también permite la inclusión de covariables para tener en cuenta los factores socioeconómicos que pueden influir en la informalidad laboral. Al incorporar esta información adicional, se pueden obtener estimaciones más precisas y detalladas de la informalidad laboral en áreas geográficas específicas.

Ahora, la transformación arcoseno para la estimación directa $\theta_d$ esta dada por: 

$$
\hat{z}_d = arcsin\left( \sqrt{ \hat{\theta}_d} \right)
$$ donde

$$
Var\left( \hat{z}_d \right) = \frac{\widehat{DEFF}_d}{4\times n_d} = \frac{1}{4\times n_{d,efectivo} }
$$

Y el modelo de Fay-Herriot  estaría definido de la siguiente forma:

$$
\begin{eqnarray*}
Z_d \mid \mu_d,\sigma^2_d &  \sim  & N(\mu_d, \sigma^2_d)\\
\mu_d & = & \boldsymbol{x}^{T}_{d}\boldsymbol{\beta} + u_d \\
\theta_d & = &  \left(sin(\mu_d)\right)^2
\end{eqnarray*}
$$ donde $u_d \sim N(0 , \sigma^2)$.


Suponga de las distribuciones previas para 
$\boldsymbol{\beta}$ y $\sigma_{u}^{2}$ son dadas por 

$$
\begin{eqnarray*}
\boldsymbol{\beta}	\sim	N\left(0,1000 \right)\\
\sigma_{u}^{2}	\sim	IG\left(0.0001,0.0001\right)
\end{eqnarray*}
$$

## Procedimiento de estimación

Lectura de la base de datos que resultó en el paso anterior y selección de las columnas de interés
```{r}
library(tidyverse)
library(magrittr)

base_FH <- readRDS("Data/base_FH.rds") %>% 
  transmute(dam2,                            ## id dominios
            Rd,
            T_pobreza = asin(sqrt(Rd)),      ## creando zd
            n_effec = n_eff_FGV,             ## n efectivo
            varhat = 1/(4*n_effec)           ## varianza para zd
            )
```

Lectura de las covariables, las cuales son obtenidas previamente. Dado la diferencia entre las escalas de las variables  es necesario hacer un ajuste a estas. 

```{r}
statelevel_predictors_df <- readRDS("Data/statelevel_predictors_df_dam2.rds") %>% 
    mutate_at(.vars = c("luces_nocturnas",
                      "cubrimiento_cultivo",
                      "cubrimiento_urbano",
                      "modificacion_humana",
                      "accesibilidad_hospitales",
                      "accesibilidad_hosp_caminado"),
            function(x) as.numeric(scale(x))) %>% 
  mutate(dam2 = str_sub(dam2,2,5))
```

Uniendo las dos bases de datos. 

```{r}
base_FH <- full_join(base_FH, statelevel_predictors_df, by = "dam2" )
tba(base_FH[,1:8] %>% head(10))
```

Seleccionando las covariables para el modelo. 

```{r}
names_cov <- c(
  "sexo2" ,
  "tasa_desocupacion" ,
  "luces_nocturnas" ,
  "cubrimiento_cultivo" ,
  "modificacion_humana",
  "alfabeta"
)

```

## Preparando los insumos para `STAN`

  1.    Dividir la base de datos en dominios observados y no observados

Dominios observados.
```{r}
data_dir <- base_FH %>% filter(!is.na(T_pobreza))
```

Dominios NO observados.
```{r}
data_syn <-
  base_FH %>% anti_join(data_dir %>% select(dam2))
tba(data_syn[,1:8] %>% slice(1:10))
```


  2.    Definir matriz de efectos fijos.
  

```{r}
## Dominios observados
Xdat <- cbind(inter = 1,data_dir[,names_cov])

## Dominios no observados
Xs <-  cbind(inter = 1,data_syn[,names_cov])
```

  3.    Creando lista de parámetros para `STAN`

```{r}
sample_data <- list(
  N1 = nrow(Xdat),       # Observados.
  N2 = nrow(Xs),         # NO Observados.
  p  = ncol(Xdat),       # Número de regresores.
  X  = as.matrix(Xdat),  # Covariables Observados.
  Xs = as.matrix(Xs),    # Covariables NO Observados
  y  = as.numeric(data_dir$T_pobreza),
  sigma_e = sqrt(data_dir$varhat)
)
```

  4.    Compilando el modelo en `STAN`
  
```{r, eval=FALSE}
library(rstan)
fit_FH_arcoseno <- "Data/modelosStan/15FH_arcsin_normal.stan"
options(mc.cores = parallel::detectCores())
model_FH_arcoseno <- stan(
  file = fit_FH_arcoseno,  
  data = sample_data,   
  verbose = FALSE,
  warmup = 500,         
  iter = 1000,            
  cores = 4              
)
saveRDS(model_FH_arcoseno,
        "Data/model_FH_arcoseno.rds")

```

```{r}
model_FH_arcoseno <- readRDS("Data/model_FH_arcoseno.rds")
```


### Resultados del modelo para los dominios observados. 

En este código, se cargan las librerías `bayesplot`, `posterior` y `patchwork`, que se utilizan para realizar gráficos y visualizaciones de los resultados del modelo.

A continuación, se utiliza la función `as.array()` y `as_draws_matrix()` para extraer las muestras de la distribución posterior del parámetro `theta` del modelo, y se seleccionan aleatoriamente 100 filas de estas muestras utilizando la función `sample()`, lo que resulta en la matriz `y_pred2.`

Finalmente, se utiliza la función `ppc_dens_overlay()` de `bayesplot` para graficar una comparación entre la distribución empírica de la variable observada pobreza en los datos (`data_dir$pobreza`) y las distribuciones predictivas posteriores simuladas para la misma variable (`y_pred2`). La función `ppc_dens_overlay()` produce un gráfico de densidad para ambas distribuciones, lo que permite visualizar cómo se comparan.

```{r, eval=FALSE}
library(bayesplot)
library(patchwork)
library(posterior)

y_pred_B <- as.array(model_FH_arcoseno, pars = "theta") %>% 
  as_draws_matrix()
rowsrandom <- sample(nrow(y_pred_B), 100)

y_pred2 <- y_pred_B[rowsrandom, ]
ppc_dens_overlay(y = as.numeric(data_dir$Rd), y_pred2)
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("0Recursos/FH_Asin.png")
```


Análisis gráfico de la convergencia de las cadenas de $\sigma^2_u$. 

```{r, eval=FALSE}
posterior_sigma2_u <- as.array(model_FH_arcoseno, pars = "sigma2_u")
(mcmc_dens_chains(posterior_sigma2_u) +
    mcmc_areas(posterior_sigma2_u) ) / 
  mcmc_trace(posterior_sigma2_u)

# traceplot(model_FH_arcoseno,pars = "sigma2_u",inc_warmup = TRUE)
# stan_plot(model_FH_arcoseno)
#traceplot(model_FH_arcoseno,pars = "beta",inc_warmup = TRUE)
```

```{r echo=FALSE, out.width="200%"}
knitr::include_graphics("0Recursos/FH_Asin2.png")
```

Estimación del FH de la pobreza en los dominios observados. 

```{r, eval=FALSE}
theta_FH <-   summary(model_FH_arcoseno,pars =  "theta")$summary %>%
  data.frame()
data_dir %<>% mutate(pred_arcoseno = theta_FH$mean, 
                     pred_arcoseno_EE = theta_FH$sd,
                     Cv_pred = pred_arcoseno_EE/pred_arcoseno)
```

Estimación del FH de la pobreza en los dominios NO observados. 

```{r, eval=FALSE}
theta_FH_pred <- summary(model_FH_arcoseno,pars =  "theta_pred")$summary %>%
  data.frame()
data_syn <- data_syn %>% 
  mutate(pred_arcoseno = theta_FH_pred$mean,
         pred_arcoseno_EE = theta_FH_pred$sd,
         Cv_pred = pred_arcoseno_EE/pred_arcoseno)


```

## Mapa de informalidad laboral

El siguiente bloque de código carga los paquetes `sp`, `sf` y `tmap` y realiza una serie de operaciones. En primer lugar, une (rbind) las estimaciones de los dominios observados y no observados (`data_dir`, `data_syn`) y selecciona las variables `dam2`, `pobreza` (informalidad laboral), `pred_arcoseno`, `pred_arcoseno_EE` y `Cv_pred` utilizando la función `select()`. A continuación, lee un archivo `Shapefile` que contiene información geoespacial del país. Luego, crea un mapa temático (`tmap`) utilizando la función `tm_shape()` y agregando capas con la función `tm_polygons()`. El mapa representa dos variables llamadas `pobreza` y `pred_arcoseno`, utilizando una paleta de colores llamada "YlOrRd" y establece los cortes de los intervalos de las variables con la variable `brks_lp`. Finalmente, la función `tm_layout()` establece algunos parámetros de diseño del mapa, como la relación de aspecto (`asp`).


```{r, out.height= "120%", eval=FALSE}
library(sp)
library(sf)
library(tmap)

data_map <- rbind(data_dir, data_syn) %>% 
  select(dam2, Rd, pred_arcoseno, pred_arcoseno_EE,Cv_pred ) 


## Leer Shapefile del país
ShapeSAE <- read_sf("Shape/DOM_dam2.shp") %>% 
   rename(dam2 = id_dominio) 

mapa <- tm_shape(ShapeSAE %>%
                   left_join(data_map,  by = "dam2"))

brks_lp <- quantile(data_map$pred_arcoseno)
tmap_options(check.and.fix = TRUE)
Mapa_lp <-
  mapa + tm_polygons(
    c("Rd", "pred_arcoseno"),
    breaks = brks_lp,
    title = "Mapa de Tasa de informalidad",
    palette = "YlOrRd",
    colorNA = "white"
  ) + tm_layout(asp = 2.5)

Mapa_lp
```


```{r echo=FALSE, out.width="200%",fig.align='center'}
knitr::include_graphics("0Recursos/Mapa_arcoseno.PNG")
```


## Mapa del coeficiente de variación.  

Ahora, se crea un segundo mapa temático (`tmap`) llamado `Mapa_cv`. Utiliza la misma estructura del primer mapa (mapa) creado anteriormente y agrega una capa utilizando la función `tm_polygons()`. El mapa representa la variable `Cv_pred`, utilizando una paleta de colores llamada "YlOrRd" y establece el título del mapa con el parámetro `title`. La función `tm_layout()` establece algunos parámetros de diseño del mapa, como la relación de aspecto (asp). Finalmente, el mapa Mapa_cv se muestra en la consola de R.

```{r, out.width="200%", eval=FALSE}
Mapa_cv <-
  mapa + tm_polygons(
    c("Cv_pred"),
     title = "Mapa de tasa de informalidad(cv)",
    palette = "YlOrRd",
    colorNA = "white"
  ) + tm_layout(asp = 2.5)

Mapa_cv

```


```{r echo=FALSE, out.width = "500px", out.height="250px",fig.align='center'}
 knitr::include_graphics("0Recursos/Mapa_arcoseno_cv.PNG")
```

